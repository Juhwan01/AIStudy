{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ecbc1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\envs\\daycon\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import optuna\n",
    "from transformers import (\n",
    "    RobertaTokenizer, \n",
    "    RobertaForSequenceClassification,\n",
    "    TrainingArguments, \n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77191a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 모델 및 토크나이저 로드\n",
    "model_name = \"DeepChem/ChemBERTa-77M-MLM\"\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    cache_dir='C:/huggingface_cache'\n",
    ")\n",
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    model_name, \n",
    "    num_labels=1,\n",
    "    cache_dir='C:/huggingface_cache'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76511a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터: (1681, 3)\n",
      "테스트 데이터: (100, 2)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "print(f\"훈련 데이터: {train_df.shape}\")\n",
    "print(f\"테스트 데이터: {test_df.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f950efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 클래스 정의\n",
    "class SMILESDataset(Dataset):\n",
    "    def __init__(self, smiles_list, labels=None):\n",
    "        self.smiles_list = smiles_list\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.smiles_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        smiles = str(self.smiles_list[idx])\n",
    "        encoding = tokenizer(\n",
    "            smiles,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        item = {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten()\n",
    "        }\n",
    "        \n",
    "        if self.labels is not None:\n",
    "            item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        \n",
    "        return item\n",
    "\n",
    "# 평가 함수들\n",
    "def normalized_rmse(y_true, y_pred):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    return rmse / (np.max(y_true) - np.min(y_true))\n",
    "\n",
    "def pearson_correlation(y_true, y_pred):\n",
    "    corr = np.corrcoef(y_true, y_pred)[0, 1]\n",
    "    return np.clip(corr, 0, 1)\n",
    "\n",
    "def competition_score(y_true, y_pred):\n",
    "    nrmse = min(normalized_rmse(y_true, y_pred), 1)\n",
    "    pearson = pearson_correlation(y_true, y_pred)\n",
    "    return 0.5 * (1 - nrmse) + 0.5 * pearson\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = predictions.flatten()\n",
    "    labels = labels.flatten()\n",
    "    \n",
    "    nrmse = normalized_rmse(labels, predictions)\n",
    "    pearson = pearson_correlation(labels, predictions)\n",
    "    comp_score = competition_score(labels, predictions)\n",
    "    \n",
    "    return {\n",
    "        'nrmse': nrmse,\n",
    "        'pearson': pearson,\n",
    "        'competition_score': comp_score,\n",
    "        'mse': mean_squared_error(labels, predictions)\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8549f412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train_df['Canonical_Smiles'].values,\n",
    "    train_df['Inhibition'].values,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 데이터셋 생성\n",
    "train_dataset = SMILESDataset(X_train, y_train)\n",
    "val_dataset = SMILESDataset(X_val, y_val)\n",
    "test_dataset = SMILESDataset(test_df['Canonical_Smiles'].values)\n",
    "\n",
    "# 데이터 콜레이터\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0da76b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna 목적 함수\n",
    "def objective(trial):\n",
    "    # 하이퍼파라미터 탐색 공간\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 5e-6, 5e-4, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32])\n",
    "    warmup_steps = trial.suggest_int(\"warmup_steps\", 50, 300)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 0.001, 0.1, log=True)\n",
    "    \n",
    "    # 모델 로드\n",
    "    model = RobertaForSequenceClassification.from_pretrained(\n",
    "        model_name, \n",
    "        num_labels=1,\n",
    "        cache_dir='C:/huggingface_cache'\n",
    "    )\n",
    "    \n",
    "    # 훈련 설정\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f'./optuna_trial_{trial.number}',\n",
    "        num_train_epochs=30,  # 빠른 탐색을 위해 줄임\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        warmup_steps=warmup_steps,\n",
    "        weight_decay=weight_decay,\n",
    "        learning_rate=learning_rate,\n",
    "        logging_steps=100,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"competition_score\",\n",
    "        greater_is_better=True,\n",
    "        save_total_limit=1,\n",
    "        report_to=None,\n",
    "        fp16=False,\n",
    "        dataloader_pin_memory=False\n",
    "    )\n",
    "    \n",
    "    # Trainer 생성\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]  # 빠른 탐색\n",
    "    )\n",
    "    \n",
    "    # 훈련\n",
    "    trainer.train()\n",
    "    \n",
    "    # 최종 평가\n",
    "    eval_results = trainer.evaluate()\n",
    "    \n",
    "    # 메모리 정리\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return eval_results['eval_competition_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34d87ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 11:45:52,806] A new study created in memory with name: no-name-5ed7e64e-5fbe-4246-9c0d-8e694b0063eb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna 하이퍼파라미터 최적화 시작...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2520' max='5040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2520/5040 00:54 < 00:54, 46.23 it/s, Epoch 15/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1776.525000</td>\n",
       "      <td>1623.592896</td>\n",
       "      <td>0.405446</td>\n",
       "      <td>0.175801</td>\n",
       "      <td>0.385178</td>\n",
       "      <td>1623.593140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1630.925800</td>\n",
       "      <td>1439.815430</td>\n",
       "      <td>0.381810</td>\n",
       "      <td>0.193590</td>\n",
       "      <td>0.405890</td>\n",
       "      <td>1439.815430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1374.657000</td>\n",
       "      <td>1288.162842</td>\n",
       "      <td>0.361143</td>\n",
       "      <td>0.188377</td>\n",
       "      <td>0.413617</td>\n",
       "      <td>1288.162842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1322.749400</td>\n",
       "      <td>1171.611328</td>\n",
       "      <td>0.344418</td>\n",
       "      <td>0.201318</td>\n",
       "      <td>0.428450</td>\n",
       "      <td>1171.611328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1149.388100</td>\n",
       "      <td>1081.860718</td>\n",
       "      <td>0.330963</td>\n",
       "      <td>0.222468</td>\n",
       "      <td>0.445752</td>\n",
       "      <td>1081.860840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1087.598100</td>\n",
       "      <td>1010.719055</td>\n",
       "      <td>0.319896</td>\n",
       "      <td>0.234832</td>\n",
       "      <td>0.457468</td>\n",
       "      <td>1010.719055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1072.079300</td>\n",
       "      <td>954.806274</td>\n",
       "      <td>0.310922</td>\n",
       "      <td>0.242802</td>\n",
       "      <td>0.465940</td>\n",
       "      <td>954.806274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>966.062500</td>\n",
       "      <td>908.967651</td>\n",
       "      <td>0.303367</td>\n",
       "      <td>0.246251</td>\n",
       "      <td>0.471442</td>\n",
       "      <td>908.967651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>951.153700</td>\n",
       "      <td>872.809326</td>\n",
       "      <td>0.297272</td>\n",
       "      <td>0.260445</td>\n",
       "      <td>0.481586</td>\n",
       "      <td>872.809326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>890.081100</td>\n",
       "      <td>843.409790</td>\n",
       "      <td>0.292222</td>\n",
       "      <td>0.319463</td>\n",
       "      <td>0.513620</td>\n",
       "      <td>843.409851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>901.963400</td>\n",
       "      <td>819.767883</td>\n",
       "      <td>0.288098</td>\n",
       "      <td>0.252320</td>\n",
       "      <td>0.482111</td>\n",
       "      <td>819.767883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>843.892100</td>\n",
       "      <td>799.982483</td>\n",
       "      <td>0.284600</td>\n",
       "      <td>0.245206</td>\n",
       "      <td>0.480303</td>\n",
       "      <td>799.982483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>821.436400</td>\n",
       "      <td>784.099243</td>\n",
       "      <td>0.281760</td>\n",
       "      <td>0.280258</td>\n",
       "      <td>0.499249</td>\n",
       "      <td>784.099243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>806.012900</td>\n",
       "      <td>770.846008</td>\n",
       "      <td>0.279369</td>\n",
       "      <td>0.259478</td>\n",
       "      <td>0.490055</td>\n",
       "      <td>770.845947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>782.142000</td>\n",
       "      <td>760.499695</td>\n",
       "      <td>0.277488</td>\n",
       "      <td>0.302304</td>\n",
       "      <td>0.512408</td>\n",
       "      <td>760.499695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 11:46:49,073] Trial 0 finished with value: 0.5136200510097674 and parameters: {'learning_rate': 2.8057582076672495e-05, 'batch_size': 8, 'warmup_steps': 89, 'weight_decay': 0.002051110418843397}. Best is trial 0 with value: 0.5136200510097674.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1176' max='5040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1176/5040 00:25 < 01:24, 45.92 it/s, Epoch 7/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1786.755200</td>\n",
       "      <td>1734.040405</td>\n",
       "      <td>0.419009</td>\n",
       "      <td>0.053610</td>\n",
       "      <td>0.317300</td>\n",
       "      <td>1734.040405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1814.025800</td>\n",
       "      <td>1695.532227</td>\n",
       "      <td>0.414331</td>\n",
       "      <td>0.140226</td>\n",
       "      <td>0.362947</td>\n",
       "      <td>1695.532227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1702.161600</td>\n",
       "      <td>1650.270020</td>\n",
       "      <td>0.408763</td>\n",
       "      <td>0.125478</td>\n",
       "      <td>0.358357</td>\n",
       "      <td>1650.270020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1716.902500</td>\n",
       "      <td>1607.764648</td>\n",
       "      <td>0.403465</td>\n",
       "      <td>0.106715</td>\n",
       "      <td>0.351625</td>\n",
       "      <td>1607.764648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1615.570000</td>\n",
       "      <td>1568.111084</td>\n",
       "      <td>0.398458</td>\n",
       "      <td>0.097450</td>\n",
       "      <td>0.349496</td>\n",
       "      <td>1568.111084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1628.947200</td>\n",
       "      <td>1530.745605</td>\n",
       "      <td>0.393682</td>\n",
       "      <td>0.091052</td>\n",
       "      <td>0.348685</td>\n",
       "      <td>1530.745605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1635.349200</td>\n",
       "      <td>1495.444702</td>\n",
       "      <td>0.389116</td>\n",
       "      <td>0.086310</td>\n",
       "      <td>0.348597</td>\n",
       "      <td>1495.444580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 11:47:15,989] Trial 1 finished with value: 0.36294747391732696 and parameters: {'learning_rate': 6.533369619026635e-06, 'batch_size': 8, 'warmup_steps': 55, 'weight_decay': 0.08706020878304858}. Best is trial 0 with value: 0.5136200510097674.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2688' max='5040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2688/5040 00:58 < 00:50, 46.16 it/s, Epoch 16/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1684.883900</td>\n",
       "      <td>1013.680664</td>\n",
       "      <td>0.320365</td>\n",
       "      <td>0.205763</td>\n",
       "      <td>0.442699</td>\n",
       "      <td>1013.680664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>860.382200</td>\n",
       "      <td>725.478210</td>\n",
       "      <td>0.271023</td>\n",
       "      <td>0.325349</td>\n",
       "      <td>0.527163</td>\n",
       "      <td>725.478149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>707.403200</td>\n",
       "      <td>696.739929</td>\n",
       "      <td>0.265601</td>\n",
       "      <td>0.289274</td>\n",
       "      <td>0.511836</td>\n",
       "      <td>696.739929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>701.601500</td>\n",
       "      <td>677.560974</td>\n",
       "      <td>0.261920</td>\n",
       "      <td>0.210892</td>\n",
       "      <td>0.474486</td>\n",
       "      <td>677.560913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>665.520200</td>\n",
       "      <td>639.407104</td>\n",
       "      <td>0.254439</td>\n",
       "      <td>0.328982</td>\n",
       "      <td>0.537272</td>\n",
       "      <td>639.407104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>625.936400</td>\n",
       "      <td>620.994141</td>\n",
       "      <td>0.250748</td>\n",
       "      <td>0.333670</td>\n",
       "      <td>0.541461</td>\n",
       "      <td>620.994141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>619.704300</td>\n",
       "      <td>653.182373</td>\n",
       "      <td>0.257165</td>\n",
       "      <td>0.315898</td>\n",
       "      <td>0.529367</td>\n",
       "      <td>653.182373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>565.307900</td>\n",
       "      <td>639.137329</td>\n",
       "      <td>0.254385</td>\n",
       "      <td>0.306357</td>\n",
       "      <td>0.525986</td>\n",
       "      <td>639.137329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>560.305400</td>\n",
       "      <td>698.744690</td>\n",
       "      <td>0.265983</td>\n",
       "      <td>0.352452</td>\n",
       "      <td>0.543235</td>\n",
       "      <td>698.744690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>474.261700</td>\n",
       "      <td>632.374329</td>\n",
       "      <td>0.253035</td>\n",
       "      <td>0.330335</td>\n",
       "      <td>0.538650</td>\n",
       "      <td>632.374329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>491.630800</td>\n",
       "      <td>612.354553</td>\n",
       "      <td>0.248998</td>\n",
       "      <td>0.357549</td>\n",
       "      <td>0.554276</td>\n",
       "      <td>612.354614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>439.207700</td>\n",
       "      <td>658.146790</td>\n",
       "      <td>0.258140</td>\n",
       "      <td>0.311474</td>\n",
       "      <td>0.526667</td>\n",
       "      <td>658.146790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>414.132300</td>\n",
       "      <td>654.865234</td>\n",
       "      <td>0.257496</td>\n",
       "      <td>0.323842</td>\n",
       "      <td>0.533173</td>\n",
       "      <td>654.865234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>384.671300</td>\n",
       "      <td>726.506226</td>\n",
       "      <td>0.271215</td>\n",
       "      <td>0.325482</td>\n",
       "      <td>0.527133</td>\n",
       "      <td>726.506226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>371.093200</td>\n",
       "      <td>706.134827</td>\n",
       "      <td>0.267386</td>\n",
       "      <td>0.327090</td>\n",
       "      <td>0.529852</td>\n",
       "      <td>706.134827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>347.920300</td>\n",
       "      <td>697.336121</td>\n",
       "      <td>0.265715</td>\n",
       "      <td>0.356223</td>\n",
       "      <td>0.545254</td>\n",
       "      <td>697.336121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 11:48:15,896] Trial 2 finished with value: 0.5542756736310166 and parameters: {'learning_rate': 0.00023112945005104147, 'batch_size': 8, 'warmup_steps': 126, 'weight_decay': 0.01120760621186057}. Best is trial 2 with value: 0.5542756736310166.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2100' max='2520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2100/2520 00:59 < 00:11, 35.22 it/s, Epoch 25/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1725.299316</td>\n",
       "      <td>0.417952</td>\n",
       "      <td>0.131859</td>\n",
       "      <td>0.356953</td>\n",
       "      <td>1725.299316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1784.098900</td>\n",
       "      <td>1592.121704</td>\n",
       "      <td>0.401497</td>\n",
       "      <td>0.129721</td>\n",
       "      <td>0.364112</td>\n",
       "      <td>1592.121704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1720.836300</td>\n",
       "      <td>1468.803955</td>\n",
       "      <td>0.385635</td>\n",
       "      <td>0.133715</td>\n",
       "      <td>0.374040</td>\n",
       "      <td>1468.803955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1533.016100</td>\n",
       "      <td>1362.020264</td>\n",
       "      <td>0.371352</td>\n",
       "      <td>0.141847</td>\n",
       "      <td>0.385247</td>\n",
       "      <td>1362.020264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1374.430900</td>\n",
       "      <td>1271.694336</td>\n",
       "      <td>0.358827</td>\n",
       "      <td>0.123770</td>\n",
       "      <td>0.382471</td>\n",
       "      <td>1271.694336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1318.995300</td>\n",
       "      <td>1196.518311</td>\n",
       "      <td>0.348060</td>\n",
       "      <td>0.127921</td>\n",
       "      <td>0.389930</td>\n",
       "      <td>1196.518311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1318.995300</td>\n",
       "      <td>1134.078003</td>\n",
       "      <td>0.338856</td>\n",
       "      <td>0.101311</td>\n",
       "      <td>0.381227</td>\n",
       "      <td>1134.078003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1203.704100</td>\n",
       "      <td>1081.482788</td>\n",
       "      <td>0.330906</td>\n",
       "      <td>0.152840</td>\n",
       "      <td>0.410967</td>\n",
       "      <td>1081.482788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1117.946800</td>\n",
       "      <td>1036.869385</td>\n",
       "      <td>0.324008</td>\n",
       "      <td>0.131477</td>\n",
       "      <td>0.403734</td>\n",
       "      <td>1036.869385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1104.195100</td>\n",
       "      <td>998.664062</td>\n",
       "      <td>0.317983</td>\n",
       "      <td>0.147981</td>\n",
       "      <td>0.414999</td>\n",
       "      <td>998.664062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1057.991300</td>\n",
       "      <td>965.589783</td>\n",
       "      <td>0.312673</td>\n",
       "      <td>0.174316</td>\n",
       "      <td>0.430821</td>\n",
       "      <td>965.589783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>970.343800</td>\n",
       "      <td>936.957336</td>\n",
       "      <td>0.308002</td>\n",
       "      <td>0.164646</td>\n",
       "      <td>0.428322</td>\n",
       "      <td>936.957336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>970.343800</td>\n",
       "      <td>912.012878</td>\n",
       "      <td>0.303875</td>\n",
       "      <td>0.171427</td>\n",
       "      <td>0.433776</td>\n",
       "      <td>912.012878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>948.052000</td>\n",
       "      <td>890.479797</td>\n",
       "      <td>0.300266</td>\n",
       "      <td>0.175876</td>\n",
       "      <td>0.437805</td>\n",
       "      <td>890.479858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>941.851300</td>\n",
       "      <td>871.777466</td>\n",
       "      <td>0.297096</td>\n",
       "      <td>0.201865</td>\n",
       "      <td>0.452384</td>\n",
       "      <td>871.777466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>892.045200</td>\n",
       "      <td>855.261475</td>\n",
       "      <td>0.294268</td>\n",
       "      <td>0.214163</td>\n",
       "      <td>0.459947</td>\n",
       "      <td>855.261475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>882.841600</td>\n",
       "      <td>840.630737</td>\n",
       "      <td>0.291741</td>\n",
       "      <td>0.219271</td>\n",
       "      <td>0.463765</td>\n",
       "      <td>840.630737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>870.198000</td>\n",
       "      <td>828.373169</td>\n",
       "      <td>0.289606</td>\n",
       "      <td>0.244027</td>\n",
       "      <td>0.477211</td>\n",
       "      <td>828.373169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>870.198000</td>\n",
       "      <td>817.703064</td>\n",
       "      <td>0.287735</td>\n",
       "      <td>0.256671</td>\n",
       "      <td>0.484468</td>\n",
       "      <td>817.703186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>843.789300</td>\n",
       "      <td>808.384338</td>\n",
       "      <td>0.286090</td>\n",
       "      <td>0.265264</td>\n",
       "      <td>0.489587</td>\n",
       "      <td>808.384338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>832.845100</td>\n",
       "      <td>800.466553</td>\n",
       "      <td>0.284686</td>\n",
       "      <td>0.262842</td>\n",
       "      <td>0.489078</td>\n",
       "      <td>800.466553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>828.706400</td>\n",
       "      <td>793.926758</td>\n",
       "      <td>0.283521</td>\n",
       "      <td>0.258187</td>\n",
       "      <td>0.487333</td>\n",
       "      <td>793.926758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>827.786600</td>\n",
       "      <td>788.386841</td>\n",
       "      <td>0.282530</td>\n",
       "      <td>0.247172</td>\n",
       "      <td>0.482321</td>\n",
       "      <td>788.386841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>790.839000</td>\n",
       "      <td>783.995361</td>\n",
       "      <td>0.281742</td>\n",
       "      <td>0.258490</td>\n",
       "      <td>0.488374</td>\n",
       "      <td>783.995483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>807.456800</td>\n",
       "      <td>780.019592</td>\n",
       "      <td>0.281026</td>\n",
       "      <td>0.251324</td>\n",
       "      <td>0.485149</td>\n",
       "      <td>780.019470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 11:49:16,759] Trial 3 finished with value: 0.4895868710196091 and parameters: {'learning_rate': 3.654769917956452e-05, 'batch_size': 16, 'warmup_steps': 123, 'weight_decay': 0.005404103854647328}. Best is trial 2 with value: 0.5542756736310166.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3696' max='5040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3696/5040 01:20 < 00:29, 46.09 it/s, Epoch 22/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1783.840900</td>\n",
       "      <td>1659.749023</td>\n",
       "      <td>0.409935</td>\n",
       "      <td>0.186364</td>\n",
       "      <td>0.388214</td>\n",
       "      <td>1659.749268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1627.628100</td>\n",
       "      <td>1398.393311</td>\n",
       "      <td>0.376278</td>\n",
       "      <td>0.183626</td>\n",
       "      <td>0.403674</td>\n",
       "      <td>1398.393433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1295.227400</td>\n",
       "      <td>1198.034912</td>\n",
       "      <td>0.348280</td>\n",
       "      <td>0.183378</td>\n",
       "      <td>0.417549</td>\n",
       "      <td>1198.034912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1218.105800</td>\n",
       "      <td>1059.033447</td>\n",
       "      <td>0.327453</td>\n",
       "      <td>0.199562</td>\n",
       "      <td>0.436055</td>\n",
       "      <td>1059.033447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1028.105500</td>\n",
       "      <td>961.047913</td>\n",
       "      <td>0.311937</td>\n",
       "      <td>0.213890</td>\n",
       "      <td>0.450976</td>\n",
       "      <td>961.047913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>954.398800</td>\n",
       "      <td>889.727905</td>\n",
       "      <td>0.300139</td>\n",
       "      <td>0.219462</td>\n",
       "      <td>0.459662</td>\n",
       "      <td>889.727905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>937.879700</td>\n",
       "      <td>836.630554</td>\n",
       "      <td>0.291046</td>\n",
       "      <td>0.162815</td>\n",
       "      <td>0.435885</td>\n",
       "      <td>836.630554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>836.921400</td>\n",
       "      <td>797.370178</td>\n",
       "      <td>0.284135</td>\n",
       "      <td>0.203053</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>797.370056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>824.645500</td>\n",
       "      <td>769.952393</td>\n",
       "      <td>0.279207</td>\n",
       "      <td>0.210469</td>\n",
       "      <td>0.465631</td>\n",
       "      <td>769.952393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>780.229000</td>\n",
       "      <td>750.677917</td>\n",
       "      <td>0.275690</td>\n",
       "      <td>0.161838</td>\n",
       "      <td>0.443074</td>\n",
       "      <td>750.677979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>795.703000</td>\n",
       "      <td>736.374939</td>\n",
       "      <td>0.273051</td>\n",
       "      <td>0.246517</td>\n",
       "      <td>0.486733</td>\n",
       "      <td>736.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>753.532300</td>\n",
       "      <td>726.774963</td>\n",
       "      <td>0.271265</td>\n",
       "      <td>0.237583</td>\n",
       "      <td>0.483159</td>\n",
       "      <td>726.774963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>737.873000</td>\n",
       "      <td>719.227112</td>\n",
       "      <td>0.269853</td>\n",
       "      <td>0.304404</td>\n",
       "      <td>0.517276</td>\n",
       "      <td>719.227112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>733.709500</td>\n",
       "      <td>713.225708</td>\n",
       "      <td>0.268725</td>\n",
       "      <td>0.288408</td>\n",
       "      <td>0.509842</td>\n",
       "      <td>713.225708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>717.815500</td>\n",
       "      <td>709.177124</td>\n",
       "      <td>0.267961</td>\n",
       "      <td>0.331320</td>\n",
       "      <td>0.531680</td>\n",
       "      <td>709.177124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>709.998400</td>\n",
       "      <td>706.440979</td>\n",
       "      <td>0.267444</td>\n",
       "      <td>0.316016</td>\n",
       "      <td>0.524286</td>\n",
       "      <td>706.440979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>702.346300</td>\n",
       "      <td>704.023010</td>\n",
       "      <td>0.266986</td>\n",
       "      <td>0.336409</td>\n",
       "      <td>0.534712</td>\n",
       "      <td>704.023010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>739.277000</td>\n",
       "      <td>702.281921</td>\n",
       "      <td>0.266655</td>\n",
       "      <td>0.333342</td>\n",
       "      <td>0.533343</td>\n",
       "      <td>702.281982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>723.392300</td>\n",
       "      <td>700.962646</td>\n",
       "      <td>0.266405</td>\n",
       "      <td>0.333505</td>\n",
       "      <td>0.533550</td>\n",
       "      <td>700.962646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>693.193000</td>\n",
       "      <td>695.995239</td>\n",
       "      <td>0.265459</td>\n",
       "      <td>0.324837</td>\n",
       "      <td>0.529689</td>\n",
       "      <td>695.995300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>713.278300</td>\n",
       "      <td>685.082275</td>\n",
       "      <td>0.263370</td>\n",
       "      <td>0.312332</td>\n",
       "      <td>0.524481</td>\n",
       "      <td>685.082275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>691.888900</td>\n",
       "      <td>718.236572</td>\n",
       "      <td>0.269667</td>\n",
       "      <td>0.316431</td>\n",
       "      <td>0.523382</td>\n",
       "      <td>718.236572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 11:50:38,256] Trial 4 finished with value: 0.5347119894914337 and parameters: {'learning_rate': 4.0842279473800804e-05, 'batch_size': 8, 'warmup_steps': 198, 'weight_decay': 0.001238513729886093}. Best is trial 2 with value: 0.5542756736310166.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1176' max='1260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1176/1260 00:50 < 00:03, 23.40 it/s, Epoch 28/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1747.784546</td>\n",
       "      <td>0.420667</td>\n",
       "      <td>0.165169</td>\n",
       "      <td>0.372251</td>\n",
       "      <td>1747.784302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1724.714722</td>\n",
       "      <td>0.417881</td>\n",
       "      <td>0.167719</td>\n",
       "      <td>0.374919</td>\n",
       "      <td>1724.714722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1809.300600</td>\n",
       "      <td>1663.145020</td>\n",
       "      <td>0.410355</td>\n",
       "      <td>0.114660</td>\n",
       "      <td>0.352153</td>\n",
       "      <td>1663.145020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1809.300600</td>\n",
       "      <td>1582.182617</td>\n",
       "      <td>0.400242</td>\n",
       "      <td>0.067899</td>\n",
       "      <td>0.333829</td>\n",
       "      <td>1582.182617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1658.575200</td>\n",
       "      <td>1485.907837</td>\n",
       "      <td>0.387874</td>\n",
       "      <td>0.063280</td>\n",
       "      <td>0.337703</td>\n",
       "      <td>1485.907837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1658.575200</td>\n",
       "      <td>1377.629883</td>\n",
       "      <td>0.373474</td>\n",
       "      <td>0.087135</td>\n",
       "      <td>0.356830</td>\n",
       "      <td>1377.629883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1658.575200</td>\n",
       "      <td>1267.086426</td>\n",
       "      <td>0.358177</td>\n",
       "      <td>0.140481</td>\n",
       "      <td>0.391152</td>\n",
       "      <td>1267.086426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1448.636700</td>\n",
       "      <td>1170.950073</td>\n",
       "      <td>0.344321</td>\n",
       "      <td>0.111975</td>\n",
       "      <td>0.383827</td>\n",
       "      <td>1170.950073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1448.636700</td>\n",
       "      <td>1094.464478</td>\n",
       "      <td>0.332886</td>\n",
       "      <td>0.143833</td>\n",
       "      <td>0.405474</td>\n",
       "      <td>1094.464355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1196.659000</td>\n",
       "      <td>1032.452026</td>\n",
       "      <td>0.323317</td>\n",
       "      <td>0.099274</td>\n",
       "      <td>0.387978</td>\n",
       "      <td>1032.451782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1196.659000</td>\n",
       "      <td>981.262451</td>\n",
       "      <td>0.315200</td>\n",
       "      <td>0.161584</td>\n",
       "      <td>0.423192</td>\n",
       "      <td>981.262451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1037.668000</td>\n",
       "      <td>938.419434</td>\n",
       "      <td>0.308243</td>\n",
       "      <td>0.139886</td>\n",
       "      <td>0.415822</td>\n",
       "      <td>938.419312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1037.668000</td>\n",
       "      <td>902.330750</td>\n",
       "      <td>0.302258</td>\n",
       "      <td>0.136443</td>\n",
       "      <td>0.417093</td>\n",
       "      <td>902.330688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1037.668000</td>\n",
       "      <td>871.778748</td>\n",
       "      <td>0.297096</td>\n",
       "      <td>0.168346</td>\n",
       "      <td>0.435625</td>\n",
       "      <td>871.778748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>934.789600</td>\n",
       "      <td>845.898376</td>\n",
       "      <td>0.292653</td>\n",
       "      <td>0.161778</td>\n",
       "      <td>0.434562</td>\n",
       "      <td>845.898254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>934.789600</td>\n",
       "      <td>823.973206</td>\n",
       "      <td>0.288836</td>\n",
       "      <td>0.168102</td>\n",
       "      <td>0.439633</td>\n",
       "      <td>823.973206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>857.655400</td>\n",
       "      <td>805.334412</td>\n",
       "      <td>0.285550</td>\n",
       "      <td>0.222988</td>\n",
       "      <td>0.468719</td>\n",
       "      <td>805.334412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>857.655400</td>\n",
       "      <td>790.144104</td>\n",
       "      <td>0.282844</td>\n",
       "      <td>0.214948</td>\n",
       "      <td>0.466052</td>\n",
       "      <td>790.144104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>857.655400</td>\n",
       "      <td>777.309143</td>\n",
       "      <td>0.280538</td>\n",
       "      <td>0.215592</td>\n",
       "      <td>0.467527</td>\n",
       "      <td>777.309143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>816.085300</td>\n",
       "      <td>766.615234</td>\n",
       "      <td>0.278601</td>\n",
       "      <td>0.251375</td>\n",
       "      <td>0.486387</td>\n",
       "      <td>766.615173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>816.085300</td>\n",
       "      <td>757.949097</td>\n",
       "      <td>0.277022</td>\n",
       "      <td>0.257563</td>\n",
       "      <td>0.490270</td>\n",
       "      <td>757.949036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>785.001900</td>\n",
       "      <td>750.425964</td>\n",
       "      <td>0.275644</td>\n",
       "      <td>0.213887</td>\n",
       "      <td>0.469122</td>\n",
       "      <td>750.426025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>785.001900</td>\n",
       "      <td>744.510681</td>\n",
       "      <td>0.274555</td>\n",
       "      <td>0.267008</td>\n",
       "      <td>0.496226</td>\n",
       "      <td>744.510681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>760.809100</td>\n",
       "      <td>740.034485</td>\n",
       "      <td>0.273729</td>\n",
       "      <td>0.233580</td>\n",
       "      <td>0.479926</td>\n",
       "      <td>740.034485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>760.809100</td>\n",
       "      <td>736.328003</td>\n",
       "      <td>0.273042</td>\n",
       "      <td>0.243142</td>\n",
       "      <td>0.485050</td>\n",
       "      <td>736.327881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>760.809100</td>\n",
       "      <td>733.421814</td>\n",
       "      <td>0.272503</td>\n",
       "      <td>0.261980</td>\n",
       "      <td>0.494738</td>\n",
       "      <td>733.421875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>750.265700</td>\n",
       "      <td>731.295227</td>\n",
       "      <td>0.272108</td>\n",
       "      <td>0.238561</td>\n",
       "      <td>0.483227</td>\n",
       "      <td>731.295349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>750.265700</td>\n",
       "      <td>729.957275</td>\n",
       "      <td>0.271859</td>\n",
       "      <td>0.234465</td>\n",
       "      <td>0.481303</td>\n",
       "      <td>729.957214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 11:51:29,708] Trial 5 finished with value: 0.49622641524230116 and parameters: {'learning_rate': 8.204643365323964e-05, 'batch_size': 32, 'warmup_steps': 292, 'weight_decay': 0.041380401125610165}. Best is trial 2 with value: 0.5542756736310166.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2520' max='2520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2520/2520 01:11, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1732.633911</td>\n",
       "      <td>0.418840</td>\n",
       "      <td>0.164389</td>\n",
       "      <td>0.372775</td>\n",
       "      <td>1732.633911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1786.519100</td>\n",
       "      <td>1655.591187</td>\n",
       "      <td>0.409422</td>\n",
       "      <td>0.081670</td>\n",
       "      <td>0.336124</td>\n",
       "      <td>1655.591187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1769.317000</td>\n",
       "      <td>1580.373169</td>\n",
       "      <td>0.400013</td>\n",
       "      <td>0.073430</td>\n",
       "      <td>0.336709</td>\n",
       "      <td>1580.373291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1642.364200</td>\n",
       "      <td>1514.229492</td>\n",
       "      <td>0.391553</td>\n",
       "      <td>0.134974</td>\n",
       "      <td>0.371711</td>\n",
       "      <td>1514.229492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1532.603700</td>\n",
       "      <td>1454.200806</td>\n",
       "      <td>0.383713</td>\n",
       "      <td>0.167351</td>\n",
       "      <td>0.391819</td>\n",
       "      <td>1454.200684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1516.585900</td>\n",
       "      <td>1399.645996</td>\n",
       "      <td>0.376447</td>\n",
       "      <td>0.182237</td>\n",
       "      <td>0.402895</td>\n",
       "      <td>1399.645874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1516.585900</td>\n",
       "      <td>1350.535645</td>\n",
       "      <td>0.369783</td>\n",
       "      <td>0.213514</td>\n",
       "      <td>0.421865</td>\n",
       "      <td>1350.535645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1421.310600</td>\n",
       "      <td>1306.502075</td>\n",
       "      <td>0.363705</td>\n",
       "      <td>0.200425</td>\n",
       "      <td>0.418360</td>\n",
       "      <td>1306.502075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1348.626300</td>\n",
       "      <td>1267.367065</td>\n",
       "      <td>0.358216</td>\n",
       "      <td>0.211543</td>\n",
       "      <td>0.426663</td>\n",
       "      <td>1267.367065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1353.156600</td>\n",
       "      <td>1232.494751</td>\n",
       "      <td>0.353254</td>\n",
       "      <td>0.230570</td>\n",
       "      <td>0.438658</td>\n",
       "      <td>1232.494751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1308.802700</td>\n",
       "      <td>1201.468994</td>\n",
       "      <td>0.348779</td>\n",
       "      <td>0.228201</td>\n",
       "      <td>0.439711</td>\n",
       "      <td>1201.468872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1216.756600</td>\n",
       "      <td>1173.795898</td>\n",
       "      <td>0.344739</td>\n",
       "      <td>0.231606</td>\n",
       "      <td>0.443433</td>\n",
       "      <td>1173.795898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1216.756600</td>\n",
       "      <td>1149.082642</td>\n",
       "      <td>0.341091</td>\n",
       "      <td>0.247052</td>\n",
       "      <td>0.452981</td>\n",
       "      <td>1149.082764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1200.387500</td>\n",
       "      <td>1127.021729</td>\n",
       "      <td>0.337801</td>\n",
       "      <td>0.256040</td>\n",
       "      <td>0.459120</td>\n",
       "      <td>1127.021851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1194.005400</td>\n",
       "      <td>1107.267456</td>\n",
       "      <td>0.334827</td>\n",
       "      <td>0.240120</td>\n",
       "      <td>0.452646</td>\n",
       "      <td>1107.267456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1139.462300</td>\n",
       "      <td>1089.603516</td>\n",
       "      <td>0.332146</td>\n",
       "      <td>0.244012</td>\n",
       "      <td>0.455933</td>\n",
       "      <td>1089.603516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1139.738900</td>\n",
       "      <td>1073.781616</td>\n",
       "      <td>0.329725</td>\n",
       "      <td>0.252429</td>\n",
       "      <td>0.461352</td>\n",
       "      <td>1073.781494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1119.832900</td>\n",
       "      <td>1059.666138</td>\n",
       "      <td>0.327551</td>\n",
       "      <td>0.249691</td>\n",
       "      <td>0.461070</td>\n",
       "      <td>1059.666016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1119.832900</td>\n",
       "      <td>1047.107788</td>\n",
       "      <td>0.325604</td>\n",
       "      <td>0.253143</td>\n",
       "      <td>0.463769</td>\n",
       "      <td>1047.107666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1092.406700</td>\n",
       "      <td>1035.957764</td>\n",
       "      <td>0.323866</td>\n",
       "      <td>0.255861</td>\n",
       "      <td>0.465998</td>\n",
       "      <td>1035.957764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1079.207000</td>\n",
       "      <td>1026.131348</td>\n",
       "      <td>0.322326</td>\n",
       "      <td>0.254033</td>\n",
       "      <td>0.465853</td>\n",
       "      <td>1026.131348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1068.676600</td>\n",
       "      <td>1017.597290</td>\n",
       "      <td>0.320983</td>\n",
       "      <td>0.244701</td>\n",
       "      <td>0.461859</td>\n",
       "      <td>1017.597290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1070.650200</td>\n",
       "      <td>1010.197449</td>\n",
       "      <td>0.319814</td>\n",
       "      <td>0.240399</td>\n",
       "      <td>0.460292</td>\n",
       "      <td>1010.197510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1029.170000</td>\n",
       "      <td>1003.914124</td>\n",
       "      <td>0.318818</td>\n",
       "      <td>0.253947</td>\n",
       "      <td>0.467564</td>\n",
       "      <td>1003.914124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1042.274000</td>\n",
       "      <td>998.642639</td>\n",
       "      <td>0.317980</td>\n",
       "      <td>0.251639</td>\n",
       "      <td>0.466830</td>\n",
       "      <td>998.642700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1042.274000</td>\n",
       "      <td>994.364868</td>\n",
       "      <td>0.317298</td>\n",
       "      <td>0.261293</td>\n",
       "      <td>0.471997</td>\n",
       "      <td>994.364990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1024.892700</td>\n",
       "      <td>991.050903</td>\n",
       "      <td>0.316769</td>\n",
       "      <td>0.257087</td>\n",
       "      <td>0.470159</td>\n",
       "      <td>991.051025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1034.615800</td>\n",
       "      <td>988.694336</td>\n",
       "      <td>0.316392</td>\n",
       "      <td>0.257885</td>\n",
       "      <td>0.470746</td>\n",
       "      <td>988.694336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1036.812100</td>\n",
       "      <td>987.282532</td>\n",
       "      <td>0.316166</td>\n",
       "      <td>0.258562</td>\n",
       "      <td>0.471198</td>\n",
       "      <td>987.282654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1010.877400</td>\n",
       "      <td>986.807007</td>\n",
       "      <td>0.316090</td>\n",
       "      <td>0.258842</td>\n",
       "      <td>0.471376</td>\n",
       "      <td>986.807007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 11:52:42,673] Trial 6 finished with value: 0.47199742354884566 and parameters: {'learning_rate': 2.033281656757398e-05, 'batch_size': 16, 'warmup_steps': 80, 'weight_decay': 0.009780337016659405}. Best is trial 2 with value: 0.5542756736310166.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5040' max='5040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5040/5040 01:49, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1790.396600</td>\n",
       "      <td>1742.491821</td>\n",
       "      <td>0.420029</td>\n",
       "      <td>0.128952</td>\n",
       "      <td>0.354462</td>\n",
       "      <td>1742.491821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1827.511300</td>\n",
       "      <td>1713.588989</td>\n",
       "      <td>0.416531</td>\n",
       "      <td>0.147757</td>\n",
       "      <td>0.365613</td>\n",
       "      <td>1713.588867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1722.541100</td>\n",
       "      <td>1674.090332</td>\n",
       "      <td>0.411703</td>\n",
       "      <td>0.132626</td>\n",
       "      <td>0.360462</td>\n",
       "      <td>1674.090332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1739.910200</td>\n",
       "      <td>1634.419922</td>\n",
       "      <td>0.406795</td>\n",
       "      <td>0.127648</td>\n",
       "      <td>0.360426</td>\n",
       "      <td>1634.420044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1641.879500</td>\n",
       "      <td>1597.379883</td>\n",
       "      <td>0.402160</td>\n",
       "      <td>0.141590</td>\n",
       "      <td>0.369715</td>\n",
       "      <td>1597.379883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1659.159200</td>\n",
       "      <td>1562.945435</td>\n",
       "      <td>0.397801</td>\n",
       "      <td>0.149737</td>\n",
       "      <td>0.375968</td>\n",
       "      <td>1562.945312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1667.706600</td>\n",
       "      <td>1530.552490</td>\n",
       "      <td>0.393657</td>\n",
       "      <td>0.157431</td>\n",
       "      <td>0.381887</td>\n",
       "      <td>1530.552490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1588.255600</td>\n",
       "      <td>1500.193237</td>\n",
       "      <td>0.389734</td>\n",
       "      <td>0.162538</td>\n",
       "      <td>0.386402</td>\n",
       "      <td>1500.193237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1613.839700</td>\n",
       "      <td>1471.605469</td>\n",
       "      <td>0.386002</td>\n",
       "      <td>0.164425</td>\n",
       "      <td>0.389211</td>\n",
       "      <td>1471.605469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1520.498700</td>\n",
       "      <td>1445.112915</td>\n",
       "      <td>0.382512</td>\n",
       "      <td>0.164055</td>\n",
       "      <td>0.390771</td>\n",
       "      <td>1445.113037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1565.363600</td>\n",
       "      <td>1420.444336</td>\n",
       "      <td>0.379233</td>\n",
       "      <td>0.163654</td>\n",
       "      <td>0.392210</td>\n",
       "      <td>1420.444336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1494.077700</td>\n",
       "      <td>1397.618896</td>\n",
       "      <td>0.376174</td>\n",
       "      <td>0.159191</td>\n",
       "      <td>0.391509</td>\n",
       "      <td>1397.618896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1468.035600</td>\n",
       "      <td>1376.643066</td>\n",
       "      <td>0.373340</td>\n",
       "      <td>0.158178</td>\n",
       "      <td>0.392419</td>\n",
       "      <td>1376.642944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1443.507300</td>\n",
       "      <td>1357.459229</td>\n",
       "      <td>0.370730</td>\n",
       "      <td>0.157390</td>\n",
       "      <td>0.393330</td>\n",
       "      <td>1357.458984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1414.641600</td>\n",
       "      <td>1339.793945</td>\n",
       "      <td>0.368310</td>\n",
       "      <td>0.162755</td>\n",
       "      <td>0.397223</td>\n",
       "      <td>1339.793945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1346.217200</td>\n",
       "      <td>1323.627808</td>\n",
       "      <td>0.366081</td>\n",
       "      <td>0.159598</td>\n",
       "      <td>0.396759</td>\n",
       "      <td>1323.627808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1344.250200</td>\n",
       "      <td>1308.893311</td>\n",
       "      <td>0.364038</td>\n",
       "      <td>0.162089</td>\n",
       "      <td>0.399026</td>\n",
       "      <td>1308.893311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1433.566600</td>\n",
       "      <td>1295.562012</td>\n",
       "      <td>0.362179</td>\n",
       "      <td>0.162161</td>\n",
       "      <td>0.399991</td>\n",
       "      <td>1295.562012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1352.966400</td>\n",
       "      <td>1283.546875</td>\n",
       "      <td>0.360496</td>\n",
       "      <td>0.161789</td>\n",
       "      <td>0.400647</td>\n",
       "      <td>1283.546875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1280.188500</td>\n",
       "      <td>1272.746704</td>\n",
       "      <td>0.358976</td>\n",
       "      <td>0.157346</td>\n",
       "      <td>0.399185</td>\n",
       "      <td>1272.746704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1344.085900</td>\n",
       "      <td>1263.120483</td>\n",
       "      <td>0.357616</td>\n",
       "      <td>0.156857</td>\n",
       "      <td>0.399620</td>\n",
       "      <td>1263.120605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1290.580100</td>\n",
       "      <td>1254.686401</td>\n",
       "      <td>0.356420</td>\n",
       "      <td>0.158221</td>\n",
       "      <td>0.400901</td>\n",
       "      <td>1254.686401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1340.174200</td>\n",
       "      <td>1247.234375</td>\n",
       "      <td>0.355360</td>\n",
       "      <td>0.159302</td>\n",
       "      <td>0.401971</td>\n",
       "      <td>1247.234375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1305.118400</td>\n",
       "      <td>1240.984497</td>\n",
       "      <td>0.354468</td>\n",
       "      <td>0.161613</td>\n",
       "      <td>0.403572</td>\n",
       "      <td>1240.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1288.418900</td>\n",
       "      <td>1235.608521</td>\n",
       "      <td>0.353700</td>\n",
       "      <td>0.163274</td>\n",
       "      <td>0.404787</td>\n",
       "      <td>1235.608398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1282.062500</td>\n",
       "      <td>1231.238281</td>\n",
       "      <td>0.353074</td>\n",
       "      <td>0.164829</td>\n",
       "      <td>0.405877</td>\n",
       "      <td>1231.238281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1280.330900</td>\n",
       "      <td>1227.824707</td>\n",
       "      <td>0.352584</td>\n",
       "      <td>0.163848</td>\n",
       "      <td>0.405632</td>\n",
       "      <td>1227.824707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1284.899800</td>\n",
       "      <td>1225.421509</td>\n",
       "      <td>0.352239</td>\n",
       "      <td>0.165544</td>\n",
       "      <td>0.406653</td>\n",
       "      <td>1225.421509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1288.870600</td>\n",
       "      <td>1223.939575</td>\n",
       "      <td>0.352026</td>\n",
       "      <td>0.165762</td>\n",
       "      <td>0.406868</td>\n",
       "      <td>1223.939575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1263.872700</td>\n",
       "      <td>1223.445068</td>\n",
       "      <td>0.351954</td>\n",
       "      <td>0.166263</td>\n",
       "      <td>0.407154</td>\n",
       "      <td>1223.445190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 11:54:33,444] Trial 7 finished with value: 0.4071540134321787 and parameters: {'learning_rate': 5.857968696153527e-06, 'batch_size': 8, 'warmup_steps': 128, 'weight_decay': 0.010968217207529524}. Best is trial 2 with value: 0.5542756736310166.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2436' max='2520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2436/2520 01:09 < 00:02, 35.13 it/s, Epoch 29/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1736.424194</td>\n",
       "      <td>0.419297</td>\n",
       "      <td>0.147182</td>\n",
       "      <td>0.363942</td>\n",
       "      <td>1736.424316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1788.719400</td>\n",
       "      <td>1633.125732</td>\n",
       "      <td>0.406634</td>\n",
       "      <td>0.143505</td>\n",
       "      <td>0.368435</td>\n",
       "      <td>1633.125977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1755.481100</td>\n",
       "      <td>1467.799805</td>\n",
       "      <td>0.385503</td>\n",
       "      <td>0.167463</td>\n",
       "      <td>0.390980</td>\n",
       "      <td>1467.799805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1530.103100</td>\n",
       "      <td>1286.814819</td>\n",
       "      <td>0.360954</td>\n",
       "      <td>0.155350</td>\n",
       "      <td>0.397198</td>\n",
       "      <td>1286.814697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1287.680200</td>\n",
       "      <td>1148.482300</td>\n",
       "      <td>0.341002</td>\n",
       "      <td>0.157987</td>\n",
       "      <td>0.408493</td>\n",
       "      <td>1148.482300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1175.275200</td>\n",
       "      <td>1045.374146</td>\n",
       "      <td>0.325335</td>\n",
       "      <td>0.149888</td>\n",
       "      <td>0.412277</td>\n",
       "      <td>1045.374146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1175.275200</td>\n",
       "      <td>965.940674</td>\n",
       "      <td>0.312730</td>\n",
       "      <td>0.141377</td>\n",
       "      <td>0.414324</td>\n",
       "      <td>965.940674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1034.684400</td>\n",
       "      <td>903.547119</td>\n",
       "      <td>0.302461</td>\n",
       "      <td>0.145535</td>\n",
       "      <td>0.421537</td>\n",
       "      <td>903.547119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>933.670500</td>\n",
       "      <td>855.291992</td>\n",
       "      <td>0.294274</td>\n",
       "      <td>0.170985</td>\n",
       "      <td>0.438356</td>\n",
       "      <td>855.291931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>902.748700</td>\n",
       "      <td>817.133179</td>\n",
       "      <td>0.287634</td>\n",
       "      <td>0.205906</td>\n",
       "      <td>0.459136</td>\n",
       "      <td>817.133179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>859.458800</td>\n",
       "      <td>787.152527</td>\n",
       "      <td>0.282308</td>\n",
       "      <td>0.236300</td>\n",
       "      <td>0.476996</td>\n",
       "      <td>787.152527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>783.772300</td>\n",
       "      <td>764.722290</td>\n",
       "      <td>0.278257</td>\n",
       "      <td>0.199886</td>\n",
       "      <td>0.460814</td>\n",
       "      <td>764.722290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>783.772300</td>\n",
       "      <td>747.575317</td>\n",
       "      <td>0.275120</td>\n",
       "      <td>0.219591</td>\n",
       "      <td>0.472235</td>\n",
       "      <td>747.575317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>764.138700</td>\n",
       "      <td>734.896301</td>\n",
       "      <td>0.272777</td>\n",
       "      <td>0.245580</td>\n",
       "      <td>0.486402</td>\n",
       "      <td>734.896301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>768.216600</td>\n",
       "      <td>726.002991</td>\n",
       "      <td>0.271121</td>\n",
       "      <td>0.278822</td>\n",
       "      <td>0.503850</td>\n",
       "      <td>726.003052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>734.541100</td>\n",
       "      <td>719.723572</td>\n",
       "      <td>0.269946</td>\n",
       "      <td>0.267816</td>\n",
       "      <td>0.498935</td>\n",
       "      <td>719.723633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>726.205200</td>\n",
       "      <td>713.421814</td>\n",
       "      <td>0.268762</td>\n",
       "      <td>0.258416</td>\n",
       "      <td>0.494827</td>\n",
       "      <td>713.421814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>730.636300</td>\n",
       "      <td>710.032898</td>\n",
       "      <td>0.268123</td>\n",
       "      <td>0.285748</td>\n",
       "      <td>0.508813</td>\n",
       "      <td>710.032898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>730.636300</td>\n",
       "      <td>706.795044</td>\n",
       "      <td>0.267511</td>\n",
       "      <td>0.309196</td>\n",
       "      <td>0.520843</td>\n",
       "      <td>706.795105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>713.520500</td>\n",
       "      <td>704.784607</td>\n",
       "      <td>0.267130</td>\n",
       "      <td>0.307460</td>\n",
       "      <td>0.520165</td>\n",
       "      <td>704.784607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>711.385800</td>\n",
       "      <td>703.274109</td>\n",
       "      <td>0.266843</td>\n",
       "      <td>0.319716</td>\n",
       "      <td>0.526436</td>\n",
       "      <td>703.274109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>719.378900</td>\n",
       "      <td>702.059692</td>\n",
       "      <td>0.266613</td>\n",
       "      <td>0.331450</td>\n",
       "      <td>0.532418</td>\n",
       "      <td>702.059631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>720.729100</td>\n",
       "      <td>701.049683</td>\n",
       "      <td>0.266421</td>\n",
       "      <td>0.333718</td>\n",
       "      <td>0.533649</td>\n",
       "      <td>701.049683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>691.913400</td>\n",
       "      <td>700.256958</td>\n",
       "      <td>0.266270</td>\n",
       "      <td>0.338540</td>\n",
       "      <td>0.536135</td>\n",
       "      <td>700.256897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>714.016800</td>\n",
       "      <td>699.799255</td>\n",
       "      <td>0.266183</td>\n",
       "      <td>0.335805</td>\n",
       "      <td>0.534811</td>\n",
       "      <td>699.799194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>714.016800</td>\n",
       "      <td>699.412476</td>\n",
       "      <td>0.266110</td>\n",
       "      <td>0.337273</td>\n",
       "      <td>0.535581</td>\n",
       "      <td>699.412415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>699.847000</td>\n",
       "      <td>699.045837</td>\n",
       "      <td>0.266040</td>\n",
       "      <td>0.336657</td>\n",
       "      <td>0.535308</td>\n",
       "      <td>699.045837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>706.027300</td>\n",
       "      <td>698.836914</td>\n",
       "      <td>0.266000</td>\n",
       "      <td>0.336406</td>\n",
       "      <td>0.535203</td>\n",
       "      <td>698.836914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>719.992400</td>\n",
       "      <td>698.711365</td>\n",
       "      <td>0.265976</td>\n",
       "      <td>0.335039</td>\n",
       "      <td>0.534531</td>\n",
       "      <td>698.711304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 11:55:44,023] Trial 8 finished with value: 0.5361349938286719 and parameters: {'learning_rate': 6.199983918423047e-05, 'batch_size': 16, 'warmup_steps': 285, 'weight_decay': 0.06161049539380966}. Best is trial 2 with value: 0.5542756736310166.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1848' max='5040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1848/5040 00:40 < 01:09, 45.92 it/s, Epoch 11/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1731.396100</td>\n",
       "      <td>1376.577271</td>\n",
       "      <td>0.373331</td>\n",
       "      <td>0.112566</td>\n",
       "      <td>0.369617</td>\n",
       "      <td>1376.577393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1284.802600</td>\n",
       "      <td>1054.649414</td>\n",
       "      <td>0.326775</td>\n",
       "      <td>0.183711</td>\n",
       "      <td>0.428468</td>\n",
       "      <td>1054.649414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>951.137700</td>\n",
       "      <td>882.494507</td>\n",
       "      <td>0.298917</td>\n",
       "      <td>0.150091</td>\n",
       "      <td>0.425587</td>\n",
       "      <td>882.494507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>888.929500</td>\n",
       "      <td>791.712463</td>\n",
       "      <td>0.283125</td>\n",
       "      <td>0.150923</td>\n",
       "      <td>0.433899</td>\n",
       "      <td>791.712524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>773.052800</td>\n",
       "      <td>742.913025</td>\n",
       "      <td>0.274260</td>\n",
       "      <td>0.227123</td>\n",
       "      <td>0.476431</td>\n",
       "      <td>742.913025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>739.788100</td>\n",
       "      <td>718.402466</td>\n",
       "      <td>0.269698</td>\n",
       "      <td>0.325001</td>\n",
       "      <td>0.527651</td>\n",
       "      <td>718.402466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>751.048900</td>\n",
       "      <td>707.157104</td>\n",
       "      <td>0.267579</td>\n",
       "      <td>0.202402</td>\n",
       "      <td>0.467412</td>\n",
       "      <td>707.157166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>700.475000</td>\n",
       "      <td>700.780396</td>\n",
       "      <td>0.266370</td>\n",
       "      <td>0.316800</td>\n",
       "      <td>0.525215</td>\n",
       "      <td>700.780396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>712.533200</td>\n",
       "      <td>697.090576</td>\n",
       "      <td>0.265668</td>\n",
       "      <td>0.311932</td>\n",
       "      <td>0.523132</td>\n",
       "      <td>697.090576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>699.072000</td>\n",
       "      <td>670.759094</td>\n",
       "      <td>0.260602</td>\n",
       "      <td>0.254701</td>\n",
       "      <td>0.497050</td>\n",
       "      <td>670.759094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>710.743000</td>\n",
       "      <td>658.722595</td>\n",
       "      <td>0.258253</td>\n",
       "      <td>0.279476</td>\n",
       "      <td>0.510611</td>\n",
       "      <td>658.722534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 11:56:25,614] Trial 9 finished with value: 0.5276512176746114 and parameters: {'learning_rate': 7.848198194330569e-05, 'batch_size': 8, 'warmup_steps': 61, 'weight_decay': 0.004473636174621266}. Best is trial 2 with value: 0.5542756736310166.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='840' max='1260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 840/1260 00:35 < 00:17, 23.55 it/s, Epoch 20/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1684.407837</td>\n",
       "      <td>0.412969</td>\n",
       "      <td>0.066782</td>\n",
       "      <td>0.326906</td>\n",
       "      <td>1684.407837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1430.703491</td>\n",
       "      <td>0.380600</td>\n",
       "      <td>0.084813</td>\n",
       "      <td>0.352107</td>\n",
       "      <td>1430.703613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1676.771100</td>\n",
       "      <td>1131.373047</td>\n",
       "      <td>0.338452</td>\n",
       "      <td>0.085654</td>\n",
       "      <td>0.373601</td>\n",
       "      <td>1131.373169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1676.771100</td>\n",
       "      <td>891.211121</td>\n",
       "      <td>0.300389</td>\n",
       "      <td>0.014789</td>\n",
       "      <td>0.357200</td>\n",
       "      <td>891.211121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1030.235400</td>\n",
       "      <td>736.628723</td>\n",
       "      <td>0.273098</td>\n",
       "      <td>0.209723</td>\n",
       "      <td>0.468313</td>\n",
       "      <td>736.628723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1030.235400</td>\n",
       "      <td>695.620483</td>\n",
       "      <td>0.265387</td>\n",
       "      <td>0.273083</td>\n",
       "      <td>0.503848</td>\n",
       "      <td>695.620483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1030.235400</td>\n",
       "      <td>689.444458</td>\n",
       "      <td>0.264207</td>\n",
       "      <td>0.247884</td>\n",
       "      <td>0.491838</td>\n",
       "      <td>689.444458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>720.780300</td>\n",
       "      <td>649.796570</td>\n",
       "      <td>0.256497</td>\n",
       "      <td>0.276673</td>\n",
       "      <td>0.510088</td>\n",
       "      <td>649.796570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>720.780300</td>\n",
       "      <td>645.217407</td>\n",
       "      <td>0.255592</td>\n",
       "      <td>0.291813</td>\n",
       "      <td>0.518111</td>\n",
       "      <td>645.217468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>659.789600</td>\n",
       "      <td>626.289062</td>\n",
       "      <td>0.251815</td>\n",
       "      <td>0.326111</td>\n",
       "      <td>0.537148</td>\n",
       "      <td>626.289124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>659.789600</td>\n",
       "      <td>627.667114</td>\n",
       "      <td>0.252092</td>\n",
       "      <td>0.323334</td>\n",
       "      <td>0.535621</td>\n",
       "      <td>627.667053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>593.986800</td>\n",
       "      <td>620.728699</td>\n",
       "      <td>0.250695</td>\n",
       "      <td>0.355644</td>\n",
       "      <td>0.552474</td>\n",
       "      <td>620.728638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>593.986800</td>\n",
       "      <td>637.119263</td>\n",
       "      <td>0.253983</td>\n",
       "      <td>0.334027</td>\n",
       "      <td>0.540022</td>\n",
       "      <td>637.119263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>593.986800</td>\n",
       "      <td>638.126038</td>\n",
       "      <td>0.254184</td>\n",
       "      <td>0.373377</td>\n",
       "      <td>0.559597</td>\n",
       "      <td>638.126038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>511.313600</td>\n",
       "      <td>594.377502</td>\n",
       "      <td>0.245316</td>\n",
       "      <td>0.391210</td>\n",
       "      <td>0.572947</td>\n",
       "      <td>594.377502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>511.313600</td>\n",
       "      <td>637.691956</td>\n",
       "      <td>0.254097</td>\n",
       "      <td>0.382466</td>\n",
       "      <td>0.564185</td>\n",
       "      <td>637.691956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>437.277600</td>\n",
       "      <td>695.258972</td>\n",
       "      <td>0.265319</td>\n",
       "      <td>0.358510</td>\n",
       "      <td>0.546596</td>\n",
       "      <td>695.258911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>437.277600</td>\n",
       "      <td>667.696350</td>\n",
       "      <td>0.260006</td>\n",
       "      <td>0.341975</td>\n",
       "      <td>0.540985</td>\n",
       "      <td>667.696350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>437.277600</td>\n",
       "      <td>639.180237</td>\n",
       "      <td>0.254393</td>\n",
       "      <td>0.366753</td>\n",
       "      <td>0.556180</td>\n",
       "      <td>639.180237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>392.042700</td>\n",
       "      <td>678.276550</td>\n",
       "      <td>0.262058</td>\n",
       "      <td>0.358714</td>\n",
       "      <td>0.548328</td>\n",
       "      <td>678.276550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 11:57:02,499] Trial 10 finished with value: 0.5729473745443601 and parameters: {'learning_rate': 0.00045181656815872543, 'batch_size': 32, 'warmup_steps': 208, 'weight_decay': 0.022005828785027447}. Best is trial 10 with value: 0.5729473745443601.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='798' max='1260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 798/1260 00:33 < 00:19, 23.48 it/s, Epoch 19/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1682.062256</td>\n",
       "      <td>0.412682</td>\n",
       "      <td>0.169037</td>\n",
       "      <td>0.378178</td>\n",
       "      <td>1682.062256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1428.466797</td>\n",
       "      <td>0.380303</td>\n",
       "      <td>0.120611</td>\n",
       "      <td>0.370154</td>\n",
       "      <td>1428.466675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1674.417500</td>\n",
       "      <td>1129.069092</td>\n",
       "      <td>0.338107</td>\n",
       "      <td>0.083786</td>\n",
       "      <td>0.372839</td>\n",
       "      <td>1129.069092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1674.417500</td>\n",
       "      <td>891.125366</td>\n",
       "      <td>0.300375</td>\n",
       "      <td>0.063464</td>\n",
       "      <td>0.381545</td>\n",
       "      <td>891.125366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1028.767400</td>\n",
       "      <td>736.797119</td>\n",
       "      <td>0.273129</td>\n",
       "      <td>0.047764</td>\n",
       "      <td>0.387318</td>\n",
       "      <td>736.797119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1028.767400</td>\n",
       "      <td>695.536133</td>\n",
       "      <td>0.265371</td>\n",
       "      <td>0.258016</td>\n",
       "      <td>0.496322</td>\n",
       "      <td>695.536072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1028.767400</td>\n",
       "      <td>735.100464</td>\n",
       "      <td>0.272815</td>\n",
       "      <td>0.301780</td>\n",
       "      <td>0.514483</td>\n",
       "      <td>735.100464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>720.480200</td>\n",
       "      <td>656.661621</td>\n",
       "      <td>0.257849</td>\n",
       "      <td>0.242709</td>\n",
       "      <td>0.492430</td>\n",
       "      <td>656.661621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>720.480200</td>\n",
       "      <td>639.287842</td>\n",
       "      <td>0.254415</td>\n",
       "      <td>0.292860</td>\n",
       "      <td>0.519223</td>\n",
       "      <td>639.287842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>642.014400</td>\n",
       "      <td>622.300049</td>\n",
       "      <td>0.251012</td>\n",
       "      <td>0.338211</td>\n",
       "      <td>0.543600</td>\n",
       "      <td>622.300049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>642.014400</td>\n",
       "      <td>650.825745</td>\n",
       "      <td>0.256700</td>\n",
       "      <td>0.274599</td>\n",
       "      <td>0.508949</td>\n",
       "      <td>650.825684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>589.591700</td>\n",
       "      <td>658.096558</td>\n",
       "      <td>0.258130</td>\n",
       "      <td>0.327521</td>\n",
       "      <td>0.534695</td>\n",
       "      <td>658.096558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>589.591700</td>\n",
       "      <td>644.599426</td>\n",
       "      <td>0.255470</td>\n",
       "      <td>0.292717</td>\n",
       "      <td>0.518624</td>\n",
       "      <td>644.599426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>589.591700</td>\n",
       "      <td>662.778809</td>\n",
       "      <td>0.259047</td>\n",
       "      <td>0.352611</td>\n",
       "      <td>0.546782</td>\n",
       "      <td>662.778809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>494.240900</td>\n",
       "      <td>666.776917</td>\n",
       "      <td>0.259827</td>\n",
       "      <td>0.301578</td>\n",
       "      <td>0.520876</td>\n",
       "      <td>666.776855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>494.240900</td>\n",
       "      <td>711.587280</td>\n",
       "      <td>0.268416</td>\n",
       "      <td>0.272472</td>\n",
       "      <td>0.502028</td>\n",
       "      <td>711.587280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>408.908000</td>\n",
       "      <td>719.431396</td>\n",
       "      <td>0.269891</td>\n",
       "      <td>0.270856</td>\n",
       "      <td>0.500482</td>\n",
       "      <td>719.431396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>408.908000</td>\n",
       "      <td>707.200317</td>\n",
       "      <td>0.267587</td>\n",
       "      <td>0.274236</td>\n",
       "      <td>0.503324</td>\n",
       "      <td>707.200317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>408.908000</td>\n",
       "      <td>732.995483</td>\n",
       "      <td>0.272424</td>\n",
       "      <td>0.270057</td>\n",
       "      <td>0.498816</td>\n",
       "      <td>732.995483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 11:57:37,691] Trial 11 finished with value: 0.5467822452041422 and parameters: {'learning_rate': 0.0004616775462768299, 'batch_size': 32, 'warmup_steps': 211, 'weight_decay': 0.02887352724952181}. Best is trial 10 with value: 0.5729473745443601.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='798' max='1260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 798/1260 00:33 < 00:19, 23.61 it/s, Epoch 19/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1697.440063</td>\n",
       "      <td>0.414564</td>\n",
       "      <td>0.176621</td>\n",
       "      <td>0.381029</td>\n",
       "      <td>1697.440063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1468.130615</td>\n",
       "      <td>0.385546</td>\n",
       "      <td>0.101208</td>\n",
       "      <td>0.357831</td>\n",
       "      <td>1468.130493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1696.129100</td>\n",
       "      <td>1182.462036</td>\n",
       "      <td>0.346009</td>\n",
       "      <td>0.111835</td>\n",
       "      <td>0.382913</td>\n",
       "      <td>1182.462036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1696.129100</td>\n",
       "      <td>944.516663</td>\n",
       "      <td>0.309242</td>\n",
       "      <td>0.115215</td>\n",
       "      <td>0.402986</td>\n",
       "      <td>944.516602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1084.323000</td>\n",
       "      <td>776.124390</td>\n",
       "      <td>0.280324</td>\n",
       "      <td>0.116343</td>\n",
       "      <td>0.418010</td>\n",
       "      <td>776.124329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1084.323000</td>\n",
       "      <td>701.127197</td>\n",
       "      <td>0.266436</td>\n",
       "      <td>0.098596</td>\n",
       "      <td>0.416080</td>\n",
       "      <td>701.127197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1084.323000</td>\n",
       "      <td>694.861572</td>\n",
       "      <td>0.265243</td>\n",
       "      <td>0.305442</td>\n",
       "      <td>0.520099</td>\n",
       "      <td>694.861572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>738.963200</td>\n",
       "      <td>683.485535</td>\n",
       "      <td>0.263062</td>\n",
       "      <td>0.171556</td>\n",
       "      <td>0.454247</td>\n",
       "      <td>683.485474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>738.963200</td>\n",
       "      <td>640.811523</td>\n",
       "      <td>0.254718</td>\n",
       "      <td>0.336790</td>\n",
       "      <td>0.541036</td>\n",
       "      <td>640.811462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>676.950900</td>\n",
       "      <td>638.029785</td>\n",
       "      <td>0.254164</td>\n",
       "      <td>0.313171</td>\n",
       "      <td>0.529503</td>\n",
       "      <td>638.029785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>676.950900</td>\n",
       "      <td>644.966614</td>\n",
       "      <td>0.255542</td>\n",
       "      <td>0.274623</td>\n",
       "      <td>0.509540</td>\n",
       "      <td>644.966614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>617.253700</td>\n",
       "      <td>629.205383</td>\n",
       "      <td>0.252401</td>\n",
       "      <td>0.320336</td>\n",
       "      <td>0.533968</td>\n",
       "      <td>629.205383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>617.253700</td>\n",
       "      <td>692.832153</td>\n",
       "      <td>0.264855</td>\n",
       "      <td>0.297145</td>\n",
       "      <td>0.516145</td>\n",
       "      <td>692.832153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>617.253700</td>\n",
       "      <td>635.507996</td>\n",
       "      <td>0.253662</td>\n",
       "      <td>0.351323</td>\n",
       "      <td>0.548831</td>\n",
       "      <td>635.507996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>523.850300</td>\n",
       "      <td>631.861572</td>\n",
       "      <td>0.252933</td>\n",
       "      <td>0.317520</td>\n",
       "      <td>0.532293</td>\n",
       "      <td>631.861572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>523.850300</td>\n",
       "      <td>677.529907</td>\n",
       "      <td>0.261914</td>\n",
       "      <td>0.317416</td>\n",
       "      <td>0.527751</td>\n",
       "      <td>677.529907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>455.130200</td>\n",
       "      <td>671.110657</td>\n",
       "      <td>0.260670</td>\n",
       "      <td>0.319489</td>\n",
       "      <td>0.529409</td>\n",
       "      <td>671.110596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>455.130200</td>\n",
       "      <td>703.300354</td>\n",
       "      <td>0.266848</td>\n",
       "      <td>0.265327</td>\n",
       "      <td>0.499239</td>\n",
       "      <td>703.300415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>455.130200</td>\n",
       "      <td>697.485657</td>\n",
       "      <td>0.265743</td>\n",
       "      <td>0.298043</td>\n",
       "      <td>0.516150</td>\n",
       "      <td>697.485718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 11:58:12,715] Trial 12 finished with value: 0.5488307118154415 and parameters: {'learning_rate': 0.00043204035227877843, 'batch_size': 32, 'warmup_steps': 230, 'weight_decay': 0.01717548248900738}. Best is trial 10 with value: 0.5729473745443601.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='840' max='1260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 840/1260 00:35 < 00:17, 23.45 it/s, Epoch 20/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1717.906372</td>\n",
       "      <td>0.417056</td>\n",
       "      <td>0.182048</td>\n",
       "      <td>0.382496</td>\n",
       "      <td>1717.906494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1548.214966</td>\n",
       "      <td>0.395922</td>\n",
       "      <td>0.135362</td>\n",
       "      <td>0.369720</td>\n",
       "      <td>1548.215088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1733.563400</td>\n",
       "      <td>1310.941895</td>\n",
       "      <td>0.364322</td>\n",
       "      <td>0.124329</td>\n",
       "      <td>0.380003</td>\n",
       "      <td>1310.941895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1733.563400</td>\n",
       "      <td>1089.187622</td>\n",
       "      <td>0.332082</td>\n",
       "      <td>0.124518</td>\n",
       "      <td>0.396218</td>\n",
       "      <td>1089.187744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1228.267900</td>\n",
       "      <td>942.072266</td>\n",
       "      <td>0.308842</td>\n",
       "      <td>0.108722</td>\n",
       "      <td>0.399940</td>\n",
       "      <td>942.072327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1228.267900</td>\n",
       "      <td>842.822693</td>\n",
       "      <td>0.292121</td>\n",
       "      <td>0.082995</td>\n",
       "      <td>0.395437</td>\n",
       "      <td>842.822510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1228.267900</td>\n",
       "      <td>775.412109</td>\n",
       "      <td>0.280195</td>\n",
       "      <td>0.137748</td>\n",
       "      <td>0.428776</td>\n",
       "      <td>775.412109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>890.652100</td>\n",
       "      <td>732.786926</td>\n",
       "      <td>0.272385</td>\n",
       "      <td>0.204800</td>\n",
       "      <td>0.466207</td>\n",
       "      <td>732.786987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>890.652100</td>\n",
       "      <td>711.997559</td>\n",
       "      <td>0.268493</td>\n",
       "      <td>0.193529</td>\n",
       "      <td>0.462518</td>\n",
       "      <td>711.997681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>738.381600</td>\n",
       "      <td>700.330872</td>\n",
       "      <td>0.266284</td>\n",
       "      <td>0.210061</td>\n",
       "      <td>0.471888</td>\n",
       "      <td>700.330872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>738.381600</td>\n",
       "      <td>696.635132</td>\n",
       "      <td>0.265581</td>\n",
       "      <td>0.331513</td>\n",
       "      <td>0.532966</td>\n",
       "      <td>696.635132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>708.810400</td>\n",
       "      <td>695.051025</td>\n",
       "      <td>0.265279</td>\n",
       "      <td>0.326998</td>\n",
       "      <td>0.530860</td>\n",
       "      <td>695.050964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>708.810400</td>\n",
       "      <td>674.557129</td>\n",
       "      <td>0.261339</td>\n",
       "      <td>0.262704</td>\n",
       "      <td>0.500682</td>\n",
       "      <td>674.557129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>708.810400</td>\n",
       "      <td>649.534607</td>\n",
       "      <td>0.256446</td>\n",
       "      <td>0.324432</td>\n",
       "      <td>0.533993</td>\n",
       "      <td>649.534607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>683.581200</td>\n",
       "      <td>651.590942</td>\n",
       "      <td>0.256851</td>\n",
       "      <td>0.352929</td>\n",
       "      <td>0.548039</td>\n",
       "      <td>651.590942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>683.581200</td>\n",
       "      <td>638.516296</td>\n",
       "      <td>0.254261</td>\n",
       "      <td>0.329804</td>\n",
       "      <td>0.537771</td>\n",
       "      <td>638.516296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>633.310400</td>\n",
       "      <td>650.765320</td>\n",
       "      <td>0.256689</td>\n",
       "      <td>0.350399</td>\n",
       "      <td>0.546855</td>\n",
       "      <td>650.765320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>633.310400</td>\n",
       "      <td>647.396301</td>\n",
       "      <td>0.256023</td>\n",
       "      <td>0.330695</td>\n",
       "      <td>0.537336</td>\n",
       "      <td>647.396301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>633.310400</td>\n",
       "      <td>640.650391</td>\n",
       "      <td>0.254686</td>\n",
       "      <td>0.340382</td>\n",
       "      <td>0.542848</td>\n",
       "      <td>640.650391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>589.968500</td>\n",
       "      <td>656.995667</td>\n",
       "      <td>0.257914</td>\n",
       "      <td>0.302671</td>\n",
       "      <td>0.522378</td>\n",
       "      <td>656.995667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 11:58:49,732] Trial 13 finished with value: 0.5480390711924561 and parameters: {'learning_rate': 0.0001974755883490512, 'batch_size': 32, 'warmup_steps': 148, 'weight_decay': 0.02106510528632681}. Best is trial 10 with value: 0.5729473745443601.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='840' max='1260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 840/1260 00:35 < 00:17, 23.72 it/s, Epoch 20/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1714.748901</td>\n",
       "      <td>0.416672</td>\n",
       "      <td>0.174747</td>\n",
       "      <td>0.379037</td>\n",
       "      <td>1714.749023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1550.485474</td>\n",
       "      <td>0.396212</td>\n",
       "      <td>0.141747</td>\n",
       "      <td>0.372767</td>\n",
       "      <td>1550.485474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1732.077300</td>\n",
       "      <td>1319.015625</td>\n",
       "      <td>0.365443</td>\n",
       "      <td>0.100930</td>\n",
       "      <td>0.367744</td>\n",
       "      <td>1319.015625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1732.077300</td>\n",
       "      <td>1092.893433</td>\n",
       "      <td>0.332647</td>\n",
       "      <td>0.066779</td>\n",
       "      <td>0.367066</td>\n",
       "      <td>1092.893555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1231.528300</td>\n",
       "      <td>927.729309</td>\n",
       "      <td>0.306482</td>\n",
       "      <td>0.041627</td>\n",
       "      <td>0.367573</td>\n",
       "      <td>927.729431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1231.528300</td>\n",
       "      <td>821.109253</td>\n",
       "      <td>0.288333</td>\n",
       "      <td>0.084932</td>\n",
       "      <td>0.398300</td>\n",
       "      <td>821.109131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1231.528300</td>\n",
       "      <td>753.215393</td>\n",
       "      <td>0.276156</td>\n",
       "      <td>0.191624</td>\n",
       "      <td>0.457734</td>\n",
       "      <td>753.215393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>868.903700</td>\n",
       "      <td>716.159241</td>\n",
       "      <td>0.269277</td>\n",
       "      <td>0.221302</td>\n",
       "      <td>0.476013</td>\n",
       "      <td>716.159241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>868.903700</td>\n",
       "      <td>702.165710</td>\n",
       "      <td>0.266633</td>\n",
       "      <td>0.225781</td>\n",
       "      <td>0.479574</td>\n",
       "      <td>702.165710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>721.131300</td>\n",
       "      <td>696.261597</td>\n",
       "      <td>0.265510</td>\n",
       "      <td>0.344699</td>\n",
       "      <td>0.539595</td>\n",
       "      <td>696.261597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>721.131300</td>\n",
       "      <td>693.820312</td>\n",
       "      <td>0.265044</td>\n",
       "      <td>0.336072</td>\n",
       "      <td>0.535514</td>\n",
       "      <td>693.820312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>699.238700</td>\n",
       "      <td>657.829102</td>\n",
       "      <td>0.258078</td>\n",
       "      <td>0.259194</td>\n",
       "      <td>0.500558</td>\n",
       "      <td>657.829102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>699.238700</td>\n",
       "      <td>651.035889</td>\n",
       "      <td>0.256742</td>\n",
       "      <td>0.269213</td>\n",
       "      <td>0.506235</td>\n",
       "      <td>651.035950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>699.238700</td>\n",
       "      <td>638.980042</td>\n",
       "      <td>0.254354</td>\n",
       "      <td>0.322063</td>\n",
       "      <td>0.533855</td>\n",
       "      <td>638.980042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>644.135500</td>\n",
       "      <td>649.620300</td>\n",
       "      <td>0.256463</td>\n",
       "      <td>0.342338</td>\n",
       "      <td>0.542938</td>\n",
       "      <td>649.620300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>644.135500</td>\n",
       "      <td>641.476929</td>\n",
       "      <td>0.254850</td>\n",
       "      <td>0.296271</td>\n",
       "      <td>0.520710</td>\n",
       "      <td>641.476929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>581.971700</td>\n",
       "      <td>661.278503</td>\n",
       "      <td>0.258754</td>\n",
       "      <td>0.327252</td>\n",
       "      <td>0.534249</td>\n",
       "      <td>661.278503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>581.971700</td>\n",
       "      <td>654.134460</td>\n",
       "      <td>0.257352</td>\n",
       "      <td>0.312186</td>\n",
       "      <td>0.527417</td>\n",
       "      <td>654.134460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>581.971700</td>\n",
       "      <td>660.001160</td>\n",
       "      <td>0.258504</td>\n",
       "      <td>0.288522</td>\n",
       "      <td>0.515009</td>\n",
       "      <td>660.001099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>537.199500</td>\n",
       "      <td>682.147644</td>\n",
       "      <td>0.262805</td>\n",
       "      <td>0.300011</td>\n",
       "      <td>0.518603</td>\n",
       "      <td>682.147705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 11:59:26,323] Trial 14 finished with value: 0.5429378777008194 and parameters: {'learning_rate': 0.00022367873502150072, 'batch_size': 32, 'warmup_steps': 169, 'weight_decay': 0.005959206131645764}. Best is trial 10 with value: 0.5729473745443601.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2184' max='5040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2184/5040 00:47 < 01:02, 45.84 it/s, Epoch 13/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1749.002700</td>\n",
       "      <td>1345.051514</td>\n",
       "      <td>0.369032</td>\n",
       "      <td>0.111572</td>\n",
       "      <td>0.371270</td>\n",
       "      <td>1345.051392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1102.175500</td>\n",
       "      <td>819.243896</td>\n",
       "      <td>0.288006</td>\n",
       "      <td>0.050648</td>\n",
       "      <td>0.381321</td>\n",
       "      <td>819.243896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>736.149100</td>\n",
       "      <td>708.736267</td>\n",
       "      <td>0.267878</td>\n",
       "      <td>0.255974</td>\n",
       "      <td>0.494048</td>\n",
       "      <td>708.736267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>712.415800</td>\n",
       "      <td>676.041199</td>\n",
       "      <td>0.261626</td>\n",
       "      <td>0.262817</td>\n",
       "      <td>0.500595</td>\n",
       "      <td>676.041199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>667.885900</td>\n",
       "      <td>650.791016</td>\n",
       "      <td>0.256694</td>\n",
       "      <td>0.284261</td>\n",
       "      <td>0.513784</td>\n",
       "      <td>650.791016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>629.881100</td>\n",
       "      <td>643.199463</td>\n",
       "      <td>0.255192</td>\n",
       "      <td>0.308773</td>\n",
       "      <td>0.526791</td>\n",
       "      <td>643.199463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>628.045700</td>\n",
       "      <td>663.251831</td>\n",
       "      <td>0.259139</td>\n",
       "      <td>0.294264</td>\n",
       "      <td>0.517562</td>\n",
       "      <td>663.251831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>560.578400</td>\n",
       "      <td>623.070007</td>\n",
       "      <td>0.251167</td>\n",
       "      <td>0.357374</td>\n",
       "      <td>0.553104</td>\n",
       "      <td>623.070007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>560.570400</td>\n",
       "      <td>675.004517</td>\n",
       "      <td>0.261425</td>\n",
       "      <td>0.313988</td>\n",
       "      <td>0.526281</td>\n",
       "      <td>675.004578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>504.728700</td>\n",
       "      <td>647.720947</td>\n",
       "      <td>0.256087</td>\n",
       "      <td>0.302943</td>\n",
       "      <td>0.523428</td>\n",
       "      <td>647.720947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>497.664800</td>\n",
       "      <td>657.581116</td>\n",
       "      <td>0.258029</td>\n",
       "      <td>0.305467</td>\n",
       "      <td>0.523719</td>\n",
       "      <td>657.581238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>457.825400</td>\n",
       "      <td>655.429321</td>\n",
       "      <td>0.257607</td>\n",
       "      <td>0.324203</td>\n",
       "      <td>0.533298</td>\n",
       "      <td>655.429321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>427.894000</td>\n",
       "      <td>710.916443</td>\n",
       "      <td>0.268289</td>\n",
       "      <td>0.292345</td>\n",
       "      <td>0.512028</td>\n",
       "      <td>710.916443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 12:00:15,290] Trial 15 finished with value: 0.5531035032518639 and parameters: {'learning_rate': 0.00019138534035817448, 'batch_size': 8, 'warmup_steps': 245, 'weight_decay': 0.013230460335438466}. Best is trial 10 with value: 0.5729473745443601.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='966' max='1260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 966/1260 00:40 < 00:12, 23.53 it/s, Epoch 23/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1737.880371</td>\n",
       "      <td>0.419473</td>\n",
       "      <td>0.218993</td>\n",
       "      <td>0.399760</td>\n",
       "      <td>1737.880615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1654.497803</td>\n",
       "      <td>0.409286</td>\n",
       "      <td>0.170963</td>\n",
       "      <td>0.380838</td>\n",
       "      <td>1654.497803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1780.571600</td>\n",
       "      <td>1513.342529</td>\n",
       "      <td>0.391438</td>\n",
       "      <td>0.162206</td>\n",
       "      <td>0.385384</td>\n",
       "      <td>1513.342529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1780.571600</td>\n",
       "      <td>1345.449951</td>\n",
       "      <td>0.369086</td>\n",
       "      <td>0.124844</td>\n",
       "      <td>0.377879</td>\n",
       "      <td>1345.449829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1459.900200</td>\n",
       "      <td>1186.898682</td>\n",
       "      <td>0.346658</td>\n",
       "      <td>0.156518</td>\n",
       "      <td>0.404930</td>\n",
       "      <td>1186.898804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1459.900200</td>\n",
       "      <td>1070.094360</td>\n",
       "      <td>0.329159</td>\n",
       "      <td>0.135671</td>\n",
       "      <td>0.403256</td>\n",
       "      <td>1070.094360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1459.900200</td>\n",
       "      <td>981.923706</td>\n",
       "      <td>0.315307</td>\n",
       "      <td>0.158313</td>\n",
       "      <td>0.421503</td>\n",
       "      <td>981.923584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1133.430500</td>\n",
       "      <td>913.040588</td>\n",
       "      <td>0.304046</td>\n",
       "      <td>0.153848</td>\n",
       "      <td>0.424901</td>\n",
       "      <td>913.040588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1133.430500</td>\n",
       "      <td>858.598877</td>\n",
       "      <td>0.294842</td>\n",
       "      <td>0.132910</td>\n",
       "      <td>0.419034</td>\n",
       "      <td>858.598877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>925.944900</td>\n",
       "      <td>815.318176</td>\n",
       "      <td>0.287315</td>\n",
       "      <td>0.132093</td>\n",
       "      <td>0.422389</td>\n",
       "      <td>815.318054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>925.944900</td>\n",
       "      <td>781.260376</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.189312</td>\n",
       "      <td>0.454031</td>\n",
       "      <td>781.260376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>817.066700</td>\n",
       "      <td>755.535400</td>\n",
       "      <td>0.276581</td>\n",
       "      <td>0.187338</td>\n",
       "      <td>0.455379</td>\n",
       "      <td>755.535522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>817.066700</td>\n",
       "      <td>735.514832</td>\n",
       "      <td>0.272891</td>\n",
       "      <td>0.158546</td>\n",
       "      <td>0.442827</td>\n",
       "      <td>735.514832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>817.066700</td>\n",
       "      <td>721.534973</td>\n",
       "      <td>0.270286</td>\n",
       "      <td>0.168276</td>\n",
       "      <td>0.448995</td>\n",
       "      <td>721.534973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>753.472500</td>\n",
       "      <td>712.543335</td>\n",
       "      <td>0.268596</td>\n",
       "      <td>0.264200</td>\n",
       "      <td>0.497802</td>\n",
       "      <td>712.543335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>753.472500</td>\n",
       "      <td>706.995056</td>\n",
       "      <td>0.267548</td>\n",
       "      <td>0.293300</td>\n",
       "      <td>0.512876</td>\n",
       "      <td>706.995056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>714.904100</td>\n",
       "      <td>702.212708</td>\n",
       "      <td>0.266642</td>\n",
       "      <td>0.310841</td>\n",
       "      <td>0.522099</td>\n",
       "      <td>702.212830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>714.904100</td>\n",
       "      <td>699.781555</td>\n",
       "      <td>0.266180</td>\n",
       "      <td>0.345928</td>\n",
       "      <td>0.539874</td>\n",
       "      <td>699.781555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>714.904100</td>\n",
       "      <td>698.140320</td>\n",
       "      <td>0.265868</td>\n",
       "      <td>0.331563</td>\n",
       "      <td>0.532848</td>\n",
       "      <td>698.140320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>708.307000</td>\n",
       "      <td>697.047668</td>\n",
       "      <td>0.265660</td>\n",
       "      <td>0.312068</td>\n",
       "      <td>0.523204</td>\n",
       "      <td>697.047668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>708.307000</td>\n",
       "      <td>696.331116</td>\n",
       "      <td>0.265523</td>\n",
       "      <td>0.314103</td>\n",
       "      <td>0.524290</td>\n",
       "      <td>696.331116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>705.387400</td>\n",
       "      <td>695.792480</td>\n",
       "      <td>0.265420</td>\n",
       "      <td>0.300028</td>\n",
       "      <td>0.517304</td>\n",
       "      <td>695.792419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>705.387400</td>\n",
       "      <td>672.543701</td>\n",
       "      <td>0.260948</td>\n",
       "      <td>0.294465</td>\n",
       "      <td>0.516758</td>\n",
       "      <td>672.543701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 12:00:57,622] Trial 16 finished with value: 0.5398737612215192 and parameters: {'learning_rate': 0.00012626855053237253, 'batch_size': 32, 'warmup_steps': 179, 'weight_decay': 0.03619983114641091}. Best is trial 10 with value: 0.5729473745443601.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1848' max='5040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1848/5040 00:40 < 01:09, 45.71 it/s, Epoch 11/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1713.483400</td>\n",
       "      <td>1101.874878</td>\n",
       "      <td>0.334011</td>\n",
       "      <td>0.160615</td>\n",
       "      <td>0.413302</td>\n",
       "      <td>1101.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>864.178600</td>\n",
       "      <td>707.856750</td>\n",
       "      <td>0.267711</td>\n",
       "      <td>0.318678</td>\n",
       "      <td>0.525483</td>\n",
       "      <td>707.856750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>696.802500</td>\n",
       "      <td>676.396057</td>\n",
       "      <td>0.261695</td>\n",
       "      <td>0.261190</td>\n",
       "      <td>0.499748</td>\n",
       "      <td>676.396057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>662.406400</td>\n",
       "      <td>645.578125</td>\n",
       "      <td>0.255663</td>\n",
       "      <td>0.296730</td>\n",
       "      <td>0.520533</td>\n",
       "      <td>645.578186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>652.044900</td>\n",
       "      <td>639.648621</td>\n",
       "      <td>0.254487</td>\n",
       "      <td>0.326290</td>\n",
       "      <td>0.535902</td>\n",
       "      <td>639.648621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>594.754900</td>\n",
       "      <td>634.649963</td>\n",
       "      <td>0.253490</td>\n",
       "      <td>0.368362</td>\n",
       "      <td>0.557436</td>\n",
       "      <td>634.649963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>573.412000</td>\n",
       "      <td>634.898376</td>\n",
       "      <td>0.253540</td>\n",
       "      <td>0.350273</td>\n",
       "      <td>0.548367</td>\n",
       "      <td>634.898438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>516.000500</td>\n",
       "      <td>715.247375</td>\n",
       "      <td>0.269105</td>\n",
       "      <td>0.232968</td>\n",
       "      <td>0.481931</td>\n",
       "      <td>715.247375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>496.797700</td>\n",
       "      <td>724.259338</td>\n",
       "      <td>0.270795</td>\n",
       "      <td>0.305719</td>\n",
       "      <td>0.517462</td>\n",
       "      <td>724.259277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>424.613700</td>\n",
       "      <td>720.834595</td>\n",
       "      <td>0.270154</td>\n",
       "      <td>0.347421</td>\n",
       "      <td>0.538634</td>\n",
       "      <td>720.834595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>409.585000</td>\n",
       "      <td>702.531433</td>\n",
       "      <td>0.266703</td>\n",
       "      <td>0.280063</td>\n",
       "      <td>0.506680</td>\n",
       "      <td>702.531433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 12:01:39,456] Trial 17 finished with value: 0.5574358383182196 and parameters: {'learning_rate': 0.00035169237047489205, 'batch_size': 8, 'warmup_steps': 253, 'weight_decay': 0.0036025945530639577}. Best is trial 10 with value: 0.5729473745443601.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='840' max='1260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 840/1260 00:37 < 00:18, 22.51 it/s, Epoch 20/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1718.131348</td>\n",
       "      <td>0.417083</td>\n",
       "      <td>0.116299</td>\n",
       "      <td>0.349608</td>\n",
       "      <td>1718.131348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1550.382324</td>\n",
       "      <td>0.396199</td>\n",
       "      <td>0.083173</td>\n",
       "      <td>0.343487</td>\n",
       "      <td>1550.382446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1733.941400</td>\n",
       "      <td>1321.979004</td>\n",
       "      <td>0.365853</td>\n",
       "      <td>0.086032</td>\n",
       "      <td>0.360089</td>\n",
       "      <td>1321.979004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1733.941400</td>\n",
       "      <td>1094.443970</td>\n",
       "      <td>0.332883</td>\n",
       "      <td>0.032092</td>\n",
       "      <td>0.349605</td>\n",
       "      <td>1094.444092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1232.463000</td>\n",
       "      <td>909.430481</td>\n",
       "      <td>0.303444</td>\n",
       "      <td>0.188056</td>\n",
       "      <td>0.442306</td>\n",
       "      <td>909.430481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1232.463000</td>\n",
       "      <td>774.195190</td>\n",
       "      <td>0.279975</td>\n",
       "      <td>0.186414</td>\n",
       "      <td>0.453219</td>\n",
       "      <td>774.195129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1232.463000</td>\n",
       "      <td>707.333557</td>\n",
       "      <td>0.267612</td>\n",
       "      <td>0.193861</td>\n",
       "      <td>0.463124</td>\n",
       "      <td>707.333557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>826.375200</td>\n",
       "      <td>695.548584</td>\n",
       "      <td>0.265374</td>\n",
       "      <td>0.281107</td>\n",
       "      <td>0.507867</td>\n",
       "      <td>695.548523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>826.375200</td>\n",
       "      <td>693.916931</td>\n",
       "      <td>0.265062</td>\n",
       "      <td>0.303959</td>\n",
       "      <td>0.519449</td>\n",
       "      <td>693.916931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>693.629100</td>\n",
       "      <td>640.619995</td>\n",
       "      <td>0.254680</td>\n",
       "      <td>0.321008</td>\n",
       "      <td>0.533164</td>\n",
       "      <td>640.619995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>693.629100</td>\n",
       "      <td>661.174438</td>\n",
       "      <td>0.258733</td>\n",
       "      <td>0.224664</td>\n",
       "      <td>0.482966</td>\n",
       "      <td>661.174438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>644.563600</td>\n",
       "      <td>646.993591</td>\n",
       "      <td>0.255944</td>\n",
       "      <td>0.265339</td>\n",
       "      <td>0.504698</td>\n",
       "      <td>646.993591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>644.563600</td>\n",
       "      <td>641.086731</td>\n",
       "      <td>0.254773</td>\n",
       "      <td>0.279698</td>\n",
       "      <td>0.512463</td>\n",
       "      <td>641.086731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>644.563600</td>\n",
       "      <td>644.583679</td>\n",
       "      <td>0.255466</td>\n",
       "      <td>0.324456</td>\n",
       "      <td>0.534495</td>\n",
       "      <td>644.583740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>566.564900</td>\n",
       "      <td>639.149414</td>\n",
       "      <td>0.254387</td>\n",
       "      <td>0.325904</td>\n",
       "      <td>0.535758</td>\n",
       "      <td>639.149414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>566.564900</td>\n",
       "      <td>687.666382</td>\n",
       "      <td>0.263866</td>\n",
       "      <td>0.323092</td>\n",
       "      <td>0.529613</td>\n",
       "      <td>687.666382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>494.355200</td>\n",
       "      <td>708.526611</td>\n",
       "      <td>0.267838</td>\n",
       "      <td>0.331845</td>\n",
       "      <td>0.532003</td>\n",
       "      <td>708.526550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>494.355200</td>\n",
       "      <td>673.253418</td>\n",
       "      <td>0.261086</td>\n",
       "      <td>0.278938</td>\n",
       "      <td>0.508926</td>\n",
       "      <td>673.253418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>494.355200</td>\n",
       "      <td>702.829407</td>\n",
       "      <td>0.266759</td>\n",
       "      <td>0.236351</td>\n",
       "      <td>0.484796</td>\n",
       "      <td>702.829407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>447.953200</td>\n",
       "      <td>720.511414</td>\n",
       "      <td>0.270094</td>\n",
       "      <td>0.328542</td>\n",
       "      <td>0.529224</td>\n",
       "      <td>720.511414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 12:02:18,071] Trial 18 finished with value: 0.5357583250133238 and parameters: {'learning_rate': 0.00034345447576133, 'batch_size': 32, 'warmup_steps': 261, 'weight_decay': 0.0028050942103296397}. Best is trial 10 with value: 0.5729473745443601.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1176' max='2520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1176/2520 00:34 < 00:39, 33.76 it/s, Epoch 14/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1700.183838</td>\n",
       "      <td>0.414899</td>\n",
       "      <td>0.167059</td>\n",
       "      <td>0.376080</td>\n",
       "      <td>1700.183960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1771.182200</td>\n",
       "      <td>1489.952515</td>\n",
       "      <td>0.388401</td>\n",
       "      <td>0.140090</td>\n",
       "      <td>0.375845</td>\n",
       "      <td>1489.952515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1634.647300</td>\n",
       "      <td>1214.831543</td>\n",
       "      <td>0.350713</td>\n",
       "      <td>0.037129</td>\n",
       "      <td>0.343208</td>\n",
       "      <td>1214.831543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1275.872600</td>\n",
       "      <td>997.303040</td>\n",
       "      <td>0.317766</td>\n",
       "      <td>0.129066</td>\n",
       "      <td>0.405650</td>\n",
       "      <td>997.303040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>986.407800</td>\n",
       "      <td>864.349609</td>\n",
       "      <td>0.295828</td>\n",
       "      <td>0.130976</td>\n",
       "      <td>0.417574</td>\n",
       "      <td>864.349609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>876.596100</td>\n",
       "      <td>784.220154</td>\n",
       "      <td>0.281782</td>\n",
       "      <td>0.173830</td>\n",
       "      <td>0.446024</td>\n",
       "      <td>784.220154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>876.596100</td>\n",
       "      <td>737.279236</td>\n",
       "      <td>0.273219</td>\n",
       "      <td>0.128070</td>\n",
       "      <td>0.427426</td>\n",
       "      <td>737.279236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>775.272400</td>\n",
       "      <td>714.293213</td>\n",
       "      <td>0.268926</td>\n",
       "      <td>0.279151</td>\n",
       "      <td>0.505113</td>\n",
       "      <td>714.293152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>720.002400</td>\n",
       "      <td>703.292114</td>\n",
       "      <td>0.266847</td>\n",
       "      <td>0.298076</td>\n",
       "      <td>0.515615</td>\n",
       "      <td>703.292175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>716.023800</td>\n",
       "      <td>686.447449</td>\n",
       "      <td>0.263632</td>\n",
       "      <td>0.156064</td>\n",
       "      <td>0.446216</td>\n",
       "      <td>686.447449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>716.384800</td>\n",
       "      <td>673.580322</td>\n",
       "      <td>0.261149</td>\n",
       "      <td>0.217651</td>\n",
       "      <td>0.478251</td>\n",
       "      <td>673.580322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>655.440800</td>\n",
       "      <td>659.094971</td>\n",
       "      <td>0.258326</td>\n",
       "      <td>0.278326</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>659.094971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>655.440800</td>\n",
       "      <td>662.570312</td>\n",
       "      <td>0.259006</td>\n",
       "      <td>0.260921</td>\n",
       "      <td>0.500957</td>\n",
       "      <td>662.570312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>635.346500</td>\n",
       "      <td>680.616089</td>\n",
       "      <td>0.262510</td>\n",
       "      <td>0.269753</td>\n",
       "      <td>0.503622</td>\n",
       "      <td>680.616089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 12:02:54,190] Trial 19 finished with value: 0.5156146430908314 and parameters: {'learning_rate': 0.0001171542971814984, 'batch_size': 16, 'warmup_steps': 263, 'weight_decay': 0.0010242771533841863}. Best is trial 10 with value: 0.5729473745443601.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1260' max='1260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1260/1260 00:54, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1751.537231</td>\n",
       "      <td>0.421118</td>\n",
       "      <td>0.047507</td>\n",
       "      <td>0.313194</td>\n",
       "      <td>1751.537231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1748.364746</td>\n",
       "      <td>0.420737</td>\n",
       "      <td>0.082744</td>\n",
       "      <td>0.331004</td>\n",
       "      <td>1748.364746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1819.375300</td>\n",
       "      <td>1742.516724</td>\n",
       "      <td>0.420032</td>\n",
       "      <td>0.119716</td>\n",
       "      <td>0.349842</td>\n",
       "      <td>1742.516724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1819.375300</td>\n",
       "      <td>1732.161011</td>\n",
       "      <td>0.418782</td>\n",
       "      <td>0.144860</td>\n",
       "      <td>0.363039</td>\n",
       "      <td>1732.161133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1774.633900</td>\n",
       "      <td>1713.790039</td>\n",
       "      <td>0.416556</td>\n",
       "      <td>0.150831</td>\n",
       "      <td>0.367138</td>\n",
       "      <td>1713.789917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1774.633900</td>\n",
       "      <td>1687.391724</td>\n",
       "      <td>0.413335</td>\n",
       "      <td>0.143040</td>\n",
       "      <td>0.364853</td>\n",
       "      <td>1687.391724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1774.633900</td>\n",
       "      <td>1661.339355</td>\n",
       "      <td>0.410132</td>\n",
       "      <td>0.147763</td>\n",
       "      <td>0.368816</td>\n",
       "      <td>1661.339233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1752.172500</td>\n",
       "      <td>1637.749756</td>\n",
       "      <td>0.407210</td>\n",
       "      <td>0.148711</td>\n",
       "      <td>0.370751</td>\n",
       "      <td>1637.749634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1752.172500</td>\n",
       "      <td>1616.139526</td>\n",
       "      <td>0.404514</td>\n",
       "      <td>0.146961</td>\n",
       "      <td>0.371223</td>\n",
       "      <td>1616.139526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1693.896900</td>\n",
       "      <td>1596.185425</td>\n",
       "      <td>0.402009</td>\n",
       "      <td>0.149782</td>\n",
       "      <td>0.373887</td>\n",
       "      <td>1596.185425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1693.896900</td>\n",
       "      <td>1577.598633</td>\n",
       "      <td>0.399662</td>\n",
       "      <td>0.149440</td>\n",
       "      <td>0.374889</td>\n",
       "      <td>1577.598633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1643.916700</td>\n",
       "      <td>1560.320435</td>\n",
       "      <td>0.397467</td>\n",
       "      <td>0.145784</td>\n",
       "      <td>0.374158</td>\n",
       "      <td>1560.320435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1643.916700</td>\n",
       "      <td>1544.228271</td>\n",
       "      <td>0.395412</td>\n",
       "      <td>0.149161</td>\n",
       "      <td>0.376874</td>\n",
       "      <td>1544.228271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1643.916700</td>\n",
       "      <td>1529.331055</td>\n",
       "      <td>0.393500</td>\n",
       "      <td>0.153793</td>\n",
       "      <td>0.380146</td>\n",
       "      <td>1529.330933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1606.729100</td>\n",
       "      <td>1515.548340</td>\n",
       "      <td>0.391723</td>\n",
       "      <td>0.154930</td>\n",
       "      <td>0.381604</td>\n",
       "      <td>1515.548218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1606.729100</td>\n",
       "      <td>1502.852295</td>\n",
       "      <td>0.390079</td>\n",
       "      <td>0.151539</td>\n",
       "      <td>0.380730</td>\n",
       "      <td>1502.852173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1569.026600</td>\n",
       "      <td>1491.137939</td>\n",
       "      <td>0.388556</td>\n",
       "      <td>0.151427</td>\n",
       "      <td>0.381436</td>\n",
       "      <td>1491.137939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1569.026600</td>\n",
       "      <td>1480.445435</td>\n",
       "      <td>0.387160</td>\n",
       "      <td>0.153629</td>\n",
       "      <td>0.383234</td>\n",
       "      <td>1480.445435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1569.026600</td>\n",
       "      <td>1470.740112</td>\n",
       "      <td>0.385889</td>\n",
       "      <td>0.151238</td>\n",
       "      <td>0.382674</td>\n",
       "      <td>1470.740112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1546.804700</td>\n",
       "      <td>1461.948853</td>\n",
       "      <td>0.384734</td>\n",
       "      <td>0.149312</td>\n",
       "      <td>0.382289</td>\n",
       "      <td>1461.948853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1546.804700</td>\n",
       "      <td>1454.101929</td>\n",
       "      <td>0.383700</td>\n",
       "      <td>0.152828</td>\n",
       "      <td>0.384564</td>\n",
       "      <td>1454.101929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1520.104200</td>\n",
       "      <td>1447.129639</td>\n",
       "      <td>0.382779</td>\n",
       "      <td>0.151249</td>\n",
       "      <td>0.384235</td>\n",
       "      <td>1447.129639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1520.104200</td>\n",
       "      <td>1441.027100</td>\n",
       "      <td>0.381971</td>\n",
       "      <td>0.151505</td>\n",
       "      <td>0.384767</td>\n",
       "      <td>1441.026978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1503.351700</td>\n",
       "      <td>1435.762817</td>\n",
       "      <td>0.381273</td>\n",
       "      <td>0.151768</td>\n",
       "      <td>0.385248</td>\n",
       "      <td>1435.762573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1503.351700</td>\n",
       "      <td>1431.332275</td>\n",
       "      <td>0.380684</td>\n",
       "      <td>0.150999</td>\n",
       "      <td>0.385158</td>\n",
       "      <td>1431.332153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1503.351700</td>\n",
       "      <td>1427.729004</td>\n",
       "      <td>0.380204</td>\n",
       "      <td>0.153326</td>\n",
       "      <td>0.386561</td>\n",
       "      <td>1427.728882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1487.553600</td>\n",
       "      <td>1424.914673</td>\n",
       "      <td>0.379829</td>\n",
       "      <td>0.154598</td>\n",
       "      <td>0.387384</td>\n",
       "      <td>1424.914673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1487.553600</td>\n",
       "      <td>1422.904663</td>\n",
       "      <td>0.379561</td>\n",
       "      <td>0.155024</td>\n",
       "      <td>0.387731</td>\n",
       "      <td>1422.904663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1494.132000</td>\n",
       "      <td>1421.691895</td>\n",
       "      <td>0.379400</td>\n",
       "      <td>0.155421</td>\n",
       "      <td>0.388011</td>\n",
       "      <td>1421.691895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1494.132000</td>\n",
       "      <td>1421.282227</td>\n",
       "      <td>0.379345</td>\n",
       "      <td>0.155487</td>\n",
       "      <td>0.388071</td>\n",
       "      <td>1421.282227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 12:03:50,172] Trial 20 finished with value: 0.38807072840998424 and parameters: {'learning_rate': 1.2125223750341214e-05, 'batch_size': 32, 'warmup_steps': 230, 'weight_decay': 0.0024766144912826576}. Best is trial 10 with value: 0.5729473745443601.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3360' max='5040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3360/5040 01:13 < 00:36, 45.52 it/s, Epoch 20/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1727.291100</td>\n",
       "      <td>1162.475464</td>\n",
       "      <td>0.343073</td>\n",
       "      <td>0.122104</td>\n",
       "      <td>0.389516</td>\n",
       "      <td>1162.475464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>926.276100</td>\n",
       "      <td>738.338257</td>\n",
       "      <td>0.273415</td>\n",
       "      <td>0.175170</td>\n",
       "      <td>0.450878</td>\n",
       "      <td>738.338318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>708.661500</td>\n",
       "      <td>696.915161</td>\n",
       "      <td>0.265634</td>\n",
       "      <td>0.268988</td>\n",
       "      <td>0.501677</td>\n",
       "      <td>696.915161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>701.960600</td>\n",
       "      <td>656.698792</td>\n",
       "      <td>0.257856</td>\n",
       "      <td>0.294439</td>\n",
       "      <td>0.518292</td>\n",
       "      <td>656.698792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>670.394300</td>\n",
       "      <td>642.959167</td>\n",
       "      <td>0.255144</td>\n",
       "      <td>0.288543</td>\n",
       "      <td>0.516699</td>\n",
       "      <td>642.959106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>632.450200</td>\n",
       "      <td>625.247986</td>\n",
       "      <td>0.251606</td>\n",
       "      <td>0.326291</td>\n",
       "      <td>0.537343</td>\n",
       "      <td>625.247986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>624.104200</td>\n",
       "      <td>700.976807</td>\n",
       "      <td>0.266407</td>\n",
       "      <td>0.302015</td>\n",
       "      <td>0.517804</td>\n",
       "      <td>700.976807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>560.203700</td>\n",
       "      <td>676.572266</td>\n",
       "      <td>0.261729</td>\n",
       "      <td>0.344182</td>\n",
       "      <td>0.541227</td>\n",
       "      <td>676.572266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>543.001800</td>\n",
       "      <td>672.587097</td>\n",
       "      <td>0.260957</td>\n",
       "      <td>0.355927</td>\n",
       "      <td>0.547485</td>\n",
       "      <td>672.587097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>465.087700</td>\n",
       "      <td>642.295044</td>\n",
       "      <td>0.255013</td>\n",
       "      <td>0.355944</td>\n",
       "      <td>0.550465</td>\n",
       "      <td>642.295044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>471.262700</td>\n",
       "      <td>624.882324</td>\n",
       "      <td>0.251532</td>\n",
       "      <td>0.379301</td>\n",
       "      <td>0.563884</td>\n",
       "      <td>624.882324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>384.212300</td>\n",
       "      <td>664.005493</td>\n",
       "      <td>0.259287</td>\n",
       "      <td>0.336526</td>\n",
       "      <td>0.538620</td>\n",
       "      <td>664.005493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>372.161200</td>\n",
       "      <td>654.982605</td>\n",
       "      <td>0.257519</td>\n",
       "      <td>0.392926</td>\n",
       "      <td>0.567704</td>\n",
       "      <td>654.982727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>368.243500</td>\n",
       "      <td>701.803162</td>\n",
       "      <td>0.266564</td>\n",
       "      <td>0.353834</td>\n",
       "      <td>0.543635</td>\n",
       "      <td>701.803162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>342.242500</td>\n",
       "      <td>650.043884</td>\n",
       "      <td>0.256546</td>\n",
       "      <td>0.396577</td>\n",
       "      <td>0.570015</td>\n",
       "      <td>650.043884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>318.004500</td>\n",
       "      <td>722.793335</td>\n",
       "      <td>0.270521</td>\n",
       "      <td>0.370086</td>\n",
       "      <td>0.549782</td>\n",
       "      <td>722.793335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>283.595300</td>\n",
       "      <td>699.798401</td>\n",
       "      <td>0.266183</td>\n",
       "      <td>0.348573</td>\n",
       "      <td>0.541195</td>\n",
       "      <td>699.798462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>284.234100</td>\n",
       "      <td>727.266296</td>\n",
       "      <td>0.271357</td>\n",
       "      <td>0.356161</td>\n",
       "      <td>0.542402</td>\n",
       "      <td>727.266357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>249.335600</td>\n",
       "      <td>712.390137</td>\n",
       "      <td>0.268567</td>\n",
       "      <td>0.355600</td>\n",
       "      <td>0.543517</td>\n",
       "      <td>712.390198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>233.996300</td>\n",
       "      <td>723.098572</td>\n",
       "      <td>0.270578</td>\n",
       "      <td>0.365413</td>\n",
       "      <td>0.547417</td>\n",
       "      <td>723.098633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 12:05:05,301] Trial 21 finished with value: 0.5700154413879907 and parameters: {'learning_rate': 0.0002471482213279421, 'batch_size': 8, 'warmup_steps': 197, 'weight_decay': 0.0068047356154822426}. Best is trial 10 with value: 0.5729473745443601.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1848' max='5040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1848/5040 00:40 < 01:10, 45.49 it/s, Epoch 11/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1702.918000</td>\n",
       "      <td>1064.998047</td>\n",
       "      <td>0.328374</td>\n",
       "      <td>0.134496</td>\n",
       "      <td>0.403061</td>\n",
       "      <td>1064.998169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>842.690900</td>\n",
       "      <td>708.934692</td>\n",
       "      <td>0.267915</td>\n",
       "      <td>0.321779</td>\n",
       "      <td>0.526932</td>\n",
       "      <td>708.934631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>702.677900</td>\n",
       "      <td>664.885315</td>\n",
       "      <td>0.259458</td>\n",
       "      <td>0.277872</td>\n",
       "      <td>0.509207</td>\n",
       "      <td>664.885254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>668.958300</td>\n",
       "      <td>642.849548</td>\n",
       "      <td>0.255123</td>\n",
       "      <td>0.276520</td>\n",
       "      <td>0.510699</td>\n",
       "      <td>642.849548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>611.713100</td>\n",
       "      <td>605.254639</td>\n",
       "      <td>0.247550</td>\n",
       "      <td>0.368203</td>\n",
       "      <td>0.560326</td>\n",
       "      <td>605.254639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>579.079100</td>\n",
       "      <td>588.884644</td>\n",
       "      <td>0.244180</td>\n",
       "      <td>0.417181</td>\n",
       "      <td>0.586501</td>\n",
       "      <td>588.884644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>559.533800</td>\n",
       "      <td>635.848877</td>\n",
       "      <td>0.253730</td>\n",
       "      <td>0.380270</td>\n",
       "      <td>0.563270</td>\n",
       "      <td>635.848877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>491.873200</td>\n",
       "      <td>654.997681</td>\n",
       "      <td>0.257522</td>\n",
       "      <td>0.379836</td>\n",
       "      <td>0.561157</td>\n",
       "      <td>654.997742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>481.438500</td>\n",
       "      <td>639.170776</td>\n",
       "      <td>0.254392</td>\n",
       "      <td>0.389437</td>\n",
       "      <td>0.567523</td>\n",
       "      <td>639.170837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>402.839200</td>\n",
       "      <td>634.012634</td>\n",
       "      <td>0.253363</td>\n",
       "      <td>0.360591</td>\n",
       "      <td>0.553614</td>\n",
       "      <td>634.012634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>396.718200</td>\n",
       "      <td>646.920898</td>\n",
       "      <td>0.255929</td>\n",
       "      <td>0.381385</td>\n",
       "      <td>0.562728</td>\n",
       "      <td>646.920898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 12:05:47,245] Trial 22 finished with value: 0.586500525139622 and parameters: {'learning_rate': 0.00030994900647604996, 'batch_size': 8, 'warmup_steps': 201, 'weight_decay': 0.007364521772775286}. Best is trial 22 with value: 0.586500525139622.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1848' max='5040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1848/5040 00:41 < 01:12, 44.29 it/s, Epoch 11/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1701.309100</td>\n",
       "      <td>1049.712036</td>\n",
       "      <td>0.326009</td>\n",
       "      <td>0.017840</td>\n",
       "      <td>0.345916</td>\n",
       "      <td>1049.712158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>837.646200</td>\n",
       "      <td>709.310303</td>\n",
       "      <td>0.267986</td>\n",
       "      <td>0.292641</td>\n",
       "      <td>0.512327</td>\n",
       "      <td>709.310303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>700.355500</td>\n",
       "      <td>725.910400</td>\n",
       "      <td>0.271104</td>\n",
       "      <td>0.190524</td>\n",
       "      <td>0.459710</td>\n",
       "      <td>725.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>695.350000</td>\n",
       "      <td>666.556030</td>\n",
       "      <td>0.259784</td>\n",
       "      <td>0.274911</td>\n",
       "      <td>0.507563</td>\n",
       "      <td>666.556030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>683.040000</td>\n",
       "      <td>655.179504</td>\n",
       "      <td>0.257558</td>\n",
       "      <td>0.270819</td>\n",
       "      <td>0.506631</td>\n",
       "      <td>655.179504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>633.718300</td>\n",
       "      <td>621.126404</td>\n",
       "      <td>0.250775</td>\n",
       "      <td>0.423516</td>\n",
       "      <td>0.586371</td>\n",
       "      <td>621.126343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>626.051900</td>\n",
       "      <td>620.126099</td>\n",
       "      <td>0.250573</td>\n",
       "      <td>0.390258</td>\n",
       "      <td>0.569842</td>\n",
       "      <td>620.126099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>558.891800</td>\n",
       "      <td>686.138428</td>\n",
       "      <td>0.263573</td>\n",
       "      <td>0.281729</td>\n",
       "      <td>0.509078</td>\n",
       "      <td>686.138428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>557.928600</td>\n",
       "      <td>684.325684</td>\n",
       "      <td>0.263224</td>\n",
       "      <td>0.324061</td>\n",
       "      <td>0.530419</td>\n",
       "      <td>684.325684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>475.075400</td>\n",
       "      <td>620.138000</td>\n",
       "      <td>0.250575</td>\n",
       "      <td>0.361018</td>\n",
       "      <td>0.555221</td>\n",
       "      <td>620.138000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>460.288700</td>\n",
       "      <td>657.694763</td>\n",
       "      <td>0.258052</td>\n",
       "      <td>0.320826</td>\n",
       "      <td>0.531387</td>\n",
       "      <td>657.694763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 12:06:30,285] Trial 23 finished with value: 0.5863707311759392 and parameters: {'learning_rate': 0.00029837444430027367, 'batch_size': 8, 'warmup_steps': 188, 'weight_decay': 0.007404414578826395}. Best is trial 22 with value: 0.586500525139622.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2352' max='5040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2352/5040 00:51 < 00:59, 45.44 it/s, Epoch 14/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1741.882800</td>\n",
       "      <td>1277.885986</td>\n",
       "      <td>0.359700</td>\n",
       "      <td>0.020464</td>\n",
       "      <td>0.330382</td>\n",
       "      <td>1277.885986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1072.166400</td>\n",
       "      <td>835.019165</td>\n",
       "      <td>0.290765</td>\n",
       "      <td>0.155039</td>\n",
       "      <td>0.432137</td>\n",
       "      <td>835.019287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>754.769100</td>\n",
       "      <td>721.557861</td>\n",
       "      <td>0.270290</td>\n",
       "      <td>0.218170</td>\n",
       "      <td>0.473940</td>\n",
       "      <td>721.557861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>724.648700</td>\n",
       "      <td>698.564819</td>\n",
       "      <td>0.265949</td>\n",
       "      <td>0.272812</td>\n",
       "      <td>0.503432</td>\n",
       "      <td>698.564880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>706.651300</td>\n",
       "      <td>661.426392</td>\n",
       "      <td>0.258783</td>\n",
       "      <td>0.293614</td>\n",
       "      <td>0.517416</td>\n",
       "      <td>661.426392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>657.575200</td>\n",
       "      <td>662.130432</td>\n",
       "      <td>0.258920</td>\n",
       "      <td>0.225932</td>\n",
       "      <td>0.483506</td>\n",
       "      <td>662.130371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>654.824700</td>\n",
       "      <td>669.425354</td>\n",
       "      <td>0.260343</td>\n",
       "      <td>0.297682</td>\n",
       "      <td>0.518670</td>\n",
       "      <td>669.425415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>590.039700</td>\n",
       "      <td>653.987488</td>\n",
       "      <td>0.257323</td>\n",
       "      <td>0.295627</td>\n",
       "      <td>0.519152</td>\n",
       "      <td>653.987427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>573.472600</td>\n",
       "      <td>685.875122</td>\n",
       "      <td>0.263522</td>\n",
       "      <td>0.344313</td>\n",
       "      <td>0.540395</td>\n",
       "      <td>685.875061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>519.503700</td>\n",
       "      <td>673.162537</td>\n",
       "      <td>0.261068</td>\n",
       "      <td>0.321222</td>\n",
       "      <td>0.530077</td>\n",
       "      <td>673.162537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>503.491400</td>\n",
       "      <td>652.293396</td>\n",
       "      <td>0.256990</td>\n",
       "      <td>0.307265</td>\n",
       "      <td>0.525138</td>\n",
       "      <td>652.293396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>442.072700</td>\n",
       "      <td>669.469971</td>\n",
       "      <td>0.260351</td>\n",
       "      <td>0.311922</td>\n",
       "      <td>0.525786</td>\n",
       "      <td>669.469971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>420.994100</td>\n",
       "      <td>694.889343</td>\n",
       "      <td>0.265248</td>\n",
       "      <td>0.316411</td>\n",
       "      <td>0.525581</td>\n",
       "      <td>694.889343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>390.769800</td>\n",
       "      <td>686.183044</td>\n",
       "      <td>0.263581</td>\n",
       "      <td>0.304842</td>\n",
       "      <td>0.520630</td>\n",
       "      <td>686.183044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 12:07:23,395] Trial 24 finished with value: 0.5403954517452308 and parameters: {'learning_rate': 0.00015599095228165317, 'batch_size': 8, 'warmup_steps': 168, 'weight_decay': 0.020665418187125653}. Best is trial 22 with value: 0.586500525139622.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2520' max='5040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2520/5040 00:55 < 00:55, 45.05 it/s, Epoch 15/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1712.750500</td>\n",
       "      <td>1097.400635</td>\n",
       "      <td>0.333332</td>\n",
       "      <td>0.113065</td>\n",
       "      <td>0.389867</td>\n",
       "      <td>1097.400757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>862.117600</td>\n",
       "      <td>711.988892</td>\n",
       "      <td>0.268492</td>\n",
       "      <td>0.224524</td>\n",
       "      <td>0.478016</td>\n",
       "      <td>711.988892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>703.598900</td>\n",
       "      <td>695.154053</td>\n",
       "      <td>0.265298</td>\n",
       "      <td>0.086501</td>\n",
       "      <td>0.410601</td>\n",
       "      <td>695.154053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>698.640600</td>\n",
       "      <td>693.979980</td>\n",
       "      <td>0.265074</td>\n",
       "      <td>0.288068</td>\n",
       "      <td>0.511497</td>\n",
       "      <td>693.979919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>684.683300</td>\n",
       "      <td>643.499817</td>\n",
       "      <td>0.255252</td>\n",
       "      <td>0.290954</td>\n",
       "      <td>0.517851</td>\n",
       "      <td>643.499817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>644.473100</td>\n",
       "      <td>645.787903</td>\n",
       "      <td>0.255705</td>\n",
       "      <td>0.281079</td>\n",
       "      <td>0.512687</td>\n",
       "      <td>645.787842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>639.879100</td>\n",
       "      <td>668.735596</td>\n",
       "      <td>0.260208</td>\n",
       "      <td>0.270859</td>\n",
       "      <td>0.505325</td>\n",
       "      <td>668.735535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>580.354500</td>\n",
       "      <td>666.458374</td>\n",
       "      <td>0.259765</td>\n",
       "      <td>0.264374</td>\n",
       "      <td>0.502304</td>\n",
       "      <td>666.458374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>583.797400</td>\n",
       "      <td>647.576965</td>\n",
       "      <td>0.256059</td>\n",
       "      <td>0.352900</td>\n",
       "      <td>0.548421</td>\n",
       "      <td>647.576965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>514.750000</td>\n",
       "      <td>621.341125</td>\n",
       "      <td>0.250818</td>\n",
       "      <td>0.353473</td>\n",
       "      <td>0.551327</td>\n",
       "      <td>621.341125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>528.862600</td>\n",
       "      <td>623.608154</td>\n",
       "      <td>0.251276</td>\n",
       "      <td>0.341395</td>\n",
       "      <td>0.545060</td>\n",
       "      <td>623.608215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>441.744500</td>\n",
       "      <td>673.964844</td>\n",
       "      <td>0.261224</td>\n",
       "      <td>0.304315</td>\n",
       "      <td>0.521546</td>\n",
       "      <td>673.964905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>419.571300</td>\n",
       "      <td>727.826355</td>\n",
       "      <td>0.271461</td>\n",
       "      <td>0.284801</td>\n",
       "      <td>0.506670</td>\n",
       "      <td>727.826355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>411.061300</td>\n",
       "      <td>719.177124</td>\n",
       "      <td>0.269844</td>\n",
       "      <td>0.343760</td>\n",
       "      <td>0.536958</td>\n",
       "      <td>719.177124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>391.375600</td>\n",
       "      <td>696.423584</td>\n",
       "      <td>0.265541</td>\n",
       "      <td>0.352514</td>\n",
       "      <td>0.543487</td>\n",
       "      <td>696.423645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 12:08:20,726] Trial 25 finished with value: 0.5513273120395712 and parameters: {'learning_rate': 0.00030958690261619943, 'batch_size': 8, 'warmup_steps': 212, 'weight_decay': 0.007228492392865632}. Best is trial 22 with value: 0.586500525139622.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1176' max='5040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1176/5040 00:26 < 01:28, 43.65 it/s, Epoch 7/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1611.425500</td>\n",
       "      <td>781.087097</td>\n",
       "      <td>0.281219</td>\n",
       "      <td>0.061959</td>\n",
       "      <td>0.390370</td>\n",
       "      <td>781.087097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>730.806400</td>\n",
       "      <td>690.487610</td>\n",
       "      <td>0.264407</td>\n",
       "      <td>0.308320</td>\n",
       "      <td>0.521957</td>\n",
       "      <td>690.487610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>699.781600</td>\n",
       "      <td>682.145386</td>\n",
       "      <td>0.262804</td>\n",
       "      <td>0.159417</td>\n",
       "      <td>0.448306</td>\n",
       "      <td>682.145325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>691.320300</td>\n",
       "      <td>677.358887</td>\n",
       "      <td>0.261881</td>\n",
       "      <td>0.174869</td>\n",
       "      <td>0.456494</td>\n",
       "      <td>677.358887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>687.530400</td>\n",
       "      <td>656.429443</td>\n",
       "      <td>0.257803</td>\n",
       "      <td>0.257410</td>\n",
       "      <td>0.499803</td>\n",
       "      <td>656.429443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>662.445200</td>\n",
       "      <td>651.091125</td>\n",
       "      <td>0.256753</td>\n",
       "      <td>0.263564</td>\n",
       "      <td>0.503405</td>\n",
       "      <td>651.091125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>672.920500</td>\n",
       "      <td>645.455566</td>\n",
       "      <td>0.255639</td>\n",
       "      <td>0.270240</td>\n",
       "      <td>0.507300</td>\n",
       "      <td>645.455627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 12:08:49,047] Trial 26 finished with value: 0.5219567475511178 and parameters: {'learning_rate': 0.00047947064240833406, 'batch_size': 8, 'warmup_steps': 151, 'weight_decay': 0.008244692594565754}. Best is trial 22 with value: 0.586500525139622.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1512' max='5040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1512/5040 00:32 < 01:16, 45.89 it/s, Epoch 9/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1760.148600</td>\n",
       "      <td>1414.113037</td>\n",
       "      <td>0.378387</td>\n",
       "      <td>0.151205</td>\n",
       "      <td>0.386409</td>\n",
       "      <td>1414.113037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1217.455200</td>\n",
       "      <td>940.686829</td>\n",
       "      <td>0.308615</td>\n",
       "      <td>0.135283</td>\n",
       "      <td>0.413334</td>\n",
       "      <td>940.686768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>827.103800</td>\n",
       "      <td>773.900513</td>\n",
       "      <td>0.279922</td>\n",
       "      <td>0.018329</td>\n",
       "      <td>0.369203</td>\n",
       "      <td>773.900513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>774.828700</td>\n",
       "      <td>716.817017</td>\n",
       "      <td>0.269401</td>\n",
       "      <td>0.349003</td>\n",
       "      <td>0.539801</td>\n",
       "      <td>716.817017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>710.943800</td>\n",
       "      <td>700.791016</td>\n",
       "      <td>0.266372</td>\n",
       "      <td>0.336146</td>\n",
       "      <td>0.534887</td>\n",
       "      <td>700.791016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>698.510500</td>\n",
       "      <td>674.437012</td>\n",
       "      <td>0.261315</td>\n",
       "      <td>0.283091</td>\n",
       "      <td>0.510888</td>\n",
       "      <td>674.437012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>705.784500</td>\n",
       "      <td>656.987549</td>\n",
       "      <td>0.257913</td>\n",
       "      <td>0.277120</td>\n",
       "      <td>0.509603</td>\n",
       "      <td>656.987549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>652.600300</td>\n",
       "      <td>659.169067</td>\n",
       "      <td>0.258341</td>\n",
       "      <td>0.313867</td>\n",
       "      <td>0.527763</td>\n",
       "      <td>659.169067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>642.392600</td>\n",
       "      <td>671.588623</td>\n",
       "      <td>0.260763</td>\n",
       "      <td>0.331950</td>\n",
       "      <td>0.535593</td>\n",
       "      <td>671.588623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 12:09:23,339] Trial 27 finished with value: 0.539801030860423 and parameters: {'learning_rate': 0.0001210551138333399, 'batch_size': 8, 'warmup_steps': 193, 'weight_decay': 0.015103406097788688}. Best is trial 22 with value: 0.586500525139622.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1260' max='2520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1260/2520 00:36 < 00:36, 34.56 it/s, Epoch 15/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1574.106812</td>\n",
       "      <td>0.399219</td>\n",
       "      <td>0.118492</td>\n",
       "      <td>0.359636</td>\n",
       "      <td>1574.106812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1721.343300</td>\n",
       "      <td>1115.726685</td>\n",
       "      <td>0.336104</td>\n",
       "      <td>0.107612</td>\n",
       "      <td>0.385754</td>\n",
       "      <td>1115.726685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1301.906300</td>\n",
       "      <td>796.400024</td>\n",
       "      <td>0.283962</td>\n",
       "      <td>0.069418</td>\n",
       "      <td>0.392728</td>\n",
       "      <td>796.400024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>837.648700</td>\n",
       "      <td>705.039490</td>\n",
       "      <td>0.267178</td>\n",
       "      <td>0.322734</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>705.039612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>696.111600</td>\n",
       "      <td>678.060364</td>\n",
       "      <td>0.262016</td>\n",
       "      <td>0.273857</td>\n",
       "      <td>0.505920</td>\n",
       "      <td>678.060364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>690.214500</td>\n",
       "      <td>649.788086</td>\n",
       "      <td>0.256496</td>\n",
       "      <td>0.268445</td>\n",
       "      <td>0.505975</td>\n",
       "      <td>649.788025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>690.214500</td>\n",
       "      <td>627.009949</td>\n",
       "      <td>0.251960</td>\n",
       "      <td>0.348559</td>\n",
       "      <td>0.548299</td>\n",
       "      <td>627.009888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>652.285100</td>\n",
       "      <td>636.550415</td>\n",
       "      <td>0.253870</td>\n",
       "      <td>0.299936</td>\n",
       "      <td>0.523033</td>\n",
       "      <td>636.550415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>597.533500</td>\n",
       "      <td>645.568604</td>\n",
       "      <td>0.255662</td>\n",
       "      <td>0.324785</td>\n",
       "      <td>0.534562</td>\n",
       "      <td>645.568604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>573.442800</td>\n",
       "      <td>606.773804</td>\n",
       "      <td>0.247861</td>\n",
       "      <td>0.385570</td>\n",
       "      <td>0.568855</td>\n",
       "      <td>606.773804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>543.885300</td>\n",
       "      <td>648.101013</td>\n",
       "      <td>0.256163</td>\n",
       "      <td>0.336632</td>\n",
       "      <td>0.540235</td>\n",
       "      <td>648.101013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>500.556700</td>\n",
       "      <td>648.411682</td>\n",
       "      <td>0.256224</td>\n",
       "      <td>0.332009</td>\n",
       "      <td>0.537893</td>\n",
       "      <td>648.411682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>500.556700</td>\n",
       "      <td>670.341797</td>\n",
       "      <td>0.260521</td>\n",
       "      <td>0.367546</td>\n",
       "      <td>0.553513</td>\n",
       "      <td>670.341858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>472.630700</td>\n",
       "      <td>672.084229</td>\n",
       "      <td>0.260859</td>\n",
       "      <td>0.375848</td>\n",
       "      <td>0.557494</td>\n",
       "      <td>672.084229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>432.451200</td>\n",
       "      <td>660.750549</td>\n",
       "      <td>0.258650</td>\n",
       "      <td>0.327913</td>\n",
       "      <td>0.534632</td>\n",
       "      <td>660.750549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 12:10:01,036] Trial 28 finished with value: 0.568854816955221 and parameters: {'learning_rate': 0.00029549500335615677, 'batch_size': 16, 'warmup_steps': 220, 'weight_decay': 0.026832017342406315}. Best is trial 22 with value: 0.586500525139622.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='840' max='1260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 840/1260 00:35 < 00:17, 23.40 it/s, Epoch 20/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1728.817871</td>\n",
       "      <td>0.418378</td>\n",
       "      <td>0.084741</td>\n",
       "      <td>0.333181</td>\n",
       "      <td>1728.817871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1599.840820</td>\n",
       "      <td>0.402469</td>\n",
       "      <td>0.095101</td>\n",
       "      <td>0.346316</td>\n",
       "      <td>1599.840820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1757.156700</td>\n",
       "      <td>1406.623169</td>\n",
       "      <td>0.377384</td>\n",
       "      <td>0.092002</td>\n",
       "      <td>0.357309</td>\n",
       "      <td>1406.623169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1757.156700</td>\n",
       "      <td>1200.964966</td>\n",
       "      <td>0.348706</td>\n",
       "      <td>0.100627</td>\n",
       "      <td>0.375961</td>\n",
       "      <td>1200.964966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1335.211700</td>\n",
       "      <td>1053.373535</td>\n",
       "      <td>0.326577</td>\n",
       "      <td>0.118891</td>\n",
       "      <td>0.396157</td>\n",
       "      <td>1053.373657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1335.211700</td>\n",
       "      <td>948.668701</td>\n",
       "      <td>0.309921</td>\n",
       "      <td>0.157378</td>\n",
       "      <td>0.423728</td>\n",
       "      <td>948.668579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1335.211700</td>\n",
       "      <td>871.318787</td>\n",
       "      <td>0.297018</td>\n",
       "      <td>0.183677</td>\n",
       "      <td>0.443330</td>\n",
       "      <td>871.318787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1004.138100</td>\n",
       "      <td>813.398193</td>\n",
       "      <td>0.286976</td>\n",
       "      <td>0.212587</td>\n",
       "      <td>0.462805</td>\n",
       "      <td>813.398193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1004.138100</td>\n",
       "      <td>771.201599</td>\n",
       "      <td>0.279433</td>\n",
       "      <td>0.191892</td>\n",
       "      <td>0.456229</td>\n",
       "      <td>771.201660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>821.297300</td>\n",
       "      <td>740.118896</td>\n",
       "      <td>0.273744</td>\n",
       "      <td>0.237168</td>\n",
       "      <td>0.481712</td>\n",
       "      <td>740.118896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>821.297300</td>\n",
       "      <td>719.824341</td>\n",
       "      <td>0.269965</td>\n",
       "      <td>0.231215</td>\n",
       "      <td>0.480625</td>\n",
       "      <td>719.824402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>744.421500</td>\n",
       "      <td>709.164612</td>\n",
       "      <td>0.267959</td>\n",
       "      <td>0.227619</td>\n",
       "      <td>0.479830</td>\n",
       "      <td>709.164612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>744.421500</td>\n",
       "      <td>701.807983</td>\n",
       "      <td>0.266565</td>\n",
       "      <td>0.257369</td>\n",
       "      <td>0.495402</td>\n",
       "      <td>701.807983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>744.421500</td>\n",
       "      <td>698.135742</td>\n",
       "      <td>0.265867</td>\n",
       "      <td>0.320912</td>\n",
       "      <td>0.527523</td>\n",
       "      <td>698.135742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>713.497600</td>\n",
       "      <td>696.463379</td>\n",
       "      <td>0.265548</td>\n",
       "      <td>0.324880</td>\n",
       "      <td>0.529666</td>\n",
       "      <td>696.463379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>713.497600</td>\n",
       "      <td>695.643311</td>\n",
       "      <td>0.265392</td>\n",
       "      <td>0.305841</td>\n",
       "      <td>0.520225</td>\n",
       "      <td>695.643372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>694.808700</td>\n",
       "      <td>666.530029</td>\n",
       "      <td>0.259779</td>\n",
       "      <td>0.296239</td>\n",
       "      <td>0.518230</td>\n",
       "      <td>666.530029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>694.808700</td>\n",
       "      <td>657.345703</td>\n",
       "      <td>0.257983</td>\n",
       "      <td>0.292913</td>\n",
       "      <td>0.517465</td>\n",
       "      <td>657.345703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>694.808700</td>\n",
       "      <td>658.386841</td>\n",
       "      <td>0.258187</td>\n",
       "      <td>0.273074</td>\n",
       "      <td>0.507443</td>\n",
       "      <td>658.386841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>662.336400</td>\n",
       "      <td>654.945740</td>\n",
       "      <td>0.257512</td>\n",
       "      <td>0.279858</td>\n",
       "      <td>0.511173</td>\n",
       "      <td>654.945740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 12:10:38,127] Trial 29 finished with value: 0.5296657156643803 and parameters: {'learning_rate': 0.0001513770987851562, 'batch_size': 32, 'warmup_steps': 148, 'weight_decay': 0.001514774919872617}. Best is trial 22 with value: 0.586500525139622.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4536' max='5040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4536/5040 01:39 < 00:11, 45.54 it/s, Epoch 27/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1783.408900</td>\n",
       "      <td>1698.432617</td>\n",
       "      <td>0.414685</td>\n",
       "      <td>0.164287</td>\n",
       "      <td>0.374801</td>\n",
       "      <td>1698.432617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1717.846900</td>\n",
       "      <td>1539.466187</td>\n",
       "      <td>0.394802</td>\n",
       "      <td>0.121488</td>\n",
       "      <td>0.363343</td>\n",
       "      <td>1539.466187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1484.918000</td>\n",
       "      <td>1399.868896</td>\n",
       "      <td>0.376477</td>\n",
       "      <td>0.086908</td>\n",
       "      <td>0.355216</td>\n",
       "      <td>1399.868896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1440.264500</td>\n",
       "      <td>1282.676392</td>\n",
       "      <td>0.360373</td>\n",
       "      <td>0.086242</td>\n",
       "      <td>0.362934</td>\n",
       "      <td>1282.676270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1261.600500</td>\n",
       "      <td>1188.181763</td>\n",
       "      <td>0.346845</td>\n",
       "      <td>0.098386</td>\n",
       "      <td>0.375770</td>\n",
       "      <td>1188.181641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1199.676100</td>\n",
       "      <td>1112.247925</td>\n",
       "      <td>0.335579</td>\n",
       "      <td>0.102472</td>\n",
       "      <td>0.383446</td>\n",
       "      <td>1112.247925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1182.063700</td>\n",
       "      <td>1051.570801</td>\n",
       "      <td>0.326297</td>\n",
       "      <td>0.101688</td>\n",
       "      <td>0.387696</td>\n",
       "      <td>1051.570801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1069.432300</td>\n",
       "      <td>1000.415405</td>\n",
       "      <td>0.318262</td>\n",
       "      <td>0.116388</td>\n",
       "      <td>0.399063</td>\n",
       "      <td>1000.415405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1053.320300</td>\n",
       "      <td>959.650757</td>\n",
       "      <td>0.311710</td>\n",
       "      <td>0.069435</td>\n",
       "      <td>0.378863</td>\n",
       "      <td>959.650757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>981.785900</td>\n",
       "      <td>924.999817</td>\n",
       "      <td>0.306031</td>\n",
       "      <td>0.094899</td>\n",
       "      <td>0.394434</td>\n",
       "      <td>924.999817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>992.647700</td>\n",
       "      <td>895.595886</td>\n",
       "      <td>0.301127</td>\n",
       "      <td>0.085596</td>\n",
       "      <td>0.392234</td>\n",
       "      <td>895.595764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>925.515200</td>\n",
       "      <td>870.291626</td>\n",
       "      <td>0.296843</td>\n",
       "      <td>0.104301</td>\n",
       "      <td>0.403729</td>\n",
       "      <td>870.291626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>899.470100</td>\n",
       "      <td>849.872559</td>\n",
       "      <td>0.293340</td>\n",
       "      <td>0.158364</td>\n",
       "      <td>0.432512</td>\n",
       "      <td>849.872559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>877.729300</td>\n",
       "      <td>832.028748</td>\n",
       "      <td>0.290244</td>\n",
       "      <td>0.115615</td>\n",
       "      <td>0.412685</td>\n",
       "      <td>832.028748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>848.474100</td>\n",
       "      <td>817.363403</td>\n",
       "      <td>0.287675</td>\n",
       "      <td>0.088701</td>\n",
       "      <td>0.400513</td>\n",
       "      <td>817.363525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>817.212200</td>\n",
       "      <td>805.272827</td>\n",
       "      <td>0.285539</td>\n",
       "      <td>0.187450</td>\n",
       "      <td>0.450956</td>\n",
       "      <td>805.272827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>805.377000</td>\n",
       "      <td>794.331604</td>\n",
       "      <td>0.283593</td>\n",
       "      <td>0.148690</td>\n",
       "      <td>0.432549</td>\n",
       "      <td>794.331482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>853.533700</td>\n",
       "      <td>785.087708</td>\n",
       "      <td>0.281938</td>\n",
       "      <td>0.184720</td>\n",
       "      <td>0.451391</td>\n",
       "      <td>785.087708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>814.459300</td>\n",
       "      <td>777.409180</td>\n",
       "      <td>0.280556</td>\n",
       "      <td>0.213341</td>\n",
       "      <td>0.466392</td>\n",
       "      <td>777.409241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>768.108800</td>\n",
       "      <td>771.272461</td>\n",
       "      <td>0.279446</td>\n",
       "      <td>0.197866</td>\n",
       "      <td>0.459210</td>\n",
       "      <td>771.272461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>805.815600</td>\n",
       "      <td>765.838440</td>\n",
       "      <td>0.278460</td>\n",
       "      <td>0.174123</td>\n",
       "      <td>0.447832</td>\n",
       "      <td>765.838440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>773.752500</td>\n",
       "      <td>761.255188</td>\n",
       "      <td>0.277626</td>\n",
       "      <td>0.212921</td>\n",
       "      <td>0.467648</td>\n",
       "      <td>761.255188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>804.527200</td>\n",
       "      <td>757.674561</td>\n",
       "      <td>0.276972</td>\n",
       "      <td>0.200360</td>\n",
       "      <td>0.461694</td>\n",
       "      <td>757.674500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>764.482300</td>\n",
       "      <td>754.641174</td>\n",
       "      <td>0.276417</td>\n",
       "      <td>0.201471</td>\n",
       "      <td>0.462527</td>\n",
       "      <td>754.641113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>759.666200</td>\n",
       "      <td>751.973022</td>\n",
       "      <td>0.275928</td>\n",
       "      <td>0.203874</td>\n",
       "      <td>0.463973</td>\n",
       "      <td>751.973083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>775.874100</td>\n",
       "      <td>749.931641</td>\n",
       "      <td>0.275553</td>\n",
       "      <td>0.196384</td>\n",
       "      <td>0.460416</td>\n",
       "      <td>749.931641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>770.098400</td>\n",
       "      <td>748.432983</td>\n",
       "      <td>0.275278</td>\n",
       "      <td>0.199546</td>\n",
       "      <td>0.462134</td>\n",
       "      <td>748.433044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 12:12:19,485] Trial 30 finished with value: 0.46764780806136075 and parameters: {'learning_rate': 2.2758624050081096e-05, 'batch_size': 8, 'warmup_steps': 181, 'weight_decay': 0.003973271001067322}. Best is trial 22 with value: 0.586500525139622.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2016' max='5040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2016/5040 00:44 < 01:06, 45.36 it/s, Epoch 12/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1719.240900</td>\n",
       "      <td>1125.243164</td>\n",
       "      <td>0.337534</td>\n",
       "      <td>0.154606</td>\n",
       "      <td>0.408536</td>\n",
       "      <td>1125.243164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>894.369800</td>\n",
       "      <td>726.232666</td>\n",
       "      <td>0.271164</td>\n",
       "      <td>0.318229</td>\n",
       "      <td>0.523532</td>\n",
       "      <td>726.232666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>705.545000</td>\n",
       "      <td>695.545593</td>\n",
       "      <td>0.265373</td>\n",
       "      <td>0.318777</td>\n",
       "      <td>0.526702</td>\n",
       "      <td>695.545532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>701.065500</td>\n",
       "      <td>683.214111</td>\n",
       "      <td>0.263010</td>\n",
       "      <td>0.337214</td>\n",
       "      <td>0.537102</td>\n",
       "      <td>683.214111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>665.191500</td>\n",
       "      <td>638.399109</td>\n",
       "      <td>0.254238</td>\n",
       "      <td>0.298080</td>\n",
       "      <td>0.521921</td>\n",
       "      <td>638.399109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>610.773000</td>\n",
       "      <td>634.308105</td>\n",
       "      <td>0.253422</td>\n",
       "      <td>0.311247</td>\n",
       "      <td>0.528912</td>\n",
       "      <td>634.308044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>599.919400</td>\n",
       "      <td>649.079407</td>\n",
       "      <td>0.256356</td>\n",
       "      <td>0.339039</td>\n",
       "      <td>0.541342</td>\n",
       "      <td>649.079407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>530.703500</td>\n",
       "      <td>655.318665</td>\n",
       "      <td>0.257585</td>\n",
       "      <td>0.285076</td>\n",
       "      <td>0.513745</td>\n",
       "      <td>655.318787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>520.577700</td>\n",
       "      <td>690.574646</td>\n",
       "      <td>0.264423</td>\n",
       "      <td>0.323265</td>\n",
       "      <td>0.529421</td>\n",
       "      <td>690.574646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>436.133200</td>\n",
       "      <td>681.340210</td>\n",
       "      <td>0.262649</td>\n",
       "      <td>0.312808</td>\n",
       "      <td>0.525079</td>\n",
       "      <td>681.340210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>449.573200</td>\n",
       "      <td>680.595947</td>\n",
       "      <td>0.262506</td>\n",
       "      <td>0.303536</td>\n",
       "      <td>0.520515</td>\n",
       "      <td>680.595947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>399.062900</td>\n",
       "      <td>732.274231</td>\n",
       "      <td>0.272290</td>\n",
       "      <td>0.307988</td>\n",
       "      <td>0.517849</td>\n",
       "      <td>732.274170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 12:13:05,765] Trial 31 finished with value: 0.5413416744842374 and parameters: {'learning_rate': 0.0002611980314589105, 'batch_size': 8, 'warmup_steps': 196, 'weight_decay': 0.00713436531661694}. Best is trial 22 with value: 0.586500525139622.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4536' max='5040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4536/5040 01:39 < 00:11, 45.56 it/s, Epoch 27/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1704.669800</td>\n",
       "      <td>1056.615356</td>\n",
       "      <td>0.327079</td>\n",
       "      <td>0.059311</td>\n",
       "      <td>0.366116</td>\n",
       "      <td>1056.615356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>830.081900</td>\n",
       "      <td>702.317078</td>\n",
       "      <td>0.266662</td>\n",
       "      <td>0.257431</td>\n",
       "      <td>0.495385</td>\n",
       "      <td>702.317139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>702.933000</td>\n",
       "      <td>689.908752</td>\n",
       "      <td>0.264296</td>\n",
       "      <td>0.282790</td>\n",
       "      <td>0.509247</td>\n",
       "      <td>689.908752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>684.652600</td>\n",
       "      <td>653.572083</td>\n",
       "      <td>0.257241</td>\n",
       "      <td>0.336569</td>\n",
       "      <td>0.539664</td>\n",
       "      <td>653.572083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>627.908000</td>\n",
       "      <td>630.234558</td>\n",
       "      <td>0.252607</td>\n",
       "      <td>0.307855</td>\n",
       "      <td>0.527624</td>\n",
       "      <td>630.234558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>604.988500</td>\n",
       "      <td>627.397034</td>\n",
       "      <td>0.252038</td>\n",
       "      <td>0.313236</td>\n",
       "      <td>0.530599</td>\n",
       "      <td>627.397034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>611.071100</td>\n",
       "      <td>652.070923</td>\n",
       "      <td>0.256946</td>\n",
       "      <td>0.342037</td>\n",
       "      <td>0.542546</td>\n",
       "      <td>652.070923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>530.985900</td>\n",
       "      <td>652.383789</td>\n",
       "      <td>0.257008</td>\n",
       "      <td>0.335833</td>\n",
       "      <td>0.539413</td>\n",
       "      <td>652.383789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>510.774800</td>\n",
       "      <td>697.314087</td>\n",
       "      <td>0.265710</td>\n",
       "      <td>0.348250</td>\n",
       "      <td>0.541270</td>\n",
       "      <td>697.314087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>432.323600</td>\n",
       "      <td>653.663696</td>\n",
       "      <td>0.257260</td>\n",
       "      <td>0.347904</td>\n",
       "      <td>0.545322</td>\n",
       "      <td>653.663696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>425.700800</td>\n",
       "      <td>673.089417</td>\n",
       "      <td>0.261054</td>\n",
       "      <td>0.322841</td>\n",
       "      <td>0.530894</td>\n",
       "      <td>673.089417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>400.904000</td>\n",
       "      <td>671.783691</td>\n",
       "      <td>0.260801</td>\n",
       "      <td>0.336221</td>\n",
       "      <td>0.537710</td>\n",
       "      <td>671.783691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>341.791500</td>\n",
       "      <td>683.645081</td>\n",
       "      <td>0.263093</td>\n",
       "      <td>0.359646</td>\n",
       "      <td>0.548276</td>\n",
       "      <td>683.645081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>348.831100</td>\n",
       "      <td>676.302979</td>\n",
       "      <td>0.261677</td>\n",
       "      <td>0.357927</td>\n",
       "      <td>0.548125</td>\n",
       "      <td>676.302979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>314.754500</td>\n",
       "      <td>715.976562</td>\n",
       "      <td>0.269243</td>\n",
       "      <td>0.324465</td>\n",
       "      <td>0.527611</td>\n",
       "      <td>715.976562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>280.613800</td>\n",
       "      <td>733.192810</td>\n",
       "      <td>0.272460</td>\n",
       "      <td>0.372842</td>\n",
       "      <td>0.550191</td>\n",
       "      <td>733.192749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>263.610800</td>\n",
       "      <td>768.749451</td>\n",
       "      <td>0.278989</td>\n",
       "      <td>0.321720</td>\n",
       "      <td>0.521366</td>\n",
       "      <td>768.749451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>267.710400</td>\n",
       "      <td>730.581238</td>\n",
       "      <td>0.271975</td>\n",
       "      <td>0.348074</td>\n",
       "      <td>0.538050</td>\n",
       "      <td>730.581238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>226.249700</td>\n",
       "      <td>710.122314</td>\n",
       "      <td>0.268140</td>\n",
       "      <td>0.375056</td>\n",
       "      <td>0.553458</td>\n",
       "      <td>710.122314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>199.409000</td>\n",
       "      <td>723.828552</td>\n",
       "      <td>0.270715</td>\n",
       "      <td>0.366222</td>\n",
       "      <td>0.547754</td>\n",
       "      <td>723.828552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>204.503300</td>\n",
       "      <td>726.848450</td>\n",
       "      <td>0.271279</td>\n",
       "      <td>0.361889</td>\n",
       "      <td>0.545305</td>\n",
       "      <td>726.848450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>186.457700</td>\n",
       "      <td>711.360779</td>\n",
       "      <td>0.268373</td>\n",
       "      <td>0.381537</td>\n",
       "      <td>0.556582</td>\n",
       "      <td>711.360779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>177.910600</td>\n",
       "      <td>743.962830</td>\n",
       "      <td>0.274454</td>\n",
       "      <td>0.360805</td>\n",
       "      <td>0.543175</td>\n",
       "      <td>743.962830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>162.017200</td>\n",
       "      <td>740.314697</td>\n",
       "      <td>0.273780</td>\n",
       "      <td>0.373717</td>\n",
       "      <td>0.549969</td>\n",
       "      <td>740.314697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>140.952800</td>\n",
       "      <td>710.953247</td>\n",
       "      <td>0.268296</td>\n",
       "      <td>0.358627</td>\n",
       "      <td>0.545165</td>\n",
       "      <td>710.953308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>125.067700</td>\n",
       "      <td>746.282227</td>\n",
       "      <td>0.274882</td>\n",
       "      <td>0.354712</td>\n",
       "      <td>0.539915</td>\n",
       "      <td>746.282227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>140.722100</td>\n",
       "      <td>736.250854</td>\n",
       "      <td>0.273028</td>\n",
       "      <td>0.368638</td>\n",
       "      <td>0.547805</td>\n",
       "      <td>736.250854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 12:14:46,880] Trial 32 finished with value: 0.5565819183371122 and parameters: {'learning_rate': 0.0003728309996441753, 'batch_size': 8, 'warmup_steps': 239, 'weight_decay': 0.005604628888021623}. Best is trial 22 with value: 0.586500525139622.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1848' max='5040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1848/5040 00:40 < 01:09, 45.84 it/s, Epoch 11/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1722.423900</td>\n",
       "      <td>1142.609741</td>\n",
       "      <td>0.340129</td>\n",
       "      <td>0.153153</td>\n",
       "      <td>0.406512</td>\n",
       "      <td>1142.609741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>907.603900</td>\n",
       "      <td>730.482178</td>\n",
       "      <td>0.271956</td>\n",
       "      <td>0.314449</td>\n",
       "      <td>0.521246</td>\n",
       "      <td>730.482239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>706.556900</td>\n",
       "      <td>696.040710</td>\n",
       "      <td>0.265468</td>\n",
       "      <td>0.319352</td>\n",
       "      <td>0.526942</td>\n",
       "      <td>696.040771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>701.096500</td>\n",
       "      <td>648.942139</td>\n",
       "      <td>0.256329</td>\n",
       "      <td>0.306056</td>\n",
       "      <td>0.524864</td>\n",
       "      <td>648.942139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>652.165600</td>\n",
       "      <td>642.132507</td>\n",
       "      <td>0.254980</td>\n",
       "      <td>0.284213</td>\n",
       "      <td>0.514616</td>\n",
       "      <td>642.132507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>622.196100</td>\n",
       "      <td>617.340820</td>\n",
       "      <td>0.250010</td>\n",
       "      <td>0.347993</td>\n",
       "      <td>0.548992</td>\n",
       "      <td>617.340820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>617.828000</td>\n",
       "      <td>659.332458</td>\n",
       "      <td>0.258373</td>\n",
       "      <td>0.319743</td>\n",
       "      <td>0.530685</td>\n",
       "      <td>659.332458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>558.468800</td>\n",
       "      <td>656.786926</td>\n",
       "      <td>0.257873</td>\n",
       "      <td>0.251326</td>\n",
       "      <td>0.496727</td>\n",
       "      <td>656.786926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>535.891300</td>\n",
       "      <td>741.188599</td>\n",
       "      <td>0.273942</td>\n",
       "      <td>0.320385</td>\n",
       "      <td>0.523222</td>\n",
       "      <td>741.188599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>450.478500</td>\n",
       "      <td>686.066223</td>\n",
       "      <td>0.263559</td>\n",
       "      <td>0.326147</td>\n",
       "      <td>0.531294</td>\n",
       "      <td>686.066223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>463.562600</td>\n",
       "      <td>672.532288</td>\n",
       "      <td>0.260946</td>\n",
       "      <td>0.319003</td>\n",
       "      <td>0.529029</td>\n",
       "      <td>672.532288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 12:15:28,765] Trial 33 finished with value: 0.548991880554232 and parameters: {'learning_rate': 0.0002560954956321345, 'batch_size': 8, 'warmup_steps': 200, 'weight_decay': 0.00895532403127346}. Best is trial 22 with value: 0.586500525139622.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2184' max='5040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2184/5040 00:48 < 01:03, 45.26 it/s, Epoch 13/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1729.465600</td>\n",
       "      <td>1198.273438</td>\n",
       "      <td>0.348315</td>\n",
       "      <td>0.018103</td>\n",
       "      <td>0.334894</td>\n",
       "      <td>1198.273438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>998.290700</td>\n",
       "      <td>788.610901</td>\n",
       "      <td>0.282570</td>\n",
       "      <td>0.171989</td>\n",
       "      <td>0.444709</td>\n",
       "      <td>788.610901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>729.773200</td>\n",
       "      <td>706.800781</td>\n",
       "      <td>0.267512</td>\n",
       "      <td>0.325024</td>\n",
       "      <td>0.528756</td>\n",
       "      <td>706.800781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>711.255500</td>\n",
       "      <td>695.391113</td>\n",
       "      <td>0.265344</td>\n",
       "      <td>0.339462</td>\n",
       "      <td>0.537059</td>\n",
       "      <td>695.391113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>688.152300</td>\n",
       "      <td>657.713074</td>\n",
       "      <td>0.258055</td>\n",
       "      <td>0.271509</td>\n",
       "      <td>0.506727</td>\n",
       "      <td>657.713074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>655.132300</td>\n",
       "      <td>647.350769</td>\n",
       "      <td>0.256014</td>\n",
       "      <td>0.268032</td>\n",
       "      <td>0.506009</td>\n",
       "      <td>647.350769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>656.461500</td>\n",
       "      <td>668.289612</td>\n",
       "      <td>0.260122</td>\n",
       "      <td>0.278501</td>\n",
       "      <td>0.509190</td>\n",
       "      <td>668.289612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>593.671100</td>\n",
       "      <td>662.269958</td>\n",
       "      <td>0.258948</td>\n",
       "      <td>0.333149</td>\n",
       "      <td>0.537101</td>\n",
       "      <td>662.270020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>591.510400</td>\n",
       "      <td>687.443604</td>\n",
       "      <td>0.263823</td>\n",
       "      <td>0.293596</td>\n",
       "      <td>0.514886</td>\n",
       "      <td>687.443665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>539.545700</td>\n",
       "      <td>664.597900</td>\n",
       "      <td>0.259402</td>\n",
       "      <td>0.309912</td>\n",
       "      <td>0.525255</td>\n",
       "      <td>664.597839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>536.684500</td>\n",
       "      <td>654.051453</td>\n",
       "      <td>0.257336</td>\n",
       "      <td>0.292779</td>\n",
       "      <td>0.517721</td>\n",
       "      <td>654.051453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>464.893400</td>\n",
       "      <td>704.598694</td>\n",
       "      <td>0.267095</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.497600</td>\n",
       "      <td>704.598694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>451.869400</td>\n",
       "      <td>697.770752</td>\n",
       "      <td>0.265797</td>\n",
       "      <td>0.285962</td>\n",
       "      <td>0.510082</td>\n",
       "      <td>697.770752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 12:16:18,441] Trial 34 finished with value: 0.5371005569361992 and parameters: {'learning_rate': 0.0001807533450329042, 'batch_size': 8, 'warmup_steps': 160, 'weight_decay': 0.0031469480060628144}. Best is trial 22 with value: 0.586500525139622.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3024' max='5040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3024/5040 01:06 < 00:44, 45.75 it/s, Epoch 18/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1769.843900</td>\n",
       "      <td>1497.587524</td>\n",
       "      <td>0.389395</td>\n",
       "      <td>0.167870</td>\n",
       "      <td>0.389238</td>\n",
       "      <td>1497.587524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1345.185600</td>\n",
       "      <td>1064.710449</td>\n",
       "      <td>0.328330</td>\n",
       "      <td>0.169529</td>\n",
       "      <td>0.420600</td>\n",
       "      <td>1064.710449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>933.492300</td>\n",
       "      <td>860.216614</td>\n",
       "      <td>0.295120</td>\n",
       "      <td>0.106554</td>\n",
       "      <td>0.405717</td>\n",
       "      <td>860.216614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>861.540200</td>\n",
       "      <td>766.623535</td>\n",
       "      <td>0.278603</td>\n",
       "      <td>0.117128</td>\n",
       "      <td>0.419263</td>\n",
       "      <td>766.623535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>749.749400</td>\n",
       "      <td>724.647278</td>\n",
       "      <td>0.270868</td>\n",
       "      <td>0.231930</td>\n",
       "      <td>0.480531</td>\n",
       "      <td>724.647278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>721.375800</td>\n",
       "      <td>706.367981</td>\n",
       "      <td>0.267430</td>\n",
       "      <td>0.327047</td>\n",
       "      <td>0.529809</td>\n",
       "      <td>706.367981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>736.323000</td>\n",
       "      <td>700.117065</td>\n",
       "      <td>0.266244</td>\n",
       "      <td>0.323904</td>\n",
       "      <td>0.528830</td>\n",
       "      <td>700.117065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>692.571600</td>\n",
       "      <td>696.341675</td>\n",
       "      <td>0.265525</td>\n",
       "      <td>0.302411</td>\n",
       "      <td>0.518443</td>\n",
       "      <td>696.341614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>703.573800</td>\n",
       "      <td>690.276184</td>\n",
       "      <td>0.264366</td>\n",
       "      <td>0.270968</td>\n",
       "      <td>0.503301</td>\n",
       "      <td>690.276123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>660.984900</td>\n",
       "      <td>652.188599</td>\n",
       "      <td>0.256969</td>\n",
       "      <td>0.343568</td>\n",
       "      <td>0.543300</td>\n",
       "      <td>652.188599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>671.297900</td>\n",
       "      <td>645.683716</td>\n",
       "      <td>0.255684</td>\n",
       "      <td>0.287525</td>\n",
       "      <td>0.515920</td>\n",
       "      <td>645.683777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>626.881700</td>\n",
       "      <td>637.448914</td>\n",
       "      <td>0.254049</td>\n",
       "      <td>0.303343</td>\n",
       "      <td>0.524647</td>\n",
       "      <td>637.448914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>601.265100</td>\n",
       "      <td>627.460144</td>\n",
       "      <td>0.252050</td>\n",
       "      <td>0.344100</td>\n",
       "      <td>0.546025</td>\n",
       "      <td>627.460144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>587.193200</td>\n",
       "      <td>678.601318</td>\n",
       "      <td>0.262121</td>\n",
       "      <td>0.354045</td>\n",
       "      <td>0.545962</td>\n",
       "      <td>678.601318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>556.741900</td>\n",
       "      <td>644.768433</td>\n",
       "      <td>0.255503</td>\n",
       "      <td>0.342887</td>\n",
       "      <td>0.543692</td>\n",
       "      <td>644.768433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>550.267000</td>\n",
       "      <td>698.587646</td>\n",
       "      <td>0.265953</td>\n",
       "      <td>0.327126</td>\n",
       "      <td>0.530586</td>\n",
       "      <td>698.587646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>520.417000</td>\n",
       "      <td>685.433044</td>\n",
       "      <td>0.263437</td>\n",
       "      <td>0.321398</td>\n",
       "      <td>0.528981</td>\n",
       "      <td>685.433105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>529.259400</td>\n",
       "      <td>690.176819</td>\n",
       "      <td>0.264347</td>\n",
       "      <td>0.310745</td>\n",
       "      <td>0.523199</td>\n",
       "      <td>690.176758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 12:17:25,865] Trial 35 finished with value: 0.5460248636433033 and parameters: {'learning_rate': 9.165791192380296e-05, 'batch_size': 8, 'warmup_steps': 185, 'weight_decay': 0.0019927136219824245}. Best is trial 22 with value: 0.586500525139622.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1512' max='5040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1512/5040 00:33 < 01:17, 45.63 it/s, Epoch 9/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1663.566900</td>\n",
       "      <td>910.618408</td>\n",
       "      <td>0.303642</td>\n",
       "      <td>0.132197</td>\n",
       "      <td>0.414277</td>\n",
       "      <td>910.618530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>756.261200</td>\n",
       "      <td>694.707153</td>\n",
       "      <td>0.265213</td>\n",
       "      <td>0.247914</td>\n",
       "      <td>0.491350</td>\n",
       "      <td>694.707092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>677.648400</td>\n",
       "      <td>658.501709</td>\n",
       "      <td>0.258210</td>\n",
       "      <td>0.255009</td>\n",
       "      <td>0.498399</td>\n",
       "      <td>658.501648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>669.292300</td>\n",
       "      <td>624.571655</td>\n",
       "      <td>0.251470</td>\n",
       "      <td>0.387020</td>\n",
       "      <td>0.567775</td>\n",
       "      <td>624.571655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>624.862000</td>\n",
       "      <td>603.412292</td>\n",
       "      <td>0.247173</td>\n",
       "      <td>0.376833</td>\n",
       "      <td>0.564830</td>\n",
       "      <td>603.412354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>607.596100</td>\n",
       "      <td>619.134338</td>\n",
       "      <td>0.250373</td>\n",
       "      <td>0.343739</td>\n",
       "      <td>0.546683</td>\n",
       "      <td>619.134338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>616.288400</td>\n",
       "      <td>649.236450</td>\n",
       "      <td>0.256387</td>\n",
       "      <td>0.309064</td>\n",
       "      <td>0.526338</td>\n",
       "      <td>649.236389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>573.485800</td>\n",
       "      <td>642.011292</td>\n",
       "      <td>0.254956</td>\n",
       "      <td>0.312534</td>\n",
       "      <td>0.528789</td>\n",
       "      <td>642.011292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>563.709300</td>\n",
       "      <td>661.115723</td>\n",
       "      <td>0.258722</td>\n",
       "      <td>0.326228</td>\n",
       "      <td>0.533753</td>\n",
       "      <td>661.115723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 12:18:00,335] Trial 36 finished with value: 0.5677752979666635 and parameters: {'learning_rate': 0.00047402932121922396, 'batch_size': 8, 'warmup_steps': 211, 'weight_decay': 0.01335554660827537}. Best is trial 22 with value: 0.586500525139622.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2016' max='5040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2016/5040 00:43 < 01:05, 45.92 it/s, Epoch 12/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1685.261100</td>\n",
       "      <td>995.154785</td>\n",
       "      <td>0.317424</td>\n",
       "      <td>0.081190</td>\n",
       "      <td>0.381883</td>\n",
       "      <td>995.154846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>840.419600</td>\n",
       "      <td>716.890198</td>\n",
       "      <td>0.269414</td>\n",
       "      <td>0.248827</td>\n",
       "      <td>0.489706</td>\n",
       "      <td>716.890198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>710.144200</td>\n",
       "      <td>683.484802</td>\n",
       "      <td>0.263062</td>\n",
       "      <td>0.312376</td>\n",
       "      <td>0.524657</td>\n",
       "      <td>683.484802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>690.754600</td>\n",
       "      <td>646.643799</td>\n",
       "      <td>0.255874</td>\n",
       "      <td>0.281685</td>\n",
       "      <td>0.512905</td>\n",
       "      <td>646.643799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>640.466000</td>\n",
       "      <td>629.212952</td>\n",
       "      <td>0.252402</td>\n",
       "      <td>0.322873</td>\n",
       "      <td>0.535236</td>\n",
       "      <td>629.212952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>605.575000</td>\n",
       "      <td>623.111450</td>\n",
       "      <td>0.251175</td>\n",
       "      <td>0.323978</td>\n",
       "      <td>0.536401</td>\n",
       "      <td>623.111450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>597.094600</td>\n",
       "      <td>633.192993</td>\n",
       "      <td>0.253199</td>\n",
       "      <td>0.368940</td>\n",
       "      <td>0.557870</td>\n",
       "      <td>633.193054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>536.976900</td>\n",
       "      <td>631.218262</td>\n",
       "      <td>0.252804</td>\n",
       "      <td>0.322878</td>\n",
       "      <td>0.535037</td>\n",
       "      <td>631.218262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>531.069400</td>\n",
       "      <td>686.316833</td>\n",
       "      <td>0.263607</td>\n",
       "      <td>0.330694</td>\n",
       "      <td>0.533544</td>\n",
       "      <td>686.316833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>461.363900</td>\n",
       "      <td>647.976562</td>\n",
       "      <td>0.256138</td>\n",
       "      <td>0.363504</td>\n",
       "      <td>0.553683</td>\n",
       "      <td>647.976562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>445.492500</td>\n",
       "      <td>688.161316</td>\n",
       "      <td>0.263961</td>\n",
       "      <td>0.265132</td>\n",
       "      <td>0.500585</td>\n",
       "      <td>688.161377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>418.821400</td>\n",
       "      <td>668.523376</td>\n",
       "      <td>0.260167</td>\n",
       "      <td>0.321645</td>\n",
       "      <td>0.530739</td>\n",
       "      <td>668.523315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 12:18:45,582] Trial 37 finished with value: 0.5578701748213815 and parameters: {'learning_rate': 0.0002559317148537725, 'batch_size': 8, 'warmup_steps': 130, 'weight_decay': 0.09526261766589357}. Best is trial 22 with value: 0.586500525139622.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2520' max='2520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2520/2520 01:11, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1733.681030</td>\n",
       "      <td>0.418966</td>\n",
       "      <td>0.134331</td>\n",
       "      <td>0.357682</td>\n",
       "      <td>1733.681030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1786.424700</td>\n",
       "      <td>1610.529663</td>\n",
       "      <td>0.403811</td>\n",
       "      <td>0.037563</td>\n",
       "      <td>0.316876</td>\n",
       "      <td>1610.529663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1738.556100</td>\n",
       "      <td>1431.932861</td>\n",
       "      <td>0.380764</td>\n",
       "      <td>0.114037</td>\n",
       "      <td>0.366637</td>\n",
       "      <td>1431.932983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1498.297000</td>\n",
       "      <td>1275.650757</td>\n",
       "      <td>0.359385</td>\n",
       "      <td>0.141702</td>\n",
       "      <td>0.391159</td>\n",
       "      <td>1275.650879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1280.623000</td>\n",
       "      <td>1156.720947</td>\n",
       "      <td>0.342222</td>\n",
       "      <td>0.126606</td>\n",
       "      <td>0.392192</td>\n",
       "      <td>1156.720825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1189.832300</td>\n",
       "      <td>1065.408081</td>\n",
       "      <td>0.328437</td>\n",
       "      <td>0.143273</td>\n",
       "      <td>0.407418</td>\n",
       "      <td>1065.408081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1189.832300</td>\n",
       "      <td>993.599121</td>\n",
       "      <td>0.317176</td>\n",
       "      <td>0.202151</td>\n",
       "      <td>0.442488</td>\n",
       "      <td>993.599060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1060.765500</td>\n",
       "      <td>935.655884</td>\n",
       "      <td>0.307788</td>\n",
       "      <td>0.173562</td>\n",
       "      <td>0.432887</td>\n",
       "      <td>935.655884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>966.435200</td>\n",
       "      <td>889.316650</td>\n",
       "      <td>0.300070</td>\n",
       "      <td>0.187287</td>\n",
       "      <td>0.443609</td>\n",
       "      <td>889.316772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>941.018000</td>\n",
       "      <td>851.025391</td>\n",
       "      <td>0.293539</td>\n",
       "      <td>0.242337</td>\n",
       "      <td>0.474399</td>\n",
       "      <td>851.025513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>897.221700</td>\n",
       "      <td>820.000000</td>\n",
       "      <td>0.288138</td>\n",
       "      <td>0.251242</td>\n",
       "      <td>0.481552</td>\n",
       "      <td>820.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>818.393900</td>\n",
       "      <td>795.496765</td>\n",
       "      <td>0.283801</td>\n",
       "      <td>0.251566</td>\n",
       "      <td>0.483882</td>\n",
       "      <td>795.496765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>818.393900</td>\n",
       "      <td>775.415405</td>\n",
       "      <td>0.280196</td>\n",
       "      <td>0.229178</td>\n",
       "      <td>0.474491</td>\n",
       "      <td>775.415405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>796.977000</td>\n",
       "      <td>759.758301</td>\n",
       "      <td>0.277352</td>\n",
       "      <td>0.195279</td>\n",
       "      <td>0.458964</td>\n",
       "      <td>759.758301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>797.053800</td>\n",
       "      <td>748.383545</td>\n",
       "      <td>0.275268</td>\n",
       "      <td>0.295190</td>\n",
       "      <td>0.509961</td>\n",
       "      <td>748.383545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>759.317200</td>\n",
       "      <td>739.517761</td>\n",
       "      <td>0.273633</td>\n",
       "      <td>0.261928</td>\n",
       "      <td>0.494147</td>\n",
       "      <td>739.517822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>750.458400</td>\n",
       "      <td>730.662720</td>\n",
       "      <td>0.271990</td>\n",
       "      <td>0.270139</td>\n",
       "      <td>0.499075</td>\n",
       "      <td>730.662659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>750.434500</td>\n",
       "      <td>725.335876</td>\n",
       "      <td>0.270997</td>\n",
       "      <td>0.326219</td>\n",
       "      <td>0.527611</td>\n",
       "      <td>725.335876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>750.434500</td>\n",
       "      <td>720.316406</td>\n",
       "      <td>0.270057</td>\n",
       "      <td>0.320718</td>\n",
       "      <td>0.525330</td>\n",
       "      <td>720.316345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>730.989800</td>\n",
       "      <td>716.649109</td>\n",
       "      <td>0.269369</td>\n",
       "      <td>0.324954</td>\n",
       "      <td>0.527793</td>\n",
       "      <td>716.649170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>726.976400</td>\n",
       "      <td>713.789246</td>\n",
       "      <td>0.268831</td>\n",
       "      <td>0.325678</td>\n",
       "      <td>0.528423</td>\n",
       "      <td>713.789246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>732.304500</td>\n",
       "      <td>711.560425</td>\n",
       "      <td>0.268411</td>\n",
       "      <td>0.324059</td>\n",
       "      <td>0.527824</td>\n",
       "      <td>711.560364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>733.007900</td>\n",
       "      <td>709.798889</td>\n",
       "      <td>0.268078</td>\n",
       "      <td>0.334030</td>\n",
       "      <td>0.532976</td>\n",
       "      <td>709.798889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>702.689100</td>\n",
       "      <td>708.373169</td>\n",
       "      <td>0.267809</td>\n",
       "      <td>0.333725</td>\n",
       "      <td>0.532958</td>\n",
       "      <td>708.373169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>724.008400</td>\n",
       "      <td>707.277222</td>\n",
       "      <td>0.267602</td>\n",
       "      <td>0.331377</td>\n",
       "      <td>0.531888</td>\n",
       "      <td>707.277222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>724.008400</td>\n",
       "      <td>706.471924</td>\n",
       "      <td>0.267449</td>\n",
       "      <td>0.333463</td>\n",
       "      <td>0.533007</td>\n",
       "      <td>706.471924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>709.030200</td>\n",
       "      <td>705.785950</td>\n",
       "      <td>0.267320</td>\n",
       "      <td>0.335054</td>\n",
       "      <td>0.533867</td>\n",
       "      <td>705.785950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>715.445300</td>\n",
       "      <td>705.388184</td>\n",
       "      <td>0.267244</td>\n",
       "      <td>0.337080</td>\n",
       "      <td>0.534918</td>\n",
       "      <td>705.388184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>728.388500</td>\n",
       "      <td>705.131287</td>\n",
       "      <td>0.267196</td>\n",
       "      <td>0.335600</td>\n",
       "      <td>0.534202</td>\n",
       "      <td>705.131287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>707.902400</td>\n",
       "      <td>705.038330</td>\n",
       "      <td>0.267178</td>\n",
       "      <td>0.335589</td>\n",
       "      <td>0.534206</td>\n",
       "      <td>705.038391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 12:19:58,732] Trial 38 finished with value: 0.5349177128965991 and parameters: {'learning_rate': 5.431580333958241e-05, 'batch_size': 16, 'warmup_steps': 225, 'weight_decay': 0.004733887818902757}. Best is trial 22 with value: 0.586500525139622.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5040' max='5040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5040/5040 01:50, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1790.811200</td>\n",
       "      <td>1745.381714</td>\n",
       "      <td>0.420377</td>\n",
       "      <td>0.113663</td>\n",
       "      <td>0.346643</td>\n",
       "      <td>1745.381714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1827.847800</td>\n",
       "      <td>1702.627563</td>\n",
       "      <td>0.415197</td>\n",
       "      <td>0.139665</td>\n",
       "      <td>0.362234</td>\n",
       "      <td>1702.627563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1694.090800</td>\n",
       "      <td>1635.689941</td>\n",
       "      <td>0.406953</td>\n",
       "      <td>0.127603</td>\n",
       "      <td>0.360325</td>\n",
       "      <td>1635.689941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1696.605000</td>\n",
       "      <td>1574.454346</td>\n",
       "      <td>0.399263</td>\n",
       "      <td>0.144369</td>\n",
       "      <td>0.372553</td>\n",
       "      <td>1574.454590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1575.314500</td>\n",
       "      <td>1518.512573</td>\n",
       "      <td>0.392106</td>\n",
       "      <td>0.160032</td>\n",
       "      <td>0.383963</td>\n",
       "      <td>1518.512573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1567.739400</td>\n",
       "      <td>1466.908936</td>\n",
       "      <td>0.385386</td>\n",
       "      <td>0.163369</td>\n",
       "      <td>0.388992</td>\n",
       "      <td>1466.908813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1565.408800</td>\n",
       "      <td>1419.416138</td>\n",
       "      <td>0.379096</td>\n",
       "      <td>0.167936</td>\n",
       "      <td>0.394420</td>\n",
       "      <td>1419.416138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1467.699800</td>\n",
       "      <td>1376.193848</td>\n",
       "      <td>0.373279</td>\n",
       "      <td>0.165677</td>\n",
       "      <td>0.396199</td>\n",
       "      <td>1376.193848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1473.939800</td>\n",
       "      <td>1336.861450</td>\n",
       "      <td>0.367906</td>\n",
       "      <td>0.167331</td>\n",
       "      <td>0.399712</td>\n",
       "      <td>1336.861450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1380.096700</td>\n",
       "      <td>1301.560181</td>\n",
       "      <td>0.363017</td>\n",
       "      <td>0.163508</td>\n",
       "      <td>0.400246</td>\n",
       "      <td>1301.560181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1408.821600</td>\n",
       "      <td>1269.735107</td>\n",
       "      <td>0.358551</td>\n",
       "      <td>0.161371</td>\n",
       "      <td>0.401410</td>\n",
       "      <td>1269.734985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1330.854800</td>\n",
       "      <td>1241.134888</td>\n",
       "      <td>0.354490</td>\n",
       "      <td>0.155678</td>\n",
       "      <td>0.400594</td>\n",
       "      <td>1241.134888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1301.672000</td>\n",
       "      <td>1215.746094</td>\n",
       "      <td>0.350845</td>\n",
       "      <td>0.159969</td>\n",
       "      <td>0.404562</td>\n",
       "      <td>1215.746094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1272.154000</td>\n",
       "      <td>1192.979370</td>\n",
       "      <td>0.347545</td>\n",
       "      <td>0.159424</td>\n",
       "      <td>0.405940</td>\n",
       "      <td>1192.979370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1238.259800</td>\n",
       "      <td>1172.427246</td>\n",
       "      <td>0.344538</td>\n",
       "      <td>0.171745</td>\n",
       "      <td>0.413603</td>\n",
       "      <td>1172.427124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1176.456500</td>\n",
       "      <td>1153.890137</td>\n",
       "      <td>0.341803</td>\n",
       "      <td>0.165040</td>\n",
       "      <td>0.411618</td>\n",
       "      <td>1153.890259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1167.733400</td>\n",
       "      <td>1137.274170</td>\n",
       "      <td>0.339334</td>\n",
       "      <td>0.169502</td>\n",
       "      <td>0.415084</td>\n",
       "      <td>1137.274170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1243.366600</td>\n",
       "      <td>1122.622559</td>\n",
       "      <td>0.337141</td>\n",
       "      <td>0.170920</td>\n",
       "      <td>0.416890</td>\n",
       "      <td>1122.622559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1171.827700</td>\n",
       "      <td>1109.519897</td>\n",
       "      <td>0.335167</td>\n",
       "      <td>0.168425</td>\n",
       "      <td>0.416629</td>\n",
       "      <td>1109.519897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1103.039200</td>\n",
       "      <td>1097.740601</td>\n",
       "      <td>0.333384</td>\n",
       "      <td>0.164873</td>\n",
       "      <td>0.415745</td>\n",
       "      <td>1097.740601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1157.668300</td>\n",
       "      <td>1087.520264</td>\n",
       "      <td>0.331828</td>\n",
       "      <td>0.165244</td>\n",
       "      <td>0.416708</td>\n",
       "      <td>1087.520264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1108.683900</td>\n",
       "      <td>1078.620972</td>\n",
       "      <td>0.330467</td>\n",
       "      <td>0.167039</td>\n",
       "      <td>0.418286</td>\n",
       "      <td>1078.620972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1151.545300</td>\n",
       "      <td>1070.754883</td>\n",
       "      <td>0.329260</td>\n",
       "      <td>0.169484</td>\n",
       "      <td>0.420112</td>\n",
       "      <td>1070.754883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1113.081400</td>\n",
       "      <td>1064.268677</td>\n",
       "      <td>0.328261</td>\n",
       "      <td>0.175727</td>\n",
       "      <td>0.423733</td>\n",
       "      <td>1064.268677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1098.447500</td>\n",
       "      <td>1058.746338</td>\n",
       "      <td>0.327409</td>\n",
       "      <td>0.180431</td>\n",
       "      <td>0.426511</td>\n",
       "      <td>1058.746338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1097.438300</td>\n",
       "      <td>1054.267822</td>\n",
       "      <td>0.326715</td>\n",
       "      <td>0.183766</td>\n",
       "      <td>0.428525</td>\n",
       "      <td>1054.267822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1093.897600</td>\n",
       "      <td>1050.868896</td>\n",
       "      <td>0.326188</td>\n",
       "      <td>0.180990</td>\n",
       "      <td>0.427401</td>\n",
       "      <td>1050.869019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1098.326500</td>\n",
       "      <td>1048.425903</td>\n",
       "      <td>0.325809</td>\n",
       "      <td>0.182540</td>\n",
       "      <td>0.428365</td>\n",
       "      <td>1048.426025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1101.172500</td>\n",
       "      <td>1046.941772</td>\n",
       "      <td>0.325578</td>\n",
       "      <td>0.182653</td>\n",
       "      <td>0.428537</td>\n",
       "      <td>1046.941895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1076.963100</td>\n",
       "      <td>1046.445801</td>\n",
       "      <td>0.325501</td>\n",
       "      <td>0.183437</td>\n",
       "      <td>0.428968</td>\n",
       "      <td>1046.445801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 12:21:50,393] Trial 39 finished with value: 0.42896801369466864 and parameters: {'learning_rate': 9.189810555280745e-06, 'batch_size': 8, 'warmup_steps': 273, 'weight_decay': 0.06441439106875717}. Best is trial 22 with value: 0.586500525139622.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1260' max='1260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1260/1260 00:53, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1750.961182</td>\n",
       "      <td>0.421049</td>\n",
       "      <td>0.069655</td>\n",
       "      <td>0.324303</td>\n",
       "      <td>1750.961182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1738.205444</td>\n",
       "      <td>0.419512</td>\n",
       "      <td>0.148482</td>\n",
       "      <td>0.364485</td>\n",
       "      <td>1738.205444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1816.104800</td>\n",
       "      <td>1704.800049</td>\n",
       "      <td>0.415462</td>\n",
       "      <td>0.145158</td>\n",
       "      <td>0.364848</td>\n",
       "      <td>1704.800049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1816.104800</td>\n",
       "      <td>1645.293823</td>\n",
       "      <td>0.408146</td>\n",
       "      <td>0.138558</td>\n",
       "      <td>0.365206</td>\n",
       "      <td>1645.293823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1710.115900</td>\n",
       "      <td>1576.022217</td>\n",
       "      <td>0.399462</td>\n",
       "      <td>0.168491</td>\n",
       "      <td>0.384514</td>\n",
       "      <td>1576.022095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1710.115900</td>\n",
       "      <td>1508.998291</td>\n",
       "      <td>0.390876</td>\n",
       "      <td>0.167785</td>\n",
       "      <td>0.388455</td>\n",
       "      <td>1508.998291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1710.115900</td>\n",
       "      <td>1449.081177</td>\n",
       "      <td>0.383037</td>\n",
       "      <td>0.168137</td>\n",
       "      <td>0.392550</td>\n",
       "      <td>1449.081177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1581.539200</td>\n",
       "      <td>1395.589966</td>\n",
       "      <td>0.375901</td>\n",
       "      <td>0.172361</td>\n",
       "      <td>0.398230</td>\n",
       "      <td>1395.589844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1581.539200</td>\n",
       "      <td>1348.004028</td>\n",
       "      <td>0.369437</td>\n",
       "      <td>0.167793</td>\n",
       "      <td>0.399178</td>\n",
       "      <td>1348.004028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1441.285500</td>\n",
       "      <td>1305.946289</td>\n",
       "      <td>0.363628</td>\n",
       "      <td>0.166668</td>\n",
       "      <td>0.401520</td>\n",
       "      <td>1305.946289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1441.285500</td>\n",
       "      <td>1268.641968</td>\n",
       "      <td>0.358397</td>\n",
       "      <td>0.171751</td>\n",
       "      <td>0.406677</td>\n",
       "      <td>1268.641968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1335.571900</td>\n",
       "      <td>1235.578125</td>\n",
       "      <td>0.353695</td>\n",
       "      <td>0.175796</td>\n",
       "      <td>0.411050</td>\n",
       "      <td>1235.578125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1335.571900</td>\n",
       "      <td>1206.285034</td>\n",
       "      <td>0.349478</td>\n",
       "      <td>0.176692</td>\n",
       "      <td>0.413607</td>\n",
       "      <td>1206.285034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1335.571900</td>\n",
       "      <td>1180.164307</td>\n",
       "      <td>0.345673</td>\n",
       "      <td>0.183843</td>\n",
       "      <td>0.419085</td>\n",
       "      <td>1180.164185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1257.797900</td>\n",
       "      <td>1156.935425</td>\n",
       "      <td>0.342254</td>\n",
       "      <td>0.184603</td>\n",
       "      <td>0.421174</td>\n",
       "      <td>1156.935425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1257.797900</td>\n",
       "      <td>1136.262085</td>\n",
       "      <td>0.339183</td>\n",
       "      <td>0.169106</td>\n",
       "      <td>0.414962</td>\n",
       "      <td>1136.262085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1192.025900</td>\n",
       "      <td>1117.829956</td>\n",
       "      <td>0.336420</td>\n",
       "      <td>0.172529</td>\n",
       "      <td>0.418054</td>\n",
       "      <td>1117.829834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1192.025900</td>\n",
       "      <td>1101.437256</td>\n",
       "      <td>0.333944</td>\n",
       "      <td>0.169868</td>\n",
       "      <td>0.417962</td>\n",
       "      <td>1101.437256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1192.025900</td>\n",
       "      <td>1086.929321</td>\n",
       "      <td>0.331738</td>\n",
       "      <td>0.164476</td>\n",
       "      <td>0.416369</td>\n",
       "      <td>1086.929321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1151.727000</td>\n",
       "      <td>1074.078735</td>\n",
       "      <td>0.329771</td>\n",
       "      <td>0.178901</td>\n",
       "      <td>0.424565</td>\n",
       "      <td>1074.078857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1151.727000</td>\n",
       "      <td>1062.799316</td>\n",
       "      <td>0.328035</td>\n",
       "      <td>0.179640</td>\n",
       "      <td>0.425803</td>\n",
       "      <td>1062.799561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1114.327200</td>\n",
       "      <td>1052.960205</td>\n",
       "      <td>0.326513</td>\n",
       "      <td>0.178671</td>\n",
       "      <td>0.426079</td>\n",
       "      <td>1052.960083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1114.327200</td>\n",
       "      <td>1044.489258</td>\n",
       "      <td>0.325197</td>\n",
       "      <td>0.180246</td>\n",
       "      <td>0.427525</td>\n",
       "      <td>1044.489136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1087.342000</td>\n",
       "      <td>1037.254639</td>\n",
       "      <td>0.324069</td>\n",
       "      <td>0.183647</td>\n",
       "      <td>0.429789</td>\n",
       "      <td>1037.254639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1087.342000</td>\n",
       "      <td>1031.250854</td>\n",
       "      <td>0.323129</td>\n",
       "      <td>0.187533</td>\n",
       "      <td>0.432202</td>\n",
       "      <td>1031.250854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1087.342000</td>\n",
       "      <td>1026.392090</td>\n",
       "      <td>0.322367</td>\n",
       "      <td>0.185802</td>\n",
       "      <td>0.431717</td>\n",
       "      <td>1026.392212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1068.349500</td>\n",
       "      <td>1022.646973</td>\n",
       "      <td>0.321779</td>\n",
       "      <td>0.187337</td>\n",
       "      <td>0.432779</td>\n",
       "      <td>1022.646912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1068.349500</td>\n",
       "      <td>1019.985168</td>\n",
       "      <td>0.321360</td>\n",
       "      <td>0.184641</td>\n",
       "      <td>0.431641</td>\n",
       "      <td>1019.985046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1069.715000</td>\n",
       "      <td>1018.391418</td>\n",
       "      <td>0.321108</td>\n",
       "      <td>0.183213</td>\n",
       "      <td>0.431052</td>\n",
       "      <td>1018.391479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1069.715000</td>\n",
       "      <td>1017.852356</td>\n",
       "      <td>0.321023</td>\n",
       "      <td>0.183108</td>\n",
       "      <td>0.431042</td>\n",
       "      <td>1017.852478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 12:22:45,207] Trial 40 finished with value: 0.43277920202500136 and parameters: {'learning_rate': 3.656611119703801e-05, 'batch_size': 32, 'warmup_steps': 206, 'weight_decay': 0.010738187480246998}. Best is trial 22 with value: 0.586500525139622.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='924' max='2520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 924/2520 00:26 < 00:45, 35.20 it/s, Epoch 11/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1558.598999</td>\n",
       "      <td>0.397248</td>\n",
       "      <td>0.164305</td>\n",
       "      <td>0.383529</td>\n",
       "      <td>1558.598999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1715.596900</td>\n",
       "      <td>1084.697754</td>\n",
       "      <td>0.331397</td>\n",
       "      <td>0.185802</td>\n",
       "      <td>0.427202</td>\n",
       "      <td>1084.697754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1271.010900</td>\n",
       "      <td>775.025330</td>\n",
       "      <td>0.280125</td>\n",
       "      <td>0.170686</td>\n",
       "      <td>0.445281</td>\n",
       "      <td>775.025208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>814.216400</td>\n",
       "      <td>700.634644</td>\n",
       "      <td>0.266342</td>\n",
       "      <td>0.282966</td>\n",
       "      <td>0.508312</td>\n",
       "      <td>700.634644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>692.237000</td>\n",
       "      <td>660.616577</td>\n",
       "      <td>0.258624</td>\n",
       "      <td>0.321602</td>\n",
       "      <td>0.531489</td>\n",
       "      <td>660.616577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>690.134800</td>\n",
       "      <td>636.002014</td>\n",
       "      <td>0.253760</td>\n",
       "      <td>0.357050</td>\n",
       "      <td>0.551645</td>\n",
       "      <td>636.002014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>690.134800</td>\n",
       "      <td>636.598999</td>\n",
       "      <td>0.253879</td>\n",
       "      <td>0.323605</td>\n",
       "      <td>0.534863</td>\n",
       "      <td>636.599060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>638.028400</td>\n",
       "      <td>649.879639</td>\n",
       "      <td>0.256514</td>\n",
       "      <td>0.354517</td>\n",
       "      <td>0.549002</td>\n",
       "      <td>649.879639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>585.642300</td>\n",
       "      <td>626.107178</td>\n",
       "      <td>0.251778</td>\n",
       "      <td>0.350833</td>\n",
       "      <td>0.549527</td>\n",
       "      <td>626.107178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>551.081600</td>\n",
       "      <td>636.237549</td>\n",
       "      <td>0.253807</td>\n",
       "      <td>0.341964</td>\n",
       "      <td>0.544078</td>\n",
       "      <td>636.237549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>539.420900</td>\n",
       "      <td>642.288696</td>\n",
       "      <td>0.255011</td>\n",
       "      <td>0.339060</td>\n",
       "      <td>0.542024</td>\n",
       "      <td>642.288574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 12:23:12,680] Trial 41 finished with value: 0.5516448735277103 and parameters: {'learning_rate': 0.000315284444764623, 'batch_size': 16, 'warmup_steps': 220, 'weight_decay': 0.03615976609534856}. Best is trial 22 with value: 0.586500525139622.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1596' max='2520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1596/2520 00:45 < 00:26, 34.87 it/s, Epoch 19/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1538.550903</td>\n",
       "      <td>0.394685</td>\n",
       "      <td>0.085879</td>\n",
       "      <td>0.345597</td>\n",
       "      <td>1538.550781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1705.025500</td>\n",
       "      <td>1052.660156</td>\n",
       "      <td>0.326466</td>\n",
       "      <td>0.123422</td>\n",
       "      <td>0.398478</td>\n",
       "      <td>1052.660034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1239.779300</td>\n",
       "      <td>768.058777</td>\n",
       "      <td>0.278863</td>\n",
       "      <td>0.169137</td>\n",
       "      <td>0.445137</td>\n",
       "      <td>768.058777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>802.981200</td>\n",
       "      <td>701.538208</td>\n",
       "      <td>0.266514</td>\n",
       "      <td>0.268163</td>\n",
       "      <td>0.500824</td>\n",
       "      <td>701.538208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>692.633400</td>\n",
       "      <td>669.422302</td>\n",
       "      <td>0.260342</td>\n",
       "      <td>0.214152</td>\n",
       "      <td>0.476905</td>\n",
       "      <td>669.422302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>697.325500</td>\n",
       "      <td>659.553894</td>\n",
       "      <td>0.258416</td>\n",
       "      <td>0.276804</td>\n",
       "      <td>0.509194</td>\n",
       "      <td>659.553894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>697.325500</td>\n",
       "      <td>644.755859</td>\n",
       "      <td>0.255501</td>\n",
       "      <td>0.304788</td>\n",
       "      <td>0.524644</td>\n",
       "      <td>644.755859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>645.216600</td>\n",
       "      <td>651.522827</td>\n",
       "      <td>0.256838</td>\n",
       "      <td>0.276012</td>\n",
       "      <td>0.509587</td>\n",
       "      <td>651.522827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>578.555900</td>\n",
       "      <td>644.848267</td>\n",
       "      <td>0.255519</td>\n",
       "      <td>0.329293</td>\n",
       "      <td>0.536887</td>\n",
       "      <td>644.848206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>551.707600</td>\n",
       "      <td>665.190125</td>\n",
       "      <td>0.259518</td>\n",
       "      <td>0.340706</td>\n",
       "      <td>0.540594</td>\n",
       "      <td>665.190125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>536.471100</td>\n",
       "      <td>649.577820</td>\n",
       "      <td>0.256454</td>\n",
       "      <td>0.300595</td>\n",
       "      <td>0.522070</td>\n",
       "      <td>649.577820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>474.473900</td>\n",
       "      <td>697.379700</td>\n",
       "      <td>0.265723</td>\n",
       "      <td>0.324943</td>\n",
       "      <td>0.529610</td>\n",
       "      <td>697.379700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>474.473900</td>\n",
       "      <td>711.050537</td>\n",
       "      <td>0.268315</td>\n",
       "      <td>0.308117</td>\n",
       "      <td>0.519901</td>\n",
       "      <td>711.050476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>436.421800</td>\n",
       "      <td>692.086060</td>\n",
       "      <td>0.264712</td>\n",
       "      <td>0.375894</td>\n",
       "      <td>0.555591</td>\n",
       "      <td>692.085999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>416.410000</td>\n",
       "      <td>723.319458</td>\n",
       "      <td>0.270620</td>\n",
       "      <td>0.325260</td>\n",
       "      <td>0.527320</td>\n",
       "      <td>723.319458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>387.539200</td>\n",
       "      <td>729.001831</td>\n",
       "      <td>0.271681</td>\n",
       "      <td>0.303572</td>\n",
       "      <td>0.515946</td>\n",
       "      <td>729.001831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>344.875200</td>\n",
       "      <td>754.410278</td>\n",
       "      <td>0.276375</td>\n",
       "      <td>0.304436</td>\n",
       "      <td>0.514031</td>\n",
       "      <td>754.410278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>347.706800</td>\n",
       "      <td>710.120056</td>\n",
       "      <td>0.268139</td>\n",
       "      <td>0.320909</td>\n",
       "      <td>0.526385</td>\n",
       "      <td>710.120056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>347.706800</td>\n",
       "      <td>712.560974</td>\n",
       "      <td>0.268600</td>\n",
       "      <td>0.316452</td>\n",
       "      <td>0.523926</td>\n",
       "      <td>712.561035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 12:23:59,699] Trial 42 finished with value: 0.5555908485807775 and parameters: {'learning_rate': 0.00028965170062902933, 'batch_size': 16, 'warmup_steps': 192, 'weight_decay': 0.02670511048773002}. Best is trial 22 with value: 0.586500525139622.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1680' max='2520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1680/2520 00:47 < 00:23, 35.06 it/s, Epoch 20/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1528.215454</td>\n",
       "      <td>0.393357</td>\n",
       "      <td>0.138042</td>\n",
       "      <td>0.372343</td>\n",
       "      <td>1528.215332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1700.869700</td>\n",
       "      <td>1026.691895</td>\n",
       "      <td>0.322414</td>\n",
       "      <td>0.102440</td>\n",
       "      <td>0.390013</td>\n",
       "      <td>1026.691895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1213.359100</td>\n",
       "      <td>740.054443</td>\n",
       "      <td>0.273732</td>\n",
       "      <td>0.151994</td>\n",
       "      <td>0.439131</td>\n",
       "      <td>740.054565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>775.644900</td>\n",
       "      <td>696.018494</td>\n",
       "      <td>0.265463</td>\n",
       "      <td>0.195492</td>\n",
       "      <td>0.465014</td>\n",
       "      <td>696.018494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>687.915200</td>\n",
       "      <td>663.425049</td>\n",
       "      <td>0.259173</td>\n",
       "      <td>0.348669</td>\n",
       "      <td>0.544748</td>\n",
       "      <td>663.425049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>690.530200</td>\n",
       "      <td>648.463928</td>\n",
       "      <td>0.256234</td>\n",
       "      <td>0.293115</td>\n",
       "      <td>0.518441</td>\n",
       "      <td>648.463867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>690.530200</td>\n",
       "      <td>625.479431</td>\n",
       "      <td>0.251652</td>\n",
       "      <td>0.324529</td>\n",
       "      <td>0.536438</td>\n",
       "      <td>625.479492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>643.851700</td>\n",
       "      <td>639.331360</td>\n",
       "      <td>0.254424</td>\n",
       "      <td>0.287390</td>\n",
       "      <td>0.516483</td>\n",
       "      <td>639.331360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>593.300300</td>\n",
       "      <td>650.049133</td>\n",
       "      <td>0.256547</td>\n",
       "      <td>0.279348</td>\n",
       "      <td>0.511400</td>\n",
       "      <td>650.049133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>573.397000</td>\n",
       "      <td>609.713745</td>\n",
       "      <td>0.248460</td>\n",
       "      <td>0.360390</td>\n",
       "      <td>0.555965</td>\n",
       "      <td>609.713745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>565.472100</td>\n",
       "      <td>642.070496</td>\n",
       "      <td>0.254968</td>\n",
       "      <td>0.322318</td>\n",
       "      <td>0.533675</td>\n",
       "      <td>642.070496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>496.247900</td>\n",
       "      <td>638.337524</td>\n",
       "      <td>0.254226</td>\n",
       "      <td>0.325707</td>\n",
       "      <td>0.535741</td>\n",
       "      <td>638.337585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>496.247900</td>\n",
       "      <td>641.573669</td>\n",
       "      <td>0.254869</td>\n",
       "      <td>0.350812</td>\n",
       "      <td>0.547971</td>\n",
       "      <td>641.573669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>479.013800</td>\n",
       "      <td>702.742310</td>\n",
       "      <td>0.266743</td>\n",
       "      <td>0.287364</td>\n",
       "      <td>0.510311</td>\n",
       "      <td>702.742249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>450.501800</td>\n",
       "      <td>635.508057</td>\n",
       "      <td>0.253662</td>\n",
       "      <td>0.366547</td>\n",
       "      <td>0.556443</td>\n",
       "      <td>635.508057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>436.168600</td>\n",
       "      <td>698.047913</td>\n",
       "      <td>0.265850</td>\n",
       "      <td>0.314756</td>\n",
       "      <td>0.524453</td>\n",
       "      <td>698.047913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>386.104600</td>\n",
       "      <td>721.160583</td>\n",
       "      <td>0.270215</td>\n",
       "      <td>0.325128</td>\n",
       "      <td>0.527456</td>\n",
       "      <td>721.160583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>379.680200</td>\n",
       "      <td>685.255859</td>\n",
       "      <td>0.263403</td>\n",
       "      <td>0.339162</td>\n",
       "      <td>0.537879</td>\n",
       "      <td>685.255859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>379.680200</td>\n",
       "      <td>693.385681</td>\n",
       "      <td>0.264961</td>\n",
       "      <td>0.361699</td>\n",
       "      <td>0.548369</td>\n",
       "      <td>693.385681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>350.904300</td>\n",
       "      <td>711.974792</td>\n",
       "      <td>0.268489</td>\n",
       "      <td>0.356377</td>\n",
       "      <td>0.543944</td>\n",
       "      <td>711.974731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 12:24:48,845] Trial 43 finished with value: 0.5564426240800355 and parameters: {'learning_rate': 0.00038350296119890766, 'batch_size': 16, 'warmup_steps': 242, 'weight_decay': 0.057900253618748634}. Best is trial 22 with value: 0.586500525139622.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1848' max='2520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1848/2520 00:52 < 00:19, 34.96 it/s, Epoch 22/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1618.245972</td>\n",
       "      <td>0.404778</td>\n",
       "      <td>0.128397</td>\n",
       "      <td>0.361810</td>\n",
       "      <td>1618.245972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1737.910800</td>\n",
       "      <td>1234.580322</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.144917</td>\n",
       "      <td>0.395682</td>\n",
       "      <td>1234.580322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1412.143000</td>\n",
       "      <td>900.474976</td>\n",
       "      <td>0.301947</td>\n",
       "      <td>0.034144</td>\n",
       "      <td>0.366099</td>\n",
       "      <td>900.474854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>950.064000</td>\n",
       "      <td>748.333496</td>\n",
       "      <td>0.275259</td>\n",
       "      <td>0.213690</td>\n",
       "      <td>0.469215</td>\n",
       "      <td>748.333435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>738.246300</td>\n",
       "      <td>705.250732</td>\n",
       "      <td>0.267218</td>\n",
       "      <td>0.270521</td>\n",
       "      <td>0.501651</td>\n",
       "      <td>705.250671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>722.107000</td>\n",
       "      <td>683.003357</td>\n",
       "      <td>0.262970</td>\n",
       "      <td>0.269270</td>\n",
       "      <td>0.503150</td>\n",
       "      <td>683.003418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>722.107000</td>\n",
       "      <td>667.212219</td>\n",
       "      <td>0.259912</td>\n",
       "      <td>0.216857</td>\n",
       "      <td>0.478472</td>\n",
       "      <td>667.212219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>686.265100</td>\n",
       "      <td>654.011047</td>\n",
       "      <td>0.257328</td>\n",
       "      <td>0.279759</td>\n",
       "      <td>0.511216</td>\n",
       "      <td>654.010986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>636.495200</td>\n",
       "      <td>638.187317</td>\n",
       "      <td>0.254196</td>\n",
       "      <td>0.289945</td>\n",
       "      <td>0.517875</td>\n",
       "      <td>638.187256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>606.113000</td>\n",
       "      <td>631.391663</td>\n",
       "      <td>0.252839</td>\n",
       "      <td>0.314796</td>\n",
       "      <td>0.530979</td>\n",
       "      <td>631.391663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>592.541700</td>\n",
       "      <td>664.799194</td>\n",
       "      <td>0.259442</td>\n",
       "      <td>0.247492</td>\n",
       "      <td>0.494025</td>\n",
       "      <td>664.799133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>524.909900</td>\n",
       "      <td>648.762024</td>\n",
       "      <td>0.256293</td>\n",
       "      <td>0.296896</td>\n",
       "      <td>0.520301</td>\n",
       "      <td>648.762024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>524.909900</td>\n",
       "      <td>661.358521</td>\n",
       "      <td>0.258769</td>\n",
       "      <td>0.297016</td>\n",
       "      <td>0.519123</td>\n",
       "      <td>661.358459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>490.777100</td>\n",
       "      <td>655.193115</td>\n",
       "      <td>0.257560</td>\n",
       "      <td>0.345995</td>\n",
       "      <td>0.544217</td>\n",
       "      <td>655.193176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>451.300100</td>\n",
       "      <td>635.589722</td>\n",
       "      <td>0.253678</td>\n",
       "      <td>0.344856</td>\n",
       "      <td>0.545589</td>\n",
       "      <td>635.589783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>437.468500</td>\n",
       "      <td>711.891968</td>\n",
       "      <td>0.268473</td>\n",
       "      <td>0.348092</td>\n",
       "      <td>0.539809</td>\n",
       "      <td>711.891968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>396.231900</td>\n",
       "      <td>713.145996</td>\n",
       "      <td>0.268710</td>\n",
       "      <td>0.360369</td>\n",
       "      <td>0.545829</td>\n",
       "      <td>713.146057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>392.216400</td>\n",
       "      <td>689.831970</td>\n",
       "      <td>0.264281</td>\n",
       "      <td>0.283612</td>\n",
       "      <td>0.509665</td>\n",
       "      <td>689.831909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>392.216400</td>\n",
       "      <td>677.244324</td>\n",
       "      <td>0.261859</td>\n",
       "      <td>0.306627</td>\n",
       "      <td>0.522384</td>\n",
       "      <td>677.244324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>354.311900</td>\n",
       "      <td>710.574463</td>\n",
       "      <td>0.268225</td>\n",
       "      <td>0.329083</td>\n",
       "      <td>0.530429</td>\n",
       "      <td>710.574463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>352.000400</td>\n",
       "      <td>698.609131</td>\n",
       "      <td>0.265957</td>\n",
       "      <td>0.302868</td>\n",
       "      <td>0.518456</td>\n",
       "      <td>698.609131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>326.865500</td>\n",
       "      <td>732.800903</td>\n",
       "      <td>0.272388</td>\n",
       "      <td>0.328135</td>\n",
       "      <td>0.527874</td>\n",
       "      <td>732.800903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 12:25:42,945] Trial 44 finished with value: 0.5458294074319749 and parameters: {'learning_rate': 0.0002179221699101961, 'batch_size': 16, 'warmup_steps': 225, 'weight_decay': 0.01844967393458508}. Best is trial 22 with value: 0.586500525139622.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1428' max='2520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1428/2520 00:40 < 00:31, 34.84 it/s, Epoch 17/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1135.243286</td>\n",
       "      <td>0.339030</td>\n",
       "      <td>0.090261</td>\n",
       "      <td>0.375615</td>\n",
       "      <td>1135.243408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1509.714500</td>\n",
       "      <td>710.336487</td>\n",
       "      <td>0.268180</td>\n",
       "      <td>0.236347</td>\n",
       "      <td>0.484084</td>\n",
       "      <td>710.336609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>809.001700</td>\n",
       "      <td>692.067139</td>\n",
       "      <td>0.264709</td>\n",
       "      <td>0.330357</td>\n",
       "      <td>0.532824</td>\n",
       "      <td>692.067017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>698.016700</td>\n",
       "      <td>652.882263</td>\n",
       "      <td>0.257106</td>\n",
       "      <td>0.316592</td>\n",
       "      <td>0.529743</td>\n",
       "      <td>652.882263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>649.387200</td>\n",
       "      <td>651.437805</td>\n",
       "      <td>0.256821</td>\n",
       "      <td>0.252498</td>\n",
       "      <td>0.497838</td>\n",
       "      <td>651.437805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>632.738400</td>\n",
       "      <td>638.533447</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.320809</td>\n",
       "      <td>0.533272</td>\n",
       "      <td>638.533386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>632.738400</td>\n",
       "      <td>662.921204</td>\n",
       "      <td>0.259075</td>\n",
       "      <td>0.302629</td>\n",
       "      <td>0.521777</td>\n",
       "      <td>662.921143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>585.737800</td>\n",
       "      <td>631.328064</td>\n",
       "      <td>0.252826</td>\n",
       "      <td>0.322397</td>\n",
       "      <td>0.534785</td>\n",
       "      <td>631.328064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>549.057400</td>\n",
       "      <td>669.280762</td>\n",
       "      <td>0.260315</td>\n",
       "      <td>0.286112</td>\n",
       "      <td>0.512899</td>\n",
       "      <td>669.280701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>506.321300</td>\n",
       "      <td>668.781128</td>\n",
       "      <td>0.260217</td>\n",
       "      <td>0.278343</td>\n",
       "      <td>0.509063</td>\n",
       "      <td>668.781128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>489.904400</td>\n",
       "      <td>671.524231</td>\n",
       "      <td>0.260750</td>\n",
       "      <td>0.293083</td>\n",
       "      <td>0.516166</td>\n",
       "      <td>671.524231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>424.230800</td>\n",
       "      <td>628.791260</td>\n",
       "      <td>0.252318</td>\n",
       "      <td>0.331015</td>\n",
       "      <td>0.539349</td>\n",
       "      <td>628.791260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>424.230800</td>\n",
       "      <td>676.592285</td>\n",
       "      <td>0.261733</td>\n",
       "      <td>0.335663</td>\n",
       "      <td>0.536965</td>\n",
       "      <td>676.592224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>392.782900</td>\n",
       "      <td>704.030701</td>\n",
       "      <td>0.266987</td>\n",
       "      <td>0.316529</td>\n",
       "      <td>0.524771</td>\n",
       "      <td>704.030701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>344.269200</td>\n",
       "      <td>733.664673</td>\n",
       "      <td>0.272548</td>\n",
       "      <td>0.298244</td>\n",
       "      <td>0.512848</td>\n",
       "      <td>733.664612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>327.811300</td>\n",
       "      <td>769.699158</td>\n",
       "      <td>0.279161</td>\n",
       "      <td>0.286654</td>\n",
       "      <td>0.503746</td>\n",
       "      <td>769.699158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>293.771000</td>\n",
       "      <td>738.758728</td>\n",
       "      <td>0.273493</td>\n",
       "      <td>0.295707</td>\n",
       "      <td>0.511107</td>\n",
       "      <td>738.758789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 12:26:25,520] Trial 45 finished with value: 0.5393486071092916 and parameters: {'learning_rate': 0.0004996289843966971, 'batch_size': 16, 'warmup_steps': 93, 'weight_decay': 0.027653797223649905}. Best is trial 22 with value: 0.586500525139622.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1092' max='2520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1092/2520 00:31 < 00:40, 34.86 it/s, Epoch 13/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1657.006348</td>\n",
       "      <td>0.409597</td>\n",
       "      <td>0.106217</td>\n",
       "      <td>0.348310</td>\n",
       "      <td>1657.006348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1756.556300</td>\n",
       "      <td>1337.770630</td>\n",
       "      <td>0.368032</td>\n",
       "      <td>0.144093</td>\n",
       "      <td>0.388031</td>\n",
       "      <td>1337.770752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1504.484800</td>\n",
       "      <td>1018.935364</td>\n",
       "      <td>0.321194</td>\n",
       "      <td>0.156383</td>\n",
       "      <td>0.417595</td>\n",
       "      <td>1018.935303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1074.408300</td>\n",
       "      <td>837.656250</td>\n",
       "      <td>0.291224</td>\n",
       "      <td>0.175786</td>\n",
       "      <td>0.442281</td>\n",
       "      <td>837.656372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>825.434200</td>\n",
       "      <td>748.144226</td>\n",
       "      <td>0.275224</td>\n",
       "      <td>0.238172</td>\n",
       "      <td>0.481474</td>\n",
       "      <td>748.144226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>762.088000</td>\n",
       "      <td>711.774719</td>\n",
       "      <td>0.268451</td>\n",
       "      <td>0.303167</td>\n",
       "      <td>0.517358</td>\n",
       "      <td>711.774658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>762.088000</td>\n",
       "      <td>698.934998</td>\n",
       "      <td>0.266019</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.522163</td>\n",
       "      <td>698.934937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>715.250500</td>\n",
       "      <td>695.680664</td>\n",
       "      <td>0.265399</td>\n",
       "      <td>0.332265</td>\n",
       "      <td>0.533433</td>\n",
       "      <td>695.680664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>691.587400</td>\n",
       "      <td>725.399841</td>\n",
       "      <td>0.271009</td>\n",
       "      <td>0.240271</td>\n",
       "      <td>0.484631</td>\n",
       "      <td>725.399780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>684.529500</td>\n",
       "      <td>646.187622</td>\n",
       "      <td>0.255784</td>\n",
       "      <td>0.310520</td>\n",
       "      <td>0.527368</td>\n",
       "      <td>646.187622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>673.305600</td>\n",
       "      <td>657.930237</td>\n",
       "      <td>0.258098</td>\n",
       "      <td>0.237814</td>\n",
       "      <td>0.489858</td>\n",
       "      <td>657.930237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>612.631700</td>\n",
       "      <td>639.172546</td>\n",
       "      <td>0.254392</td>\n",
       "      <td>0.298453</td>\n",
       "      <td>0.522030</td>\n",
       "      <td>639.172546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>612.631700</td>\n",
       "      <td>638.522888</td>\n",
       "      <td>0.254263</td>\n",
       "      <td>0.294602</td>\n",
       "      <td>0.520170</td>\n",
       "      <td>638.522888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 12:26:58,108] Trial 46 finished with value: 0.5334328578566974 and parameters: {'learning_rate': 0.0001630666046091185, 'batch_size': 16, 'warmup_steps': 215, 'weight_decay': 0.007427509091188607}. Best is trial 22 with value: 0.586500525139622.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='798' max='1260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 798/1260 00:34 < 00:19, 23.37 it/s, Epoch 19/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1694.378662</td>\n",
       "      <td>0.414190</td>\n",
       "      <td>0.183151</td>\n",
       "      <td>0.384480</td>\n",
       "      <td>1694.378662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1454.670776</td>\n",
       "      <td>0.383775</td>\n",
       "      <td>0.142512</td>\n",
       "      <td>0.379368</td>\n",
       "      <td>1454.670776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1688.997700</td>\n",
       "      <td>1163.937378</td>\n",
       "      <td>0.343288</td>\n",
       "      <td>0.125451</td>\n",
       "      <td>0.391081</td>\n",
       "      <td>1163.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1688.997700</td>\n",
       "      <td>923.335327</td>\n",
       "      <td>0.305755</td>\n",
       "      <td>0.108239</td>\n",
       "      <td>0.401242</td>\n",
       "      <td>923.335327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1062.897700</td>\n",
       "      <td>761.446045</td>\n",
       "      <td>0.277660</td>\n",
       "      <td>0.174690</td>\n",
       "      <td>0.448515</td>\n",
       "      <td>761.446106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1062.897700</td>\n",
       "      <td>701.668945</td>\n",
       "      <td>0.266539</td>\n",
       "      <td>0.097636</td>\n",
       "      <td>0.415549</td>\n",
       "      <td>701.668945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1062.897700</td>\n",
       "      <td>694.828674</td>\n",
       "      <td>0.265236</td>\n",
       "      <td>0.303053</td>\n",
       "      <td>0.518908</td>\n",
       "      <td>694.828796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>734.847000</td>\n",
       "      <td>665.521667</td>\n",
       "      <td>0.259582</td>\n",
       "      <td>0.254572</td>\n",
       "      <td>0.497495</td>\n",
       "      <td>665.521729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>734.847000</td>\n",
       "      <td>653.676941</td>\n",
       "      <td>0.257262</td>\n",
       "      <td>0.258582</td>\n",
       "      <td>0.500660</td>\n",
       "      <td>653.677002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>669.701200</td>\n",
       "      <td>643.958008</td>\n",
       "      <td>0.255342</td>\n",
       "      <td>0.295228</td>\n",
       "      <td>0.519943</td>\n",
       "      <td>643.957947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>669.701200</td>\n",
       "      <td>641.860840</td>\n",
       "      <td>0.254926</td>\n",
       "      <td>0.277373</td>\n",
       "      <td>0.511223</td>\n",
       "      <td>641.860840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>602.107900</td>\n",
       "      <td>643.249084</td>\n",
       "      <td>0.255202</td>\n",
       "      <td>0.296380</td>\n",
       "      <td>0.520589</td>\n",
       "      <td>643.249084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>602.107900</td>\n",
       "      <td>648.014465</td>\n",
       "      <td>0.256145</td>\n",
       "      <td>0.357830</td>\n",
       "      <td>0.550842</td>\n",
       "      <td>648.014465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>602.107900</td>\n",
       "      <td>616.339294</td>\n",
       "      <td>0.249807</td>\n",
       "      <td>0.358439</td>\n",
       "      <td>0.554316</td>\n",
       "      <td>616.339294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>514.398900</td>\n",
       "      <td>655.559998</td>\n",
       "      <td>0.257632</td>\n",
       "      <td>0.297011</td>\n",
       "      <td>0.519689</td>\n",
       "      <td>655.559875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>514.398900</td>\n",
       "      <td>650.839050</td>\n",
       "      <td>0.256703</td>\n",
       "      <td>0.341866</td>\n",
       "      <td>0.542581</td>\n",
       "      <td>650.839050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>436.258700</td>\n",
       "      <td>655.234802</td>\n",
       "      <td>0.257568</td>\n",
       "      <td>0.362440</td>\n",
       "      <td>0.552436</td>\n",
       "      <td>655.234680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>436.258700</td>\n",
       "      <td>696.230713</td>\n",
       "      <td>0.265504</td>\n",
       "      <td>0.298531</td>\n",
       "      <td>0.516513</td>\n",
       "      <td>696.230713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>436.258700</td>\n",
       "      <td>670.306824</td>\n",
       "      <td>0.260514</td>\n",
       "      <td>0.305470</td>\n",
       "      <td>0.522478</td>\n",
       "      <td>670.306824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 12:27:33,472] Trial 47 finished with value: 0.5543163209759048 and parameters: {'learning_rate': 0.00038509263994625746, 'batch_size': 32, 'warmup_steps': 186, 'weight_decay': 0.01307683617720472}. Best is trial 22 with value: 0.586500525139622.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3528' max='5040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3528/5040 01:16 < 00:32, 45.90 it/s, Epoch 21/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1718.331200</td>\n",
       "      <td>1126.532104</td>\n",
       "      <td>0.337727</td>\n",
       "      <td>0.112826</td>\n",
       "      <td>0.387549</td>\n",
       "      <td>1126.532104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>921.570500</td>\n",
       "      <td>744.817749</td>\n",
       "      <td>0.274612</td>\n",
       "      <td>0.156847</td>\n",
       "      <td>0.441118</td>\n",
       "      <td>744.817749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>712.095300</td>\n",
       "      <td>698.374023</td>\n",
       "      <td>0.265912</td>\n",
       "      <td>0.254966</td>\n",
       "      <td>0.494527</td>\n",
       "      <td>698.374084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>703.174100</td>\n",
       "      <td>680.636597</td>\n",
       "      <td>0.262514</td>\n",
       "      <td>0.221964</td>\n",
       "      <td>0.479725</td>\n",
       "      <td>680.636658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>662.563400</td>\n",
       "      <td>639.080933</td>\n",
       "      <td>0.254374</td>\n",
       "      <td>0.319417</td>\n",
       "      <td>0.532522</td>\n",
       "      <td>639.080872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>628.959500</td>\n",
       "      <td>626.038513</td>\n",
       "      <td>0.251765</td>\n",
       "      <td>0.329468</td>\n",
       "      <td>0.538852</td>\n",
       "      <td>626.038513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>630.578200</td>\n",
       "      <td>621.255676</td>\n",
       "      <td>0.250801</td>\n",
       "      <td>0.377199</td>\n",
       "      <td>0.563199</td>\n",
       "      <td>621.255676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>564.039700</td>\n",
       "      <td>614.229675</td>\n",
       "      <td>0.249379</td>\n",
       "      <td>0.387623</td>\n",
       "      <td>0.569122</td>\n",
       "      <td>614.229675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>538.372700</td>\n",
       "      <td>631.563538</td>\n",
       "      <td>0.252873</td>\n",
       "      <td>0.394392</td>\n",
       "      <td>0.570760</td>\n",
       "      <td>631.563538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>486.245000</td>\n",
       "      <td>634.914917</td>\n",
       "      <td>0.253543</td>\n",
       "      <td>0.390861</td>\n",
       "      <td>0.568659</td>\n",
       "      <td>634.914917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>494.887900</td>\n",
       "      <td>616.993713</td>\n",
       "      <td>0.249939</td>\n",
       "      <td>0.380672</td>\n",
       "      <td>0.565366</td>\n",
       "      <td>616.993713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>429.637900</td>\n",
       "      <td>629.350159</td>\n",
       "      <td>0.252430</td>\n",
       "      <td>0.385858</td>\n",
       "      <td>0.566714</td>\n",
       "      <td>629.350159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>388.195700</td>\n",
       "      <td>647.324768</td>\n",
       "      <td>0.256009</td>\n",
       "      <td>0.415349</td>\n",
       "      <td>0.579670</td>\n",
       "      <td>647.324829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>382.944500</td>\n",
       "      <td>667.167725</td>\n",
       "      <td>0.259903</td>\n",
       "      <td>0.413428</td>\n",
       "      <td>0.576763</td>\n",
       "      <td>667.167725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>358.577700</td>\n",
       "      <td>653.346191</td>\n",
       "      <td>0.257197</td>\n",
       "      <td>0.390656</td>\n",
       "      <td>0.566730</td>\n",
       "      <td>653.346252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>316.372000</td>\n",
       "      <td>679.546631</td>\n",
       "      <td>0.262303</td>\n",
       "      <td>0.425628</td>\n",
       "      <td>0.581662</td>\n",
       "      <td>679.546692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>309.079100</td>\n",
       "      <td>681.715393</td>\n",
       "      <td>0.262722</td>\n",
       "      <td>0.369186</td>\n",
       "      <td>0.553232</td>\n",
       "      <td>681.715393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>318.024500</td>\n",
       "      <td>693.482788</td>\n",
       "      <td>0.264979</td>\n",
       "      <td>0.406628</td>\n",
       "      <td>0.570824</td>\n",
       "      <td>693.482849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>276.154900</td>\n",
       "      <td>688.434631</td>\n",
       "      <td>0.264013</td>\n",
       "      <td>0.400577</td>\n",
       "      <td>0.568282</td>\n",
       "      <td>688.434631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>246.736400</td>\n",
       "      <td>706.132935</td>\n",
       "      <td>0.267385</td>\n",
       "      <td>0.389771</td>\n",
       "      <td>0.561193</td>\n",
       "      <td>706.132874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>252.437900</td>\n",
       "      <td>679.178284</td>\n",
       "      <td>0.262232</td>\n",
       "      <td>0.377004</td>\n",
       "      <td>0.557386</td>\n",
       "      <td>679.178345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 12:28:51,651] Trial 48 finished with value: 0.5816623837702477 and parameters: {'learning_rate': 0.00022069517200075023, 'batch_size': 8, 'warmup_steps': 168, 'weight_decay': 0.006166026366219402}. Best is trial 22 with value: 0.586500525139622.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2016' max='5040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2016/5040 00:44 < 01:06, 45.70 it/s, Epoch 12/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1701.007300</td>\n",
       "      <td>1051.018677</td>\n",
       "      <td>0.326212</td>\n",
       "      <td>0.146299</td>\n",
       "      <td>0.410044</td>\n",
       "      <td>1051.018677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>881.043000</td>\n",
       "      <td>731.493896</td>\n",
       "      <td>0.272145</td>\n",
       "      <td>0.137796</td>\n",
       "      <td>0.432826</td>\n",
       "      <td>731.493896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>708.513400</td>\n",
       "      <td>697.017090</td>\n",
       "      <td>0.265654</td>\n",
       "      <td>0.313500</td>\n",
       "      <td>0.523923</td>\n",
       "      <td>697.017090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>702.075900</td>\n",
       "      <td>743.591125</td>\n",
       "      <td>0.274386</td>\n",
       "      <td>0.240924</td>\n",
       "      <td>0.483269</td>\n",
       "      <td>743.591125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>679.701600</td>\n",
       "      <td>664.756470</td>\n",
       "      <td>0.259433</td>\n",
       "      <td>0.225745</td>\n",
       "      <td>0.483156</td>\n",
       "      <td>664.756470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>650.912900</td>\n",
       "      <td>669.350281</td>\n",
       "      <td>0.260328</td>\n",
       "      <td>0.198273</td>\n",
       "      <td>0.468972</td>\n",
       "      <td>669.350220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>654.595000</td>\n",
       "      <td>648.662537</td>\n",
       "      <td>0.256273</td>\n",
       "      <td>0.335316</td>\n",
       "      <td>0.539521</td>\n",
       "      <td>648.662537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>583.616100</td>\n",
       "      <td>652.475891</td>\n",
       "      <td>0.257026</td>\n",
       "      <td>0.257835</td>\n",
       "      <td>0.500405</td>\n",
       "      <td>652.475830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>596.672400</td>\n",
       "      <td>653.624573</td>\n",
       "      <td>0.257252</td>\n",
       "      <td>0.320581</td>\n",
       "      <td>0.531665</td>\n",
       "      <td>653.624512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>529.323400</td>\n",
       "      <td>639.688171</td>\n",
       "      <td>0.254495</td>\n",
       "      <td>0.319885</td>\n",
       "      <td>0.532695</td>\n",
       "      <td>639.688171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>537.023700</td>\n",
       "      <td>670.441467</td>\n",
       "      <td>0.260540</td>\n",
       "      <td>0.262482</td>\n",
       "      <td>0.500971</td>\n",
       "      <td>670.441467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>471.861400</td>\n",
       "      <td>661.275024</td>\n",
       "      <td>0.258753</td>\n",
       "      <td>0.311125</td>\n",
       "      <td>0.526186</td>\n",
       "      <td>661.275085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43/43 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 12:29:37,092] Trial 49 finished with value: 0.5395211332783588 and parameters: {'learning_rate': 0.00023152889753023145, 'batch_size': 8, 'warmup_steps': 135, 'weight_decay': 0.0059508921263809215}. Best is trial 22 with value: 0.586500525139622.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적화 완료!\n",
      "최고 점수: 0.5865\n",
      "최적 하이퍼파라미터: {'learning_rate': 0.00030994900647604996, 'batch_size': 8, 'warmup_steps': 201, 'weight_decay': 0.007364521772775286}\n"
     ]
    }
   ],
   "source": [
    "# Optuna 스터디 생성 및 실행\n",
    "print(\"Optuna 하이퍼파라미터 최적화 시작...\")\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    sampler=optuna.samplers.TPESampler(seed=42)\n",
    ")\n",
    "\n",
    "# 최적화 실행 (50회 시도)\n",
    "study.optimize(objective, n_trials=50, timeout=7200)  # 2시간 제한\n",
    "\n",
    "print(\"최적화 완료!\")\n",
    "print(f\"최고 점수: {study.best_value:.4f}\")\n",
    "print(f\"최적 하이퍼파라미터: {study.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0dbff83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "최적 하이퍼파라미터로 최종 훈련 시작...\n"
     ]
    }
   ],
   "source": [
    "# 최적 하이퍼파라미터로 최종 훈련\n",
    "print(\"\\n최적 하이퍼파라미터로 최종 훈련 시작...\")\n",
    "best_params = study.best_params\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./chemberta_best',\n",
    "    num_train_epochs=100,\n",
    "    per_device_train_batch_size=best_params['batch_size'],\n",
    "    per_device_eval_batch_size=best_params['batch_size'],\n",
    "    warmup_steps=best_params['warmup_steps'],\n",
    "    weight_decay=best_params['weight_decay'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    logging_steps=50,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"competition_score\",\n",
    "    greater_is_better=True,\n",
    "    save_total_limit=3,\n",
    "    report_to=None,\n",
    "    fp16=False,\n",
    "    dataloader_pin_memory=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=15)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7cac313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 훈련 시작...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4536' max='16800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 4536/16800 01:38 < 04:25, 46.22 it/s, Epoch 27/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Nrmse</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Competition Score</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1517.462800</td>\n",
       "      <td>1074.737793</td>\n",
       "      <td>0.329872</td>\n",
       "      <td>0.189614</td>\n",
       "      <td>0.429871</td>\n",
       "      <td>1074.737793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>706.320500</td>\n",
       "      <td>709.433289</td>\n",
       "      <td>0.268009</td>\n",
       "      <td>0.288829</td>\n",
       "      <td>0.510410</td>\n",
       "      <td>709.433289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>718.493400</td>\n",
       "      <td>694.879333</td>\n",
       "      <td>0.265246</td>\n",
       "      <td>0.335674</td>\n",
       "      <td>0.535214</td>\n",
       "      <td>694.879333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>712.618700</td>\n",
       "      <td>651.726074</td>\n",
       "      <td>0.256878</td>\n",
       "      <td>0.289535</td>\n",
       "      <td>0.516329</td>\n",
       "      <td>651.726074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>626.076000</td>\n",
       "      <td>629.351624</td>\n",
       "      <td>0.252430</td>\n",
       "      <td>0.335201</td>\n",
       "      <td>0.541386</td>\n",
       "      <td>629.351624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>644.044300</td>\n",
       "      <td>635.519409</td>\n",
       "      <td>0.253664</td>\n",
       "      <td>0.299992</td>\n",
       "      <td>0.523164</td>\n",
       "      <td>635.519409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>579.373800</td>\n",
       "      <td>696.604309</td>\n",
       "      <td>0.265575</td>\n",
       "      <td>0.301205</td>\n",
       "      <td>0.517815</td>\n",
       "      <td>696.604309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>589.841600</td>\n",
       "      <td>623.443420</td>\n",
       "      <td>0.251242</td>\n",
       "      <td>0.331755</td>\n",
       "      <td>0.540256</td>\n",
       "      <td>623.443420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>565.954800</td>\n",
       "      <td>648.397461</td>\n",
       "      <td>0.256221</td>\n",
       "      <td>0.362771</td>\n",
       "      <td>0.553275</td>\n",
       "      <td>648.397461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>539.277000</td>\n",
       "      <td>624.470947</td>\n",
       "      <td>0.251449</td>\n",
       "      <td>0.374752</td>\n",
       "      <td>0.561651</td>\n",
       "      <td>624.470886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>471.655200</td>\n",
       "      <td>623.593445</td>\n",
       "      <td>0.251273</td>\n",
       "      <td>0.344922</td>\n",
       "      <td>0.546825</td>\n",
       "      <td>623.593445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>435.596900</td>\n",
       "      <td>620.671265</td>\n",
       "      <td>0.250683</td>\n",
       "      <td>0.383364</td>\n",
       "      <td>0.566340</td>\n",
       "      <td>620.671265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>465.517600</td>\n",
       "      <td>742.572815</td>\n",
       "      <td>0.274198</td>\n",
       "      <td>0.313781</td>\n",
       "      <td>0.519792</td>\n",
       "      <td>742.572815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>376.648100</td>\n",
       "      <td>675.276611</td>\n",
       "      <td>0.261478</td>\n",
       "      <td>0.360913</td>\n",
       "      <td>0.549717</td>\n",
       "      <td>675.276611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>373.981700</td>\n",
       "      <td>716.086060</td>\n",
       "      <td>0.269263</td>\n",
       "      <td>0.370919</td>\n",
       "      <td>0.550828</td>\n",
       "      <td>716.086060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>290.593200</td>\n",
       "      <td>762.333252</td>\n",
       "      <td>0.277822</td>\n",
       "      <td>0.307804</td>\n",
       "      <td>0.514991</td>\n",
       "      <td>762.333252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>323.832000</td>\n",
       "      <td>800.359619</td>\n",
       "      <td>0.284667</td>\n",
       "      <td>0.292621</td>\n",
       "      <td>0.503977</td>\n",
       "      <td>800.359619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>280.835900</td>\n",
       "      <td>785.039673</td>\n",
       "      <td>0.281929</td>\n",
       "      <td>0.341119</td>\n",
       "      <td>0.529595</td>\n",
       "      <td>785.039673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>279.357600</td>\n",
       "      <td>780.423767</td>\n",
       "      <td>0.281099</td>\n",
       "      <td>0.320731</td>\n",
       "      <td>0.519816</td>\n",
       "      <td>780.423767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>284.221600</td>\n",
       "      <td>837.525757</td>\n",
       "      <td>0.291201</td>\n",
       "      <td>0.330449</td>\n",
       "      <td>0.519624</td>\n",
       "      <td>837.525696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>275.134200</td>\n",
       "      <td>885.428589</td>\n",
       "      <td>0.299413</td>\n",
       "      <td>0.235109</td>\n",
       "      <td>0.467848</td>\n",
       "      <td>885.428589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>223.359700</td>\n",
       "      <td>798.131470</td>\n",
       "      <td>0.284270</td>\n",
       "      <td>0.313841</td>\n",
       "      <td>0.514785</td>\n",
       "      <td>798.131470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>212.893000</td>\n",
       "      <td>772.386658</td>\n",
       "      <td>0.279648</td>\n",
       "      <td>0.346902</td>\n",
       "      <td>0.533627</td>\n",
       "      <td>772.386780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>215.997600</td>\n",
       "      <td>794.042114</td>\n",
       "      <td>0.283541</td>\n",
       "      <td>0.334583</td>\n",
       "      <td>0.525521</td>\n",
       "      <td>794.042114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>180.428300</td>\n",
       "      <td>880.722351</td>\n",
       "      <td>0.298616</td>\n",
       "      <td>0.316671</td>\n",
       "      <td>0.509027</td>\n",
       "      <td>880.722351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>188.151200</td>\n",
       "      <td>899.359985</td>\n",
       "      <td>0.301760</td>\n",
       "      <td>0.262638</td>\n",
       "      <td>0.480439</td>\n",
       "      <td>899.359985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>189.273500</td>\n",
       "      <td>865.059692</td>\n",
       "      <td>0.295949</td>\n",
       "      <td>0.308441</td>\n",
       "      <td>0.506246</td>\n",
       "      <td>865.059692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 성능 평가...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 검증 성능: {'eval_loss': 620.6712646484375, 'eval_nrmse': 0.25068310833942326, 'eval_pearson': 0.3833638332789165, 'eval_competition_score': 0.5663403624697466, 'eval_mse': 620.6712646484375, 'eval_runtime': 0.354, 'eval_samples_per_second': 951.935, 'eval_steps_per_second': 121.463, 'epoch': 27.0}\n"
     ]
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "print(\"모델 훈련 시작...\")\n",
    "trainer.train()\n",
    "\n",
    "# 검증 성능 평가\n",
    "print(\"검증 성능 평가...\")\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"최종 검증 성능: {eval_results}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "308aa3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "전체 데이터로 최종 훈련...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5275' max='5275' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5275/5275 01:39, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>430.359200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>464.344800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>450.707700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>466.680700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>477.232900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>411.099100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>432.048400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>450.065000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>398.023200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>479.596800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>478.701100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>429.163700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>382.104300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>366.148400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>395.727300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>380.974800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>419.866700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>330.324300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>347.638200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>384.975600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>335.739900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>314.083600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>326.605900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>350.826100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>331.104900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>319.170100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>273.493400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>293.798900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>287.258100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>297.164200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>304.148200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>256.985400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>271.283000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>299.776300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>222.757500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>267.624200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>265.340700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>229.501300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>220.638700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>231.387200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>259.059500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>216.747800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>208.672200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>216.687900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>247.544000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>226.098400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>290.758700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>180.951700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>211.436400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>183.790400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>178.934500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>206.249100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>203.367700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>178.066200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>202.362500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>196.887100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>156.310400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>213.133100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>197.347200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>169.260600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>173.754100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>183.560100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>145.820400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>173.038300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>144.689600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>164.013000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>167.082600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>167.776600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>158.077800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>157.939500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3550</td>\n",
       "      <td>165.982000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>126.490200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3650</td>\n",
       "      <td>162.635900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>150.718900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>137.056000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>139.372900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3850</td>\n",
       "      <td>138.182100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>141.189600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3950</td>\n",
       "      <td>114.267600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>130.470100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4050</td>\n",
       "      <td>181.398300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>121.704800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4150</td>\n",
       "      <td>131.027100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>107.039400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>109.878500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>102.873200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4350</td>\n",
       "      <td>122.436900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>122.246900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4450</td>\n",
       "      <td>114.713200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>101.863500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4550</td>\n",
       "      <td>138.443400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>126.704700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4650</td>\n",
       "      <td>97.320700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>133.269800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4750</td>\n",
       "      <td>122.588900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>86.607300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4850</td>\n",
       "      <td>109.323900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>93.801700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4950</td>\n",
       "      <td>99.758500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>94.782800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5050</td>\n",
       "      <td>104.878700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>113.387900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5150</td>\n",
       "      <td>108.864500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>110.078700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5250</td>\n",
       "      <td>108.678200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5275, training_loss=229.05776811500297, metrics={'train_runtime': 99.2923, 'train_samples_per_second': 423.245, 'train_steps_per_second': 53.126, 'total_flos': 45370363629480.0, 'train_loss': 229.05776811500297, 'epoch': 25.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 데이터로 재훈련\n",
    "print(\"\\n전체 데이터로 최종 훈련...\")\n",
    "full_dataset = SMILESDataset(train_df['Canonical_Smiles'].values, train_df['Inhibition'].values)\n",
    "\n",
    "final_training_args = TrainingArguments(\n",
    "    output_dir='./chemberta_final',\n",
    "    num_train_epochs=25,\n",
    "    per_device_train_batch_size=best_params['batch_size'],\n",
    "    warmup_steps=best_params['warmup_steps'],\n",
    "    weight_decay=best_params['weight_decay'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    logging_steps=50,\n",
    "    save_strategy=\"no\",\n",
    "    report_to=None,\n",
    "    fp16=False\n",
    ")\n",
    "\n",
    "final_trainer = Trainer(\n",
    "    model=model,\n",
    "    args=final_training_args,\n",
    "    train_dataset=full_dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "final_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d2817d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터 예측 중...\n",
      "\n",
      "최적화 결과:\n",
      "- 최고 검증 점수: 0.5865\n",
      "- 최적 학습률: 3.10e-04\n",
      "- 최적 배치 크기: 8\n",
      "- 최적 Warmup Steps: 201\n",
      "- 최적 Weight Decay: 0.0074\n",
      "예측 결과 저장: chemberta_optuna_submission.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"테스트 데이터 예측 중...\")\n",
    "test_dataset = SMILESDataset(test_df['Canonical_Smiles'].values)\n",
    "predictions = trainer.predict(test_dataset)\n",
    "test_predictions = predictions.predictions.flatten()\n",
    "\n",
    "# 결과 저장\n",
    "submission['Inhibition'] = test_predictions\n",
    "submission.to_csv('chemberta_optuna_submission.csv', index=False)\n",
    "\n",
    "print(f\"\\n최적화 결과:\")\n",
    "print(f\"- 최고 검증 점수: {study.best_value:.4f}\")\n",
    "print(f\"- 최적 학습률: {best_params['learning_rate']:.2e}\")\n",
    "print(f\"- 최적 배치 크기: {best_params['batch_size']}\")\n",
    "print(f\"- 최적 Warmup Steps: {best_params['warmup_steps']}\")\n",
    "print(f\"- 최적 Weight Decay: {best_params['weight_decay']:.4f}\")\n",
    "print(\"예측 결과 저장: chemberta_optuna_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d74af2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 예측값 분석 ===\n",
      "예측값 범위: -0.60 ~ 74.70\n",
      "실제값 범위: 0.00 ~ 99.38\n",
      "예측값 평균: 29.62\n",
      "실제값 평균: 33.22\n",
      "예측값 표준편차: 20.12\n",
      "실제값 표준편차: 26.41\n",
      "\n",
      "=== 예측값 분포 ===\n",
      "count    100.000000\n",
      "mean      29.615916\n",
      "std       20.120878\n",
      "min       -0.595903\n",
      "25%       13.647787\n",
      "50%       24.885278\n",
      "75%       44.081975\n",
      "max       74.699570\n",
      "Name: Inhibition, dtype: float64\n",
      "\n",
      "=== 이상치 확인 ===\n",
      "음수값 개수: 1\n",
      "100 초과값 개수: 0\n",
      "NaN 개수: 0\n",
      "\n",
      "가장 작은 5개 값: [-0.5959028   0.13939762  1.3311311   1.8108578   1.9346439 ]\n",
      "가장 큰 5개 값: [74.69957 74.68019 74.62001 73.23399 72.18682]\n"
     ]
    }
   ],
   "source": [
    "# 예측값 분석\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 결과 파일 로드\n",
    "submission = pd.read_csv('chemberta_optuna_submission.csv')\n",
    "train_df = pd.read_csv('train.csv')\n",
    "\n",
    "print(\"=== 예측값 분석 ===\")\n",
    "print(f\"예측값 범위: {submission['Inhibition'].min():.2f} ~ {submission['Inhibition'].max():.2f}\")\n",
    "print(f\"실제값 범위: {train_df['Inhibition'].min():.2f} ~ {train_df['Inhibition'].max():.2f}\")\n",
    "print(f\"예측값 평균: {submission['Inhibition'].mean():.2f}\")\n",
    "print(f\"실제값 평균: {train_df['Inhibition'].mean():.2f}\")\n",
    "print(f\"예측값 표준편차: {submission['Inhibition'].std():.2f}\")\n",
    "print(f\"실제값 표준편차: {train_df['Inhibition'].std():.2f}\")\n",
    "\n",
    "print(\"\\n=== 예측값 분포 ===\")\n",
    "print(submission['Inhibition'].describe())\n",
    "\n",
    "print(\"\\n=== 이상치 확인 ===\")\n",
    "print(f\"음수값 개수: {(submission['Inhibition'] < 0).sum()}\")\n",
    "print(f\"100 초과값 개수: {(submission['Inhibition'] > 100).sum()}\")\n",
    "print(f\"NaN 개수: {submission['Inhibition'].isna().sum()}\")\n",
    "\n",
    "# 극단값 확인\n",
    "print(f\"\\n가장 작은 5개 값: {submission['Inhibition'].nsmallest(5).values}\")\n",
    "print(f\"가장 큰 5개 값: {submission['Inhibition'].nlargest(5).values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a626d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daycon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
