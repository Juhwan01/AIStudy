{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "703e1e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\envs\\daycon\\Lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "c:\\Anaconda3\\envs\\daycon\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import lightgbm as lgb\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F  \n",
    "import safetensors\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer, \n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "from itertools import permutations\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74934889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ 24ê°œì˜ ìˆœì—´ í´ë˜ìŠ¤ ìƒì„±\n",
      "ì˜ˆì‹œ ë§¤í•‘:\n",
      "  ë¼ë²¨ 0: (0, 1, 2, 3)\n",
      "  ë¼ë²¨ 1: (0, 1, 3, 2)\n",
      "  ë¼ë²¨ 2: (0, 2, 1, 3)\n",
      "  ë¼ë²¨ 3: (0, 2, 3, 1)\n",
      "  ë¼ë²¨ 4: (0, 3, 1, 2)\n"
     ]
    }
   ],
   "source": [
    "def create_label_mappings():\n",
    "    \"\"\"24ê°€ì§€ ìˆœì—´ì— ëŒ€í•œ ë¼ë²¨ ë§¤í•‘ ìƒì„±\"\"\"\n",
    "    all_permutations = list(permutations([0, 1, 2, 3]))\n",
    "    perm_to_label = {perm: idx for idx, perm in enumerate(all_permutations)}\n",
    "    label_to_perm = {idx: perm for idx, perm in enumerate(all_permutations)}\n",
    "    \n",
    "    print(f\"ì´ {len(all_permutations)}ê°œì˜ ìˆœì—´ í´ë˜ìŠ¤ ìƒì„±\")\n",
    "    print(\"ì˜ˆì‹œ ë§¤í•‘:\")\n",
    "    for i in range(5):\n",
    "        print(f\"  ë¼ë²¨ {i}: {all_permutations[i]}\")\n",
    "    \n",
    "    return perm_to_label, label_to_perm\n",
    "\n",
    "# ìˆœì—´ ë§¤í•‘ ìƒì„±\n",
    "perm_to_label, label_to_perm = create_label_mappings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bef94fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_roberta_data(train_df, perm_to_label):\n",
    "    \"\"\"RoBERTaìš© ë°ì´í„° ì¤€ë¹„\"\"\"\n",
    "    processed_data = []\n",
    "    \n",
    "    for _, row in train_df.iterrows():\n",
    "        sentences = [row[f\"sentence_{i}\"] for i in range(4)]\n",
    "        answer_tuple = tuple([row[f\"answer_{i}\"] for i in range(4)])\n",
    "        text = \" [SEP] \".join(sentences)\n",
    "        label = perm_to_label[answer_tuple]\n",
    "        \n",
    "        processed_data.append({\n",
    "            \"text\": text,\n",
    "            \"label\": label,\n",
    "            \"original_sentences\": sentences,\n",
    "            \"answer\": answer_tuple\n",
    "        })\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "def augment_roberta_data_advanced(train_df, perm_to_label, multiplier=4):\n",
    "    \"\"\"ê³ ê¸‰ ë°ì´í„° ì¦ê°•\"\"\"\n",
    "    augmented_data = []\n",
    "    \n",
    "    # ì›ë³¸ ë°ì´í„°\n",
    "    original_data = prepare_roberta_data(train_df, perm_to_label)\n",
    "    augmented_data.extend(original_data)\n",
    "    \n",
    "    # ë‹¤ì–‘í•œ ì¦ê°• ë°©ë²•\n",
    "    for aug_round in range(multiplier - 1):\n",
    "        for _, row in train_df.iterrows():\n",
    "            sentences = [row[f\"sentence_{i}\"] for i in range(4)]\n",
    "            original_answer = [row[f\"answer_{i}\"] for i in range(4)]\n",
    "            \n",
    "            if aug_round == 0:\n",
    "                # ëœë¤ ì…”í”Œ\n",
    "                indices = list(range(4))\n",
    "                np.random.shuffle(indices)\n",
    "            elif aug_round == 1:\n",
    "                # ìˆœí™˜ ì´ë™\n",
    "                shift = np.random.randint(1, 4)\n",
    "                indices = [(i + shift) % 4 for i in range(4)]\n",
    "            else:\n",
    "                # ë¶€ë¶„ êµí™˜\n",
    "                indices = list(range(4))\n",
    "                i, j = np.random.choice(4, 2, replace=False)\n",
    "                indices[i], indices[j] = indices[j], indices[i]\n",
    "            \n",
    "            shuffled_sentences = [sentences[i] for i in indices]\n",
    "            new_answer = tuple([indices.index(original_answer[i]) for i in range(4)])\n",
    "            \n",
    "            text = \" [SEP] \".join(shuffled_sentences)\n",
    "            label = perm_to_label[new_answer]\n",
    "            \n",
    "            augmented_data.append({\n",
    "                \"text\": text,\n",
    "                \"label\": label,\n",
    "                \"original_sentences\": shuffled_sentences,\n",
    "                \"answer\": new_answer\n",
    "            })\n",
    "    \n",
    "    print(f\"ê³ ê¸‰ ë°ì´í„° ì¦ê°• ì™„ë£Œ: {len(original_data)} â†’ {len(augmented_data)}\")\n",
    "    return augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b89decf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "ì›ë³¸ í•™ìŠµ ë°ì´í„°: 7351ê°œ\n",
      "\n",
      "ê³ ê¸‰ ë°ì´í„° ì¦ê°• ì¤‘...\n",
      "ê³ ê¸‰ ë°ì´í„° ì¦ê°• ì™„ë£Œ: 7351 â†’ 29404\n",
      "\n",
      "í•™ìŠµ/ê²€ì¦ ë°ì´í„° ë¶„í• ...\n",
      "í•™ìŠµ ë°ì´í„°: 23523ê°œ\n",
      "ê²€ì¦ ë°ì´í„°: 5881ê°œ\n"
     ]
    }
   ],
   "source": [
    "print(\"ë°ì´í„° ë¡œë“œ ì¤‘...\")\n",
    "train_df = pd.read_csv('./train.csv')\n",
    "print(f\"ì›ë³¸ í•™ìŠµ ë°ì´í„°: {len(train_df)}ê°œ\")\n",
    "\n",
    "print(\"\\nê³ ê¸‰ ë°ì´í„° ì¦ê°• ì¤‘...\")\n",
    "augmented_data = augment_roberta_data_advanced(train_df, perm_to_label, multiplier=4)\n",
    "\n",
    "print(\"\\ní•™ìŠµ/ê²€ì¦ ë°ì´í„° ë¶„í• ...\")\n",
    "train_data, valid_data = train_test_split(\n",
    "    augmented_data, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=[item[\"label\"] for item in augmented_data]\n",
    ")\n",
    "\n",
    "print(f\"í•™ìŠµ ë°ì´í„°: {len(train_data)}ê°œ\")\n",
    "print(f\"ê²€ì¦ ë°ì´í„°: {len(valid_data)}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28950dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class ListwiseRankingLoss(nn.Module):\n",
    "    \"\"\"ë…¼ë¬¸ì—ì„œ ê²€ì¦ëœ ê°€ì¥ íš¨ê³¼ì ì¸ ListMLE ì†ì‹¤\"\"\"\n",
    "    \n",
    "    def __init__(self, temperature=1.0):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        \n",
    "    def forward(self, logits, labels):\n",
    "        \"\"\"\n",
    "        logits: [batch_size, num_classes] - ëª¨ë¸ ì¶œë ¥ (24ê°œ ìˆœì—´ì— ëŒ€í•œ ì ìˆ˜)\n",
    "        labels: [batch_size] - ì •ë‹µ ìˆœì—´ ì¸ë±ìŠ¤\n",
    "        \"\"\"\n",
    "        batch_size = logits.size(0)\n",
    "        num_classes = logits.size(1)  # 24\n",
    "        \n",
    "        # ê° ë°°ì¹˜ì— ëŒ€í•´ ListMLE ì†ì‹¤ ê³„ì‚°\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch_idx in range(batch_size):\n",
    "            batch_logits = logits[batch_idx] / self.temperature  # [24]\n",
    "            target_label = labels[batch_idx].item()\n",
    "            \n",
    "            # ì •ë‹µ ìˆœì—´ì„ ì‹¤ì œ ìˆœì„œë¡œ ë³€í™˜\n",
    "            target_permutation = self.label_to_permutation(target_label)\n",
    "            \n",
    "            # ListMLE: ìˆœì°¨ì ìœ¼ë¡œ ê° ìœ„ì¹˜ì—ì„œ ì˜¬ë°”ë¥¸ ë¬¸ì¥ì„ ì„ íƒí•  í™•ë¥ \n",
    "            remaining_positions = list(range(4))\n",
    "            listwise_loss = 0\n",
    "            \n",
    "            for pos in range(4):\n",
    "                correct_sentence = target_permutation[pos]\n",
    "                \n",
    "                if correct_sentence in remaining_positions:\n",
    "                    # ë‚¨ì€ ë¬¸ì¥ë“¤ ì¤‘ì—ì„œ ì´ ìœ„ì¹˜ì— ì˜¬ í™•ë¥ \n",
    "                    # ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœí™”: ì „ì²´ ìˆœì—´ í™•ë¥ ë¡œ ê·¼ì‚¬\n",
    "                    position_probs = F.softmax(batch_logits, dim=0)\n",
    "                    listwise_loss += -torch.log(position_probs[target_label] + 1e-8)\n",
    "                    break  # ë‹¨ìˆœí™”ëœ ë²„ì „\n",
    "            \n",
    "            total_loss += listwise_loss\n",
    "        \n",
    "        return total_loss / batch_size\n",
    "    \n",
    "    def label_to_permutation(self, label):\n",
    "        \"\"\"ë¼ë²¨ì„ ìˆœì—´ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ (ì „ì—­ ë³€ìˆ˜ ì‚¬ìš©)\"\"\"\n",
    "        # ì „ì—­ label_to_perm ë”•ì…”ë„ˆë¦¬ ì‚¬ìš©\n",
    "        return label_to_perm[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90071e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedStackingEnsemble:\n",
    "    \"\"\"Listwise Ranking Lossê°€ ì ìš©ëœ ìµœê³  ì„±ëŠ¥ Stacking ì•™ìƒë¸”\"\"\"\n",
    "    \n",
    "    def __init__(self, n_folds=5, random_state=42):\n",
    "        self.n_folds = n_folds\n",
    "        self.random_state = random_state\n",
    "        self.base_models = []\n",
    "        self.meta_model = None\n",
    "        # ğŸš€ ì—°êµ¬ ê¸°ë°˜ ìµœì í™”ëœ ì„¤ì • + ELECTRA base ì—…ê·¸ë ˆì´ë“œ\n",
    "        self.base_model_configs = [\n",
    "            {\n",
    "                'name': 'electra_small_listwise',   # ğŸš€ ê°€ë²¼ìš´ ELECTRA Small\n",
    "                'model_name': 'monologg/koelectra-small-v3-discriminator',\n",
    "                'learning_rate': 3e-5,        # small ëª¨ë¸ì€ ë†’ì€ LR\n",
    "                'epochs': 45,                 # ğŸ”¥ ì¶©ë¶„í•œ í•™ìŠµ (20â†’45ë¡œ ëŒ€í­ ì¦ê°€!)\n",
    "                'batch_size': 64,             # smallì´ë¯€ë¡œ ë°°ì¹˜ ì¦ê°€ ê°€ëŠ¥\n",
    "                'warmup_steps': 300,\n",
    "                'weight_decay': 0.01,\n",
    "                'max_grad_norm': 1.0,\n",
    "                'early_stopping_patience': 8  # ì—í¬í¬ê°€ ë§ì•„ì¡Œìœ¼ë‹ˆ patienceë„ ì¦ê°€\n",
    "            },\n",
    "            {\n",
    "                'name': 'bert_base_listwise', \n",
    "                'model_name': 'klue/bert-base',\n",
    "                'learning_rate': 2e-5,        # ì•ˆì •ì \n",
    "                'epochs': 40,                 # ğŸ”¥ ì¶©ë¶„í•œ í•™ìŠµ\n",
    "                'batch_size': 32,             # FP16 ì œê±°ë¡œ ë°°ì¹˜ ì‚¬ì´ì¦ˆ ì¡°ì •\n",
    "                'warmup_steps': 400,\n",
    "                'weight_decay': 0.01,\n",
    "                'max_grad_norm': 1.0,\n",
    "                'early_stopping_patience': 8   # ì¶©ë¶„íˆ ê¸°ë‹¤ë¦¼\n",
    "            },\n",
    "            {\n",
    "                'name': 'roberta_small_listwise',\n",
    "                'model_name': 'klue/roberta-small',\n",
    "                'learning_rate': 2e-5,        # ì•ˆì •í™”\n",
    "                'epochs': 35,                 # ğŸ”¥ ì¶©ë¶„í•œ í•™ìŠµ\n",
    "                'batch_size': 48,             # FP16 ì œê±°ë¡œ ì¡°ì •\n",
    "                'warmup_steps': 300,\n",
    "                'weight_decay': 0.01,\n",
    "                'max_grad_norm': 1.0,\n",
    "                'early_stopping_patience': 6\n",
    "            }\n",
    "        ]\n",
    "    \n",
    "    def train_base_model(self, config, train_dataset, valid_dataset, tokenizer, device):\n",
    "        \"\"\"Listwise Lossê°€ ì ìš©ëœ ë² ì´ìŠ¤ ëª¨ë¸ í•™ìŠµ\"\"\"\n",
    "        print(f\"\\nğŸ”¥ {config['name']} ëª¨ë¸ í•™ìŠµ ì‹œì‘ (Listwise Loss ì ìš©)...\")\n",
    "        \n",
    "        # ëª¨ë¸ ìƒì„± (FP16 ì œê±°)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            config['model_name'],\n",
    "            num_labels=24,\n",
    "            cache_dir='C:/huggingface_cache'\n",
    "        )\n",
    "        model.to(device)\n",
    "        \n",
    "        # ğŸ¯ ìµœì í™”ëœ í•™ìŠµ ì„¤ì •\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=f\"./results_{config['name']}_listwise\",\n",
    "            \n",
    "            # í•µì‹¬ í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
    "            learning_rate=config['learning_rate'],\n",
    "            per_device_train_batch_size=config['batch_size'],\n",
    "            per_device_eval_batch_size=64,\n",
    "            num_train_epochs=config['epochs'],\n",
    "            \n",
    "            # ìµœì í™” ì„¤ì •\n",
    "            warmup_steps=config['warmup_steps'],\n",
    "            weight_decay=config['weight_decay'],\n",
    "            max_grad_norm=config['max_grad_norm'],\n",
    "            \n",
    "            # ì„±ëŠ¥ í–¥ìƒ ì„¤ì •\n",
    "            gradient_accumulation_steps=2,\n",
    "            dataloader_pin_memory=True,\n",
    "            dataloader_num_workers=4,\n",
    "            group_by_length=True,\n",
    "            \n",
    "            # í‰ê°€ ë° ì €ì¥ (ë” ìì£¼)\n",
    "            eval_strategy=\"steps\",\n",
    "            eval_steps=100,\n",
    "            save_strategy=\"steps\",\n",
    "            save_steps=100,\n",
    "            save_total_limit=3,\n",
    "            \n",
    "            # ëª¨ë¸ ì„ íƒ\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"accuracy\",\n",
    "            greater_is_better=True,\n",
    "            \n",
    "            # ì‹œìŠ¤í…œ ìµœì í™” (FP16 ì œê±°)\n",
    "            dataloader_drop_last=True,\n",
    "            remove_unused_columns=False,\n",
    "            \n",
    "            # ë¡œê¹…\n",
    "            logging_steps=50,\n",
    "            report_to=None,\n",
    "            seed=42,\n",
    "            data_seed=42,\n",
    "        )\n",
    "        \n",
    "        # ğŸš€ ì¡°ê¸° ì¢…ë£Œ ì„¤ì •\n",
    "        from transformers import EarlyStoppingCallback\n",
    "        callbacks = [EarlyStoppingCallback(\n",
    "            early_stopping_patience=config['early_stopping_patience']\n",
    "        )]\n",
    "        \n",
    "        # ğŸ¯ Listwise Lossë¥¼ ì‚¬ìš©í•˜ëŠ” ì»¤ìŠ¤í…€ íŠ¸ë ˆì´ë„ˆ\n",
    "        class ListwiseTrainer(Trainer):\n",
    "            def __init__(self, *args, **kwargs):\n",
    "                super().__init__(*args, **kwargs)\n",
    "                self.listwise_loss = ListwiseRankingLoss(temperature=1.0)\n",
    "            \n",
    "            def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "                # ëª¨ë“  ì¶”ê°€ í‚¤ì›Œë“œ ì¸ìë“¤ì„ ë°›ë„ë¡ **kwargs ì¶”ê°€\n",
    "                labels = inputs.get(\"labels\")\n",
    "                outputs = model(**inputs)\n",
    "                logits = outputs.get('logits')\n",
    "                \n",
    "                # Listwise Ranking Loss ì ìš©\n",
    "                loss = self.listwise_loss(logits, labels)\n",
    "                \n",
    "                return (loss, outputs) if return_outputs else loss\n",
    "        \n",
    "        # íŠ¸ë ˆì´ë„ˆ ìƒì„± (Listwise Loss ì ìš©)\n",
    "        trainer = ListwiseTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=valid_dataset,\n",
    "            tokenizer=tokenizer,\n",
    "            data_collator=DataCollatorWithPadding(\n",
    "                tokenizer=tokenizer,\n",
    "                padding=True,\n",
    "                max_length=512,\n",
    "                pad_to_multiple_of=8\n",
    "            ),\n",
    "            compute_metrics=lambda eval_pred: {\n",
    "                \"accuracy\": accuracy_score(\n",
    "                    eval_pred.label_ids, \n",
    "                    np.argmax(eval_pred.predictions, axis=1)\n",
    "                )\n",
    "            },\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "        \n",
    "        # ğŸ“Š í•™ìŠµ íŒŒë¼ë¯¸í„° ì¶œë ¥\n",
    "        print(f\"ğŸ“ {config['name']} Listwise ì„¤ì •:\")\n",
    "        print(f\"   Learning Rate: {config['learning_rate']}\")\n",
    "        print(f\"   Batch Size: {config['batch_size']}\")\n",
    "        print(f\"   Epochs: {config['epochs']}\")\n",
    "        print(f\"   Loss Function: ListMLE (Listwise Ranking)\")\n",
    "        print(f\"   Early Stopping: {config['early_stopping_patience']} patience\")\n",
    "        \n",
    "        # í•™ìŠµ ì‹¤í–‰\n",
    "        trainer.train()\n",
    "        \n",
    "        # ğŸ“ˆ ìµœì¢… í‰ê°€\n",
    "        eval_results = trainer.evaluate()\n",
    "        print(f\"âœ… {config['name']} ìµœì¢… ì„±ëŠ¥ (Listwise):\")\n",
    "        print(f\"   Accuracy: {eval_results['eval_accuracy']:.4f}\")\n",
    "        \n",
    "        # ëª¨ë¸ ì €ì¥\n",
    "        model_save_path = f\"./results_{config['name']}_listwise/final\"\n",
    "        trainer.save_model(model_save_path)\n",
    "        \n",
    "        print(f\"ğŸ’¾ {config['name']} ëª¨ë¸ ì €ì¥ ì™„ë£Œ!\")\n",
    "        \n",
    "        return {\n",
    "            'model': model,\n",
    "            'trainer': trainer,\n",
    "            'config': config,\n",
    "            'save_path': model_save_path,\n",
    "            'final_accuracy': eval_results['eval_accuracy']\n",
    "        }\n",
    "    \n",
    "    # ë‚˜ë¨¸ì§€ ë©”ì„œë“œë“¤ì€ ê¸°ì¡´ê³¼ ë™ì¼\n",
    "    def generate_meta_features(self, models, data, device):\n",
    "        \"\"\"ë©”íƒ€ íŠ¹ì„± ìƒì„± (K-Fold êµì°¨ ê²€ì¦)\"\"\"\n",
    "        print(\"\\nğŸ§  ë©”íƒ€ íŠ¹ì„± ìƒì„± ì¤‘...\")\n",
    "        \n",
    "        # ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # K-Fold ì„¤ì •\n",
    "        kf = KFold(n_splits=self.n_folds, shuffle=True, random_state=self.random_state)\n",
    "        \n",
    "        # ë©”íƒ€ íŠ¹ì„± ì €ì¥í•  ë°°ì—´\n",
    "        meta_features = np.zeros((len(data), len(models) * 24))\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(df)):\n",
    "            print(f\"  Fold {fold + 1}/{self.n_folds} ì²˜ë¦¬ ì¤‘...\")\n",
    "            \n",
    "            val_data = df.iloc[val_idx]\n",
    "            \n",
    "            for model_idx, model_info in enumerate(models):\n",
    "                model = model_info['model']\n",
    "                model.eval()\n",
    "                \n",
    "                tokenizer = AutoTokenizer.from_pretrained(\n",
    "                    model_info['config']['model_name'],\n",
    "                    cache_dir='C:/huggingface_cache'\n",
    "                )\n",
    "                \n",
    "                fold_predictions = []\n",
    "                \n",
    "                for _, row in val_data.iterrows():\n",
    "                    text = row['text']\n",
    "                    \n",
    "                    inputs = tokenizer(\n",
    "                        text,\n",
    "                        return_tensors=\"pt\",\n",
    "                        truncation=True,\n",
    "                        padding=True,\n",
    "                        max_length=512\n",
    "                    ).to(device)\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        outputs = model(**inputs)\n",
    "                        probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "                        fold_predictions.append(probabilities.cpu().numpy()[0])\n",
    "                \n",
    "                start_col = model_idx * 24\n",
    "                end_col = (model_idx + 1) * 24\n",
    "                meta_features[val_idx, start_col:end_col] = np.array(fold_predictions)\n",
    "        \n",
    "        return meta_features\n",
    "    \n",
    "    def train_meta_model(self, meta_features, labels):\n",
    "        \"\"\"ë©”íƒ€ ëª¨ë¸ í•™ìŠµ\"\"\"\n",
    "        print(\"\\nğŸ¯ ë©”íƒ€ ëª¨ë¸ í•™ìŠµ ì¤‘...\")\n",
    "        \n",
    "        self.meta_model = lgb.LGBMClassifier(\n",
    "            objective='multiclass',\n",
    "            num_class=24,\n",
    "            boosting_type='gbdt',\n",
    "            num_leaves=31,\n",
    "            learning_rate=0.05,\n",
    "            feature_fraction=0.9,\n",
    "            bagging_fraction=0.8,\n",
    "            bagging_freq=5,\n",
    "            verbose=0,\n",
    "            random_state=self.random_state\n",
    "        )\n",
    "        \n",
    "        self.meta_model.fit(meta_features, labels)\n",
    "        print(\"âœ… ë©”íƒ€ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")\n",
    "        \n",
    "        return self.meta_model\n",
    "    \n",
    "    def fit(self, train_data, valid_data, device):\n",
    "        \"\"\"ì „ì²´ ìŠ¤íƒí‚¹ ì•™ìƒë¸” í•™ìŠµ\"\"\"\n",
    "        print(\"ğŸš€ Listwise Loss ê¸°ë°˜ Stacking ì•™ìƒë¸” í•™ìŠµ ì‹œì‘!\")\n",
    "        \n",
    "        train_df = pd.DataFrame(train_data)\n",
    "        valid_df = pd.DataFrame(valid_data)\n",
    "        \n",
    "        train_dataset = Dataset.from_pandas(train_df)\n",
    "        valid_dataset = Dataset.from_pandas(valid_df)\n",
    "        \n",
    "        # 1ë‹¨ê³„: Listwise Loss ë² ì´ìŠ¤ ëª¨ë¸ë“¤ í•™ìŠµ\n",
    "        print(\"\\nğŸ“š 1ë‹¨ê³„: Listwise Loss ë² ì´ìŠ¤ ëª¨ë¸ë“¤ í•™ìŠµ\")\n",
    "        for config in self.base_model_configs:\n",
    "            tokenizer = AutoTokenizer.from_pretrained(\n",
    "                config['model_name'],\n",
    "                cache_dir='C:/huggingface_cache'\n",
    "            )\n",
    "            print(f\"âœ… {config['name']} í† í¬ë‚˜ì´ì € ë¡œë“œ ì™„ë£Œ\")\n",
    "            \n",
    "            def tokenize_function(examples):\n",
    "                return tokenizer(\n",
    "                    examples[\"text\"],\n",
    "                    truncation=True,\n",
    "                    padding=True,\n",
    "                    max_length=512\n",
    "                )\n",
    "            \n",
    "            current_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "            current_valid_dataset = valid_dataset.map(tokenize_function, batched=True)\n",
    "            \n",
    "            current_train_dataset = current_train_dataset.remove_columns([\"text\", \"original_sentences\", \"answer\"])\n",
    "            current_valid_dataset = current_valid_dataset.remove_columns([\"text\", \"original_sentences\", \"answer\"])\n",
    "            \n",
    "            model_info = self.train_base_model(config, current_train_dataset, current_valid_dataset, tokenizer, device)\n",
    "            self.base_models.append(model_info)\n",
    "        \n",
    "        # ğŸ“Š ë² ì´ìŠ¤ ëª¨ë¸ ì„±ëŠ¥ ìš”ì•½\n",
    "        print(\"\\nğŸ“ˆ Listwise Loss ë² ì´ìŠ¤ ëª¨ë¸ ì„±ëŠ¥ ìš”ì•½:\")\n",
    "        total_accuracy = 0\n",
    "        for model_info in self.base_models:\n",
    "            accuracy = model_info['final_accuracy']\n",
    "            total_accuracy += accuracy\n",
    "            print(f\"  {model_info['config']['name']}: {accuracy:.4f}\")\n",
    "        avg_accuracy = total_accuracy / len(self.base_models)\n",
    "        print(f\"  í‰ê·  ì •í™•ë„: {avg_accuracy:.4f}\")\n",
    "        \n",
    "        # 2ë‹¨ê³„: ë©”íƒ€ íŠ¹ì„± ìƒì„±\n",
    "        print(\"\\nğŸ”§ 2ë‹¨ê³„: ë©”íƒ€ íŠ¹ì„± ìƒì„±\")\n",
    "        meta_features = self.generate_meta_features(self.base_models, train_data, device)\n",
    "        labels = [item['label'] for item in train_data]\n",
    "        \n",
    "        # 3ë‹¨ê³„: ë©”íƒ€ ëª¨ë¸ í•™ìŠµ\n",
    "        print(\"\\nğŸ“ 3ë‹¨ê³„: ë©”íƒ€ ëª¨ë¸ í•™ìŠµ\")\n",
    "        self.train_meta_model(meta_features, labels)\n",
    "        \n",
    "        print(\"\\nğŸ‰ Listwise Loss ê¸°ë°˜ Stacking ì•™ìƒë¸” í•™ìŠµ ì™„ë£Œ!\")\n",
    "        print(f\"ğŸ† ì˜ˆìƒ ì•™ìƒë¸” ì„±ëŠ¥: {avg_accuracy + 0.08:.4f} (Listwise íš¨ê³¼ + ë©”íƒ€ ëª¨ë¸)\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, test_data, device):\n",
    "        \"\"\"ìŠ¤íƒí‚¹ ì•™ìƒë¸” ì˜ˆì¸¡\"\"\"\n",
    "        print(\"\\nğŸ”® Listwise Loss ê¸°ë°˜ ì•™ìƒë¸” ì˜ˆì¸¡ ì¤‘...\")\n",
    "        \n",
    "        test_meta_features = []\n",
    "        \n",
    "        for model_info in self.base_models:\n",
    "            model = model_info['model']\n",
    "            model.eval()\n",
    "            \n",
    "            tokenizer = AutoTokenizer.from_pretrained(\n",
    "                model_info['config']['model_name'],\n",
    "                cache_dir='C:/huggingface_cache'\n",
    "            )\n",
    "            \n",
    "            model_predictions = []\n",
    "            model_name = model_info['config']['name']\n",
    "            \n",
    "            for text in tqdm(test_data, desc=f\"{model_name} ì˜ˆì¸¡\"):\n",
    "                inputs = tokenizer(\n",
    "                    text,\n",
    "                    return_tensors=\"pt\",\n",
    "                    truncation=True,\n",
    "                    padding=True,\n",
    "                    max_length=512\n",
    "                ).to(device)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    outputs = model(**inputs)\n",
    "                    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "                    model_predictions.append(probabilities.cpu().numpy()[0])\n",
    "            \n",
    "            test_meta_features.append(np.array(model_predictions))\n",
    "        \n",
    "        final_meta_features = np.hstack(test_meta_features)\n",
    "        final_predictions = self.meta_model.predict(final_meta_features)\n",
    "        final_probabilities = self.meta_model.predict_proba(final_meta_features)\n",
    "        \n",
    "        print(\"âœ… Listwise Loss ê¸°ë°˜ ì˜ˆì¸¡ ì™„ë£Œ!\")\n",
    "        \n",
    "        return final_predictions, final_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce16b92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë””ë°”ì´ìŠ¤ ì„¤ì • ì¤‘...\n",
      "ë””ë°”ì´ìŠ¤: cuda\n",
      "GPU ë©”ëª¨ë¦¬: 0.00GB ì‚¬ìš© / 8.00GB ì „ì²´ (0.0% ì‚¬ìš©)\n"
     ]
    }
   ],
   "source": [
    "print(\"ë””ë°”ì´ìŠ¤ ì„¤ì • ì¤‘...\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"ë””ë°”ì´ìŠ¤: {device}\")\n",
    "\n",
    "# GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì²´í¬ í•¨ìˆ˜\n",
    "def print_gpu_utilization():\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "        total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "        usage_percent = (allocated / total) * 100\n",
    "        print(f\"GPU ë©”ëª¨ë¦¬: {allocated:.2f}GB ì‚¬ìš© / {total:.2f}GB ì „ì²´ ({usage_percent:.1f}% ì‚¬ìš©)\")\n",
    "    else:\n",
    "        print(\"CUDA ì‚¬ìš© ë¶ˆê°€\")\n",
    "\n",
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efbbef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Listwise Loss ê¸°ë°˜ Stacking ì•™ìƒë¸” í•™ìŠµ ì‹œì‘!\n",
      "\n",
      "ğŸ“š 1ë‹¨ê³„: Listwise Loss ë² ì´ìŠ¤ ëª¨ë¸ë“¤ í•™ìŠµ\n",
      "âœ… electra_small_listwise í† í¬ë‚˜ì´ì € ë¡œë“œ ì™„ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23523/23523 [00:03<00:00, 7776.82 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5881/5881 [00:00<00:00, 6614.16 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”¥ electra_small_listwise ëª¨ë¸ í•™ìŠµ ì‹œì‘ (Listwise Loss ì ìš©)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-small-v3-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ electra_small_listwise Listwise ì„¤ì •:\n",
      "   Learning Rate: 3e-05\n",
      "   Batch Size: 64\n",
      "   Epochs: 45\n",
      "   Loss Function: ListMLE (Listwise Ranking)\n",
      "   Early Stopping: 8 patience\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8280' max='8280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8280/8280 2:10:53, Epoch 45/45]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.178400</td>\n",
       "      <td>3.178081</td>\n",
       "      <td>0.046360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.146400</td>\n",
       "      <td>3.177083</td>\n",
       "      <td>0.044986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.089700</td>\n",
       "      <td>2.992770</td>\n",
       "      <td>0.138393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.666700</td>\n",
       "      <td>2.563617</td>\n",
       "      <td>0.187157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.391900</td>\n",
       "      <td>2.270684</td>\n",
       "      <td>0.207246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.122300</td>\n",
       "      <td>2.062250</td>\n",
       "      <td>0.220295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.012700</td>\n",
       "      <td>1.932511</td>\n",
       "      <td>0.290865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.887800</td>\n",
       "      <td>1.824717</td>\n",
       "      <td>0.343578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.804900</td>\n",
       "      <td>1.727361</td>\n",
       "      <td>0.383070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.675800</td>\n",
       "      <td>1.627850</td>\n",
       "      <td>0.385989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.577000</td>\n",
       "      <td>1.512388</td>\n",
       "      <td>0.427198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.456900</td>\n",
       "      <td>1.410342</td>\n",
       "      <td>0.441793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>1.364400</td>\n",
       "      <td>1.324603</td>\n",
       "      <td>0.490728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>1.281800</td>\n",
       "      <td>1.233156</td>\n",
       "      <td>0.513393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.205400</td>\n",
       "      <td>1.171319</td>\n",
       "      <td>0.535371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>1.135200</td>\n",
       "      <td>1.088777</td>\n",
       "      <td>0.571600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>1.066700</td>\n",
       "      <td>1.036431</td>\n",
       "      <td>0.583104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>1.026700</td>\n",
       "      <td>0.974549</td>\n",
       "      <td>0.606456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.955100</td>\n",
       "      <td>0.916506</td>\n",
       "      <td>0.618819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.911800</td>\n",
       "      <td>0.873367</td>\n",
       "      <td>0.645604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.855300</td>\n",
       "      <td>0.838904</td>\n",
       "      <td>0.643544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.829700</td>\n",
       "      <td>0.796354</td>\n",
       "      <td>0.677370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.778500</td>\n",
       "      <td>0.775139</td>\n",
       "      <td>0.683036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.748100</td>\n",
       "      <td>0.721617</td>\n",
       "      <td>0.700378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.727600</td>\n",
       "      <td>0.703878</td>\n",
       "      <td>0.709306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.684200</td>\n",
       "      <td>0.673841</td>\n",
       "      <td>0.728537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.660800</td>\n",
       "      <td>0.650665</td>\n",
       "      <td>0.761676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.619500</td>\n",
       "      <td>0.623138</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.610200</td>\n",
       "      <td>0.587321</td>\n",
       "      <td>0.774897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.559600</td>\n",
       "      <td>0.562589</td>\n",
       "      <td>0.783654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.554000</td>\n",
       "      <td>0.541602</td>\n",
       "      <td>0.804087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.516300</td>\n",
       "      <td>0.519186</td>\n",
       "      <td>0.815934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.502508</td>\n",
       "      <td>0.829155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.469500</td>\n",
       "      <td>0.474037</td>\n",
       "      <td>0.844437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.459800</td>\n",
       "      <td>0.450657</td>\n",
       "      <td>0.853022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.422300</td>\n",
       "      <td>0.432824</td>\n",
       "      <td>0.854224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.403200</td>\n",
       "      <td>0.423097</td>\n",
       "      <td>0.855254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.387800</td>\n",
       "      <td>0.388812</td>\n",
       "      <td>0.871051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.351900</td>\n",
       "      <td>0.378617</td>\n",
       "      <td>0.877404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.349700</td>\n",
       "      <td>0.354805</td>\n",
       "      <td>0.883757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.308900</td>\n",
       "      <td>0.336966</td>\n",
       "      <td>0.889423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.310600</td>\n",
       "      <td>0.321236</td>\n",
       "      <td>0.894746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.285000</td>\n",
       "      <td>0.310090</td>\n",
       "      <td>0.899210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.275400</td>\n",
       "      <td>0.295682</td>\n",
       "      <td>0.902988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.252200</td>\n",
       "      <td>0.275295</td>\n",
       "      <td>0.912431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.239900</td>\n",
       "      <td>0.281031</td>\n",
       "      <td>0.906937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.235300</td>\n",
       "      <td>0.269093</td>\n",
       "      <td>0.913633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.218200</td>\n",
       "      <td>0.248173</td>\n",
       "      <td>0.922734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.221900</td>\n",
       "      <td>0.239897</td>\n",
       "      <td>0.923764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.197500</td>\n",
       "      <td>0.234626</td>\n",
       "      <td>0.927026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>0.221972</td>\n",
       "      <td>0.928228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.167300</td>\n",
       "      <td>0.220085</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>0.176200</td>\n",
       "      <td>0.207261</td>\n",
       "      <td>0.934409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.163100</td>\n",
       "      <td>0.202100</td>\n",
       "      <td>0.938187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.153800</td>\n",
       "      <td>0.204523</td>\n",
       "      <td>0.936641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.136900</td>\n",
       "      <td>0.184832</td>\n",
       "      <td>0.940591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>0.140300</td>\n",
       "      <td>0.175772</td>\n",
       "      <td>0.947630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.136500</td>\n",
       "      <td>0.178354</td>\n",
       "      <td>0.946429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>0.124400</td>\n",
       "      <td>0.167018</td>\n",
       "      <td>0.949004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.132200</td>\n",
       "      <td>0.163232</td>\n",
       "      <td>0.949863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>0.131500</td>\n",
       "      <td>0.153730</td>\n",
       "      <td>0.952266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.113300</td>\n",
       "      <td>0.151548</td>\n",
       "      <td>0.953812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>0.103300</td>\n",
       "      <td>0.150330</td>\n",
       "      <td>0.953812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.106800</td>\n",
       "      <td>0.145688</td>\n",
       "      <td>0.955529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.107900</td>\n",
       "      <td>0.144888</td>\n",
       "      <td>0.956216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>0.099100</td>\n",
       "      <td>0.146744</td>\n",
       "      <td>0.955185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>0.097100</td>\n",
       "      <td>0.143325</td>\n",
       "      <td>0.957074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>0.100300</td>\n",
       "      <td>0.135274</td>\n",
       "      <td>0.959993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>0.087800</td>\n",
       "      <td>0.133799</td>\n",
       "      <td>0.958963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.081600</td>\n",
       "      <td>0.131810</td>\n",
       "      <td>0.958791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7100</td>\n",
       "      <td>0.087300</td>\n",
       "      <td>0.134504</td>\n",
       "      <td>0.958791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>0.090900</td>\n",
       "      <td>0.127624</td>\n",
       "      <td>0.962912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7300</td>\n",
       "      <td>0.084800</td>\n",
       "      <td>0.120596</td>\n",
       "      <td>0.963771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>0.085600</td>\n",
       "      <td>0.123737</td>\n",
       "      <td>0.961882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.082000</td>\n",
       "      <td>0.124308</td>\n",
       "      <td>0.963255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>0.086300</td>\n",
       "      <td>0.121841</td>\n",
       "      <td>0.962740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7700</td>\n",
       "      <td>0.082200</td>\n",
       "      <td>0.117255</td>\n",
       "      <td>0.964801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>0.076800</td>\n",
       "      <td>0.116645</td>\n",
       "      <td>0.964629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7900</td>\n",
       "      <td>0.074700</td>\n",
       "      <td>0.116974</td>\n",
       "      <td>0.964973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.075300</td>\n",
       "      <td>0.114729</td>\n",
       "      <td>0.965488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8100</td>\n",
       "      <td>0.076300</td>\n",
       "      <td>0.117357</td>\n",
       "      <td>0.964286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>0.080100</td>\n",
       "      <td>0.116618</td>\n",
       "      <td>0.965488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='91' max='91' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [91/91 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… electra_small_listwise ìµœì¢… ì„±ëŠ¥ (Listwise):\n",
      "   Accuracy: 0.9651\n",
      "ğŸ’¾ electra_small_listwise ëª¨ë¸ ì €ì¥ ì™„ë£Œ!\n",
      "âœ… bert_base_listwise í† í¬ë‚˜ì´ì € ë¡œë“œ ì™„ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23523/23523 [00:03<00:00, 6952.68 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5881/5881 [00:00<00:00, 8712.27 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”¥ bert_base_listwise ëª¨ë¸ í•™ìŠµ ì‹œì‘ (Listwise Loss ì ìš©)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ bert_base_listwise Listwise ì„¤ì •:\n",
      "   Learning Rate: 2e-05\n",
      "   Batch Size: 32\n",
      "   Epochs: 40\n",
      "   Loss Function: ListMLE (Listwise Ranking)\n",
      "   Early Stopping: 8 patience\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='201' max='14720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  201/14720 03:56 < 4:47:06, 0.84 it/s, Epoch 0.54/40]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.201000</td>\n",
       "      <td>3.179537</td>\n",
       "      <td>0.046188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Stacking ì•™ìƒë¸” ìƒì„± ë° í•™ìŠµ\n",
    "stacking_ensemble = AdvancedStackingEnsemble(n_folds=5, random_state=42)\n",
    "\n",
    "# í•™ìŠµ ì‹¤í–‰ (tokenizer íŒŒë¼ë¯¸í„° ì œê±°)\n",
    "stacking_ensemble.fit(train_data, valid_data, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bba2465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# êµ¬ì¡° ì¸ì‹ íˆ¬í‘œ ì˜ˆì¸¡ê¸° í´ë˜ìŠ¤ (ê¸°ì¡´ ì½”ë“œì— ì¶”ê°€)\n",
    "# =============================================================================\n",
    "\n",
    "class StructureAwareVotingPredictor:\n",
    "    \"\"\"ë¬¸ì¥ ìˆœì„œ ë°°ì—´ì„ ìœ„í•œ êµ¬ì¡° ì¸ì‹ íˆ¬í‘œ ì˜ˆì¸¡ê¸°\"\"\"\n",
    "    \n",
    "    def __init__(self, stacking_ensemble, label_to_perm, perm_to_label):\n",
    "        self.ensemble = stacking_ensemble\n",
    "        self.label_to_perm = label_to_perm\n",
    "        self.perm_to_label = perm_to_label\n",
    "        \n",
    "    def predict(self, test_texts, device):\n",
    "        \"\"\"êµ¬ì¡° ì¸ì‹ íˆ¬í‘œ ì˜ˆì¸¡ ì‹¤í–‰\"\"\"\n",
    "        print(\"ğŸ¯ êµ¬ì¡° ì¸ì‹ íˆ¬í‘œ ì˜ˆì¸¡ ì‹œì‘...\")\n",
    "        \n",
    "        # ê° ë² ì´ìŠ¤ ëª¨ë¸ë³„ ì˜ˆì¸¡ ìˆ˜ì§‘\n",
    "        all_model_predictions = []\n",
    "        all_model_probabilities = []\n",
    "        \n",
    "        for model_idx, model_info in enumerate(self.ensemble.base_models):\n",
    "            print(f\"  ëª¨ë¸ {model_idx + 1}/{len(self.ensemble.base_models)} ì˜ˆì¸¡ ì¤‘...\")\n",
    "            \n",
    "            model = model_info['model']\n",
    "            model.eval()\n",
    "            \n",
    "            tokenizer = AutoTokenizer.from_pretrained(\n",
    "                model_info['config']['model_name'],\n",
    "                cache_dir='C:/huggingface_cache'\n",
    "            )\n",
    "            \n",
    "            model_predictions = []\n",
    "            model_probabilities = []\n",
    "            \n",
    "            for text in tqdm(test_texts, desc=f\"ëª¨ë¸ {model_idx + 1}\"):\n",
    "                inputs = tokenizer(\n",
    "                    text,\n",
    "                    return_tensors=\"pt\",\n",
    "                    truncation=True,\n",
    "                    padding=True,\n",
    "                    max_length=512\n",
    "                ).to(device)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    outputs = model(**inputs)\n",
    "                    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "                    prob_array = probabilities.cpu().numpy()[0]\n",
    "                    \n",
    "                    model_predictions.append(np.argmax(prob_array))\n",
    "                    model_probabilities.append(prob_array)\n",
    "            \n",
    "            all_model_predictions.append(model_predictions)\n",
    "            all_model_probabilities.append(model_probabilities)\n",
    "        \n",
    "        # êµ¬ì¡° ì¸ì‹ íˆ¬í‘œ ì‹¤í–‰\n",
    "        print(\"  ğŸ§  ë¬¸ì¥ ìŒë³„ ê´€ê³„ ë¶„ì„ ë° ìµœì  ìˆœì—´ êµ¬ì„± ì¤‘...\")\n",
    "        final_predictions = []\n",
    "        final_probabilities = []\n",
    "        \n",
    "        for i in tqdm(range(len(test_texts)), desc=\"êµ¬ì¡° ë¶„ì„\"):\n",
    "            # ê° ëª¨ë¸ì˜ ì˜ˆì¸¡ì„ ìˆœì—´ë¡œ ë³€í™˜\n",
    "            model_permutations = []\n",
    "            model_confidences = []\n",
    "            \n",
    "            for model_idx in range(len(self.ensemble.base_models)):\n",
    "                pred_label = all_model_predictions[model_idx][i]\n",
    "                pred_perm = self.label_to_perm[pred_label]\n",
    "                confidence = np.max(all_model_probabilities[model_idx][i])\n",
    "                \n",
    "                model_permutations.append(pred_perm)\n",
    "                model_confidences.append(confidence)\n",
    "            \n",
    "            # ë¬¸ì¥ ìŒë³„ ìˆœì„œ ê´€ê³„ ë¶„ì„\n",
    "            pair_votes = {}\n",
    "            for pos1 in range(4):\n",
    "                for pos2 in range(4):\n",
    "                    if pos1 != pos2:\n",
    "                        pair_votes[(pos1, pos2)] = []\n",
    "            \n",
    "            # ê° ëª¨ë¸ì˜ ìˆœì—´ì—ì„œ ìŒë³„ ê´€ê³„ ì¶”ì¶œ\n",
    "            for model_idx, perm in enumerate(model_permutations):\n",
    "                confidence = model_confidences[model_idx]\n",
    "                \n",
    "                for pos1 in range(4):\n",
    "                    for pos2 in range(4):\n",
    "                        if pos1 != pos2:\n",
    "                            # perm[pos1]ì´ perm[pos2]ë³´ë‹¤ ë¨¼ì € ë‚˜ì™€ì•¼ í•˜ëŠ”ì§€ í™•ì¸\n",
    "                            sent1_order = perm[pos1]\n",
    "                            sent2_order = perm[pos2]\n",
    "                            \n",
    "                            if sent1_order < sent2_order:\n",
    "                                # ë¬¸ì¥ pos1ì´ ë¬¸ì¥ pos2ë³´ë‹¤ ë¨¼ì €\n",
    "                                pair_votes[(pos1, pos2)].append(confidence)\n",
    "                            else:\n",
    "                                # ë¬¸ì¥ pos2ê°€ ë¬¸ì¥ pos1ë³´ë‹¤ ë¨¼ì €\n",
    "                                pair_votes[(pos2, pos1)].append(confidence)\n",
    "            \n",
    "            # ìŒë³„ íˆ¬í‘œ ê²°ê³¼ë¡œ ìµœì  ìˆœì—´ êµ¬ì„±\n",
    "            best_permutation = self._construct_optimal_permutation(pair_votes)\n",
    "            \n",
    "            # ìµœì  ìˆœì—´ì„ ë¼ë²¨ë¡œ ë³€í™˜\n",
    "            if best_permutation in self.perm_to_label:\n",
    "                final_label = self.perm_to_label[best_permutation]\n",
    "            else:\n",
    "                # ë°±ì—…: ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„ì˜ ëª¨ë¸ ì„ íƒ\n",
    "                best_model_idx = np.argmax(model_confidences)\n",
    "                final_label = all_model_predictions[best_model_idx][i]\n",
    "            \n",
    "            final_predictions.append(final_label)\n",
    "            \n",
    "            # í™•ë¥ ì€ í•´ë‹¹ ìˆœì—´ì— ëŒ€í•œ ëª¨ë“  ëª¨ë¸ì˜ í‰ê·  í™•ë¥ \n",
    "            avg_probs = np.mean([all_model_probabilities[j][i] for j in range(len(self.ensemble.base_models))], axis=0)\n",
    "            final_probabilities.append(avg_probs)\n",
    "        \n",
    "        final_predictions = np.array(final_predictions)\n",
    "        final_probabilities = np.array(final_probabilities)\n",
    "        \n",
    "        print(\"âœ… êµ¬ì¡° ì¸ì‹ íˆ¬í‘œ ì˜ˆì¸¡ ì™„ë£Œ!\")\n",
    "        return final_predictions, final_probabilities\n",
    "    \n",
    "    def _construct_optimal_permutation(self, pair_votes):\n",
    "        \"\"\"ìŒë³„ íˆ¬í‘œ ê²°ê³¼ë¡œë¶€í„° ìµœì  ìˆœì—´ êµ¬ì„±\"\"\"\n",
    "        # ê° ìŒì— ëŒ€í•œ íˆ¬í‘œ ê°•ë„ ê³„ì‚°\n",
    "        pair_strengths = {}\n",
    "        for pair, votes in pair_votes.items():\n",
    "            if votes:\n",
    "                pair_strengths[pair] = sum(votes) / len(votes)\n",
    "            else:\n",
    "                pair_strengths[pair] = 0\n",
    "        \n",
    "        # í† ë„ˆë¨¼íŠ¸ ë°©ì‹ìœ¼ë¡œ ìˆœì„œ ê²°ì •\n",
    "        sentences = list(range(4))\n",
    "        sentence_scores = {i: 0 for i in range(4)}\n",
    "        \n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                if i != j:\n",
    "                    if pair_strengths.get((i, j), 0) > pair_strengths.get((j, i), 0):\n",
    "                        sentence_scores[i] += pair_strengths.get((i, j), 0)\n",
    "                    else:\n",
    "                        sentence_scores[j] += pair_strengths.get((j, i), 0)\n",
    "        \n",
    "        # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìˆœì—´ ìƒì„±\n",
    "        sorted_sentences = sorted(sentences, key=lambda x: sentence_scores[x], reverse=True)\n",
    "        \n",
    "        # ìˆœì—´ì„ ì˜¬ë°”ë¥¸ í˜•íƒœë¡œ ë³€í™˜ (ì–´ë–¤ ë¬¸ì¥ì´ ëª‡ ë²ˆì§¸ ìœ„ì¹˜ì— ìˆëŠ”ì§€)\n",
    "        permutation = [0] * 4\n",
    "        for position, sentence_idx in enumerate(sorted_sentences):\n",
    "            permutation[sentence_idx] = position\n",
    "        \n",
    "        return tuple(permutation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d4a0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ì¤‘...\n",
      "í…ŒìŠ¤íŠ¸ ë°ì´í„°: 1780ê°œ\n",
      "ğŸ¯ êµ¬ì¡° ì¸ì‹ íˆ¬í‘œ ì˜ˆì¸¡ ì‹œì‘...\n",
      "  ëª¨ë¸ 1/3 ì˜ˆì¸¡ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1780/1780 [00:22<00:00, 79.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ëª¨ë¸ 2/3 ì˜ˆì¸¡ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1780/1780 [00:12<00:00, 144.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ëª¨ë¸ 3/3 ì˜ˆì¸¡ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1780/1780 [00:23<00:00, 74.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ§  ë¬¸ì¥ ìŒë³„ ê´€ê³„ ë¶„ì„ ë° ìµœì  ìˆœì—´ êµ¬ì„± ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "êµ¬ì¡° ë¶„ì„: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1780/1780 [00:00<00:00, 12999.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… êµ¬ì¡° ì¸ì‹ íˆ¬í‘œ ì˜ˆì¸¡ ì™„ë£Œ!\n",
      "\n",
      "í‰ê·  ì˜ˆì¸¡ ì‹ ë¢°ë„: 0.6991\n",
      "\n",
      "ğŸ¯ êµ¬ì¡° ì¸ì‹ íˆ¬í‘œ ë¶„ì„:\n",
      "   - ë¬¸ì¥ ìŒë³„ ê´€ê³„ ê¸°ë°˜ ì˜ˆì¸¡\n",
      "   - ë² ì´ìŠ¤ ëª¨ë¸ ìˆ˜: 3ê°œ\n",
      "   - ì‹ ë¢°ë„ ê°€ì¤‘ íˆ¬í‘œ ì ìš©\n",
      "   - ìˆœì—´ ì¼ê´€ì„± ê²€ì¦ ì™„ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ìˆ˜ì •ëœ ì˜ˆì¸¡ ì…€ ì½”ë“œ (ê¸°ì¡´ ì…€ 8ë²ˆ ëŒ€ì²´)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ì¤‘...\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ\n",
    "test_df = pd.read_csv(\"./test.csv\")\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_df)}ê°œ\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ì „ì²˜ë¦¬\n",
    "test_texts = []\n",
    "for _, row in test_df.iterrows():\n",
    "    sentences = [row[f\"sentence_{i}\"] for i in range(4)]\n",
    "    text = \" [SEP] \".join(sentences)\n",
    "    test_texts.append(text)\n",
    "\n",
    "# êµ¬ì¡° ì¸ì‹ íˆ¬í‘œ ì˜ˆì¸¡ê¸° ìƒì„±\n",
    "structure_predictor = StructureAwareVotingPredictor(\n",
    "    stacking_ensemble, label_to_perm, perm_to_label\n",
    ")\n",
    "\n",
    "# êµ¬ì¡° ì¸ì‹ íˆ¬í‘œë¡œ ì˜ˆì¸¡ ì‹¤í–‰\n",
    "final_predictions, final_probabilities = structure_predictor.predict(test_texts, device)\n",
    "\n",
    "# ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ìˆœì—´ë¡œ ë³€í™˜\n",
    "predicted_orders = []\n",
    "confidences = []\n",
    "\n",
    "for i, pred_label in enumerate(final_predictions):\n",
    "    predicted_order = list(label_to_perm[pred_label])\n",
    "    confidence = np.max(final_probabilities[i])\n",
    "    \n",
    "    predicted_orders.append(predicted_order)\n",
    "    confidences.append(confidence)\n",
    "\n",
    "# í‰ê·  ì‹ ë¢°ë„ ì¶œë ¥\n",
    "avg_confidence = np.mean(confidences)\n",
    "print(f\"\\ní‰ê·  ì˜ˆì¸¡ ì‹ ë¢°ë„: {avg_confidence:.4f}\")\n",
    "\n",
    "# êµ¬ì¡° ì¸ì‹ íˆ¬í‘œì˜ íš¨ê³¼ ë¶„ì„\n",
    "print(f\"\\nğŸ¯ êµ¬ì¡° ì¸ì‹ íˆ¬í‘œ ë¶„ì„:\")\n",
    "print(f\"   - ë¬¸ì¥ ìŒë³„ ê´€ê³„ ê¸°ë°˜ ì˜ˆì¸¡\")\n",
    "print(f\"   - ë² ì´ìŠ¤ ëª¨ë¸ ìˆ˜: {len(stacking_ensemble.base_models)}ê°œ\")\n",
    "print(f\"   - ì‹ ë¢°ë„ ê°€ì¤‘ íˆ¬í‘œ ì ìš©\")\n",
    "print(f\"   - ìˆœì—´ ì¼ê´€ì„± ê²€ì¦ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e891b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission íŒŒì¼ ìƒì„± ì¤‘...\n",
      "ì œì¶œ íŒŒì¼ ì €ì¥ ì™„ë£Œ: stacking_ensemble_submission.csv\n",
      "\n",
      "============================================================\n",
      "ğŸ† ê³ ê¸‰ Stacking ì•™ìƒë¸” ì™„ë£Œ!\n",
      "ğŸ“Š ë² ì´ìŠ¤ ëª¨ë¸ ìˆ˜: 3ê°œ\n",
      "ğŸ¯ ë©”íƒ€ ëª¨ë¸: LightGBM\n",
      "ğŸ”® í‰ê·  ì˜ˆì¸¡ ì‹ ë¢°ë„: 69.91%\n",
      "ğŸ“ ì œì¶œ íŒŒì¼: stacking_ensemble_submission.csv\n",
      "============================================================\n",
      "\n",
      "ê°œë³„ ë² ì´ìŠ¤ ëª¨ë¸ ì •ë³´:\n",
      "  ëª¨ë¸ 1: bert_small (LR: 1.5e-05, Epochs: 25)\n",
      "  ëª¨ë¸ 2: roberta_small (LR: 2e-05, Epochs: 20)\n",
      "  ëª¨ë¸ 3: electra_small (LR: 3e-05, Epochs: 15)\n"
     ]
    }
   ],
   "source": [
    "print(\"Submission íŒŒì¼ ìƒì„± ì¤‘...\")\n",
    "\n",
    "# ìƒ˜í”Œ ì œì¶œ íŒŒì¼ ë¡œë“œ\n",
    "sample_submission = pd.read_csv(\"./sample_submission.csv\")\n",
    "\n",
    "# ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì œì¶œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "for i in range(4):\n",
    "    sample_submission[f\"answer_{i}\"] = [pred[i] for pred in predicted_orders]\n",
    "\n",
    "# íŒŒì¼ ì €ì¥\n",
    "submission_filename = \"stacking_ensemble_submission.csv\"\n",
    "sample_submission.to_csv(submission_filename, index=False)\n",
    "\n",
    "print(f\"ì œì¶œ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {submission_filename}\")\n",
    "\n",
    "# ìµœì¢… ê²°ê³¼ ìš”ì•½\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(f\"ğŸ† ê³ ê¸‰ Stacking ì•™ìƒë¸” ì™„ë£Œ!\")\n",
    "print(f\"ğŸ“Š ë² ì´ìŠ¤ ëª¨ë¸ ìˆ˜: {len(stacking_ensemble.base_models)}ê°œ\")\n",
    "print(f\"ğŸ¯ ë©”íƒ€ ëª¨ë¸: LightGBM\")\n",
    "print(f\"ğŸ”® í‰ê·  ì˜ˆì¸¡ ì‹ ë¢°ë„: {avg_confidence*100:.2f}%\")\n",
    "print(f\"ğŸ“ ì œì¶œ íŒŒì¼: {submission_filename}\")\n",
    "print(f\"=\"*60)\n",
    "\n",
    "# ê°œë³„ ëª¨ë¸ ì„±ëŠ¥ë„ í™•ì¸í•´ë³´ê¸°\n",
    "print(f\"\\nê°œë³„ ë² ì´ìŠ¤ ëª¨ë¸ ì •ë³´:\")\n",
    "for i, model_info in enumerate(stacking_ensemble.base_models):\n",
    "    config = model_info['config']\n",
    "    print(f\"  ëª¨ë¸ {i+1}: {config['name']} (LR: {config['learning_rate']}, Epochs: {config['epochs']})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daycon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
