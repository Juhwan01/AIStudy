{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "703e1e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\envs\\daycon\\Lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "c:\\Anaconda3\\envs\\daycon\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import lightgbm as lgb\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F  \n",
    "import safetensors\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer, \n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "from itertools import permutations\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74934889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 24개의 순열 클래스 생성\n",
      "예시 매핑:\n",
      "  라벨 0: (0, 1, 2, 3)\n",
      "  라벨 1: (0, 1, 3, 2)\n",
      "  라벨 2: (0, 2, 1, 3)\n",
      "  라벨 3: (0, 2, 3, 1)\n",
      "  라벨 4: (0, 3, 1, 2)\n"
     ]
    }
   ],
   "source": [
    "def create_label_mappings():\n",
    "    \"\"\"24가지 순열에 대한 라벨 매핑 생성\"\"\"\n",
    "    all_permutations = list(permutations([0, 1, 2, 3]))\n",
    "    perm_to_label = {perm: idx for idx, perm in enumerate(all_permutations)}\n",
    "    label_to_perm = {idx: perm for idx, perm in enumerate(all_permutations)}\n",
    "    \n",
    "    print(f\"총 {len(all_permutations)}개의 순열 클래스 생성\")\n",
    "    print(\"예시 매핑:\")\n",
    "    for i in range(5):\n",
    "        print(f\"  라벨 {i}: {all_permutations[i]}\")\n",
    "    \n",
    "    return perm_to_label, label_to_perm\n",
    "\n",
    "# 순열 매핑 생성\n",
    "perm_to_label, label_to_perm = create_label_mappings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bef94fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_roberta_data(train_df, perm_to_label):\n",
    "    \"\"\"RoBERTa용 데이터 준비\"\"\"\n",
    "    processed_data = []\n",
    "    \n",
    "    for _, row in train_df.iterrows():\n",
    "        sentences = [row[f\"sentence_{i}\"] for i in range(4)]\n",
    "        answer_tuple = tuple([row[f\"answer_{i}\"] for i in range(4)])\n",
    "        text = \" [SEP] \".join(sentences)\n",
    "        label = perm_to_label[answer_tuple]\n",
    "        \n",
    "        processed_data.append({\n",
    "            \"text\": text,\n",
    "            \"label\": label,\n",
    "            \"original_sentences\": sentences,\n",
    "            \"answer\": answer_tuple\n",
    "        })\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "def augment_roberta_data_advanced(train_df, perm_to_label, multiplier=4):\n",
    "    \"\"\"고급 데이터 증강\"\"\"\n",
    "    augmented_data = []\n",
    "    \n",
    "    # 원본 데이터\n",
    "    original_data = prepare_roberta_data(train_df, perm_to_label)\n",
    "    augmented_data.extend(original_data)\n",
    "    \n",
    "    # 다양한 증강 방법\n",
    "    for aug_round in range(multiplier - 1):\n",
    "        for _, row in train_df.iterrows():\n",
    "            sentences = [row[f\"sentence_{i}\"] for i in range(4)]\n",
    "            original_answer = [row[f\"answer_{i}\"] for i in range(4)]\n",
    "            \n",
    "            if aug_round == 0:\n",
    "                # 랜덤 셔플\n",
    "                indices = list(range(4))\n",
    "                np.random.shuffle(indices)\n",
    "            elif aug_round == 1:\n",
    "                # 순환 이동\n",
    "                shift = np.random.randint(1, 4)\n",
    "                indices = [(i + shift) % 4 for i in range(4)]\n",
    "            else:\n",
    "                # 부분 교환\n",
    "                indices = list(range(4))\n",
    "                i, j = np.random.choice(4, 2, replace=False)\n",
    "                indices[i], indices[j] = indices[j], indices[i]\n",
    "            \n",
    "            shuffled_sentences = [sentences[i] for i in indices]\n",
    "            new_answer = tuple([indices.index(original_answer[i]) for i in range(4)])\n",
    "            \n",
    "            text = \" [SEP] \".join(shuffled_sentences)\n",
    "            label = perm_to_label[new_answer]\n",
    "            \n",
    "            augmented_data.append({\n",
    "                \"text\": text,\n",
    "                \"label\": label,\n",
    "                \"original_sentences\": shuffled_sentences,\n",
    "                \"answer\": new_answer\n",
    "            })\n",
    "    \n",
    "    print(f\"고급 데이터 증강 완료: {len(original_data)} → {len(augmented_data)}\")\n",
    "    return augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b89decf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로드 중...\n",
      "원본 학습 데이터: 7351개\n",
      "\n",
      "고급 데이터 증강 중...\n",
      "고급 데이터 증강 완료: 7351 → 29404\n",
      "\n",
      "학습/검증 데이터 분할...\n",
      "학습 데이터: 23523개\n",
      "검증 데이터: 5881개\n"
     ]
    }
   ],
   "source": [
    "print(\"데이터 로드 중...\")\n",
    "train_df = pd.read_csv('./train.csv')\n",
    "print(f\"원본 학습 데이터: {len(train_df)}개\")\n",
    "\n",
    "print(\"\\n고급 데이터 증강 중...\")\n",
    "augmented_data = augment_roberta_data_advanced(train_df, perm_to_label, multiplier=4)\n",
    "\n",
    "print(\"\\n학습/검증 데이터 분할...\")\n",
    "train_data, valid_data = train_test_split(\n",
    "    augmented_data, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=[item[\"label\"] for item in augmented_data]\n",
    ")\n",
    "\n",
    "print(f\"학습 데이터: {len(train_data)}개\")\n",
    "print(f\"검증 데이터: {len(valid_data)}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28950dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class ListwiseRankingLoss(nn.Module):\n",
    "    \"\"\"논문에서 검증된 가장 효과적인 ListMLE 손실\"\"\"\n",
    "    \n",
    "    def __init__(self, temperature=1.0):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        \n",
    "    def forward(self, logits, labels):\n",
    "        \"\"\"\n",
    "        logits: [batch_size, num_classes] - 모델 출력 (24개 순열에 대한 점수)\n",
    "        labels: [batch_size] - 정답 순열 인덱스\n",
    "        \"\"\"\n",
    "        batch_size = logits.size(0)\n",
    "        num_classes = logits.size(1)  # 24\n",
    "        \n",
    "        # 각 배치에 대해 ListMLE 손실 계산\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch_idx in range(batch_size):\n",
    "            batch_logits = logits[batch_idx] / self.temperature  # [24]\n",
    "            target_label = labels[batch_idx].item()\n",
    "            \n",
    "            # 정답 순열을 실제 순서로 변환\n",
    "            target_permutation = self.label_to_permutation(target_label)\n",
    "            \n",
    "            # ListMLE: 순차적으로 각 위치에서 올바른 문장을 선택할 확률\n",
    "            remaining_positions = list(range(4))\n",
    "            listwise_loss = 0\n",
    "            \n",
    "            for pos in range(4):\n",
    "                correct_sentence = target_permutation[pos]\n",
    "                \n",
    "                if correct_sentence in remaining_positions:\n",
    "                    # 남은 문장들 중에서 이 위치에 올 확률\n",
    "                    # 여기서는 단순화: 전체 순열 확률로 근사\n",
    "                    position_probs = F.softmax(batch_logits, dim=0)\n",
    "                    listwise_loss += -torch.log(position_probs[target_label] + 1e-8)\n",
    "                    break  # 단순화된 버전\n",
    "            \n",
    "            total_loss += listwise_loss\n",
    "        \n",
    "        return total_loss / batch_size\n",
    "    \n",
    "    def label_to_permutation(self, label):\n",
    "        \"\"\"라벨을 순열로 변환하는 함수 (전역 변수 사용)\"\"\"\n",
    "        # 전역 label_to_perm 딕셔너리 사용\n",
    "        return label_to_perm[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90071e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedStackingEnsemble:\n",
    "    \"\"\"Listwise Ranking Loss가 적용된 최고 성능 Stacking 앙상블\"\"\"\n",
    "    \n",
    "    def __init__(self, n_folds=5, random_state=42):\n",
    "        self.n_folds = n_folds\n",
    "        self.random_state = random_state\n",
    "        self.base_models = []\n",
    "        self.meta_model = None\n",
    "        # 🚀 연구 기반 최적화된 설정 + ELECTRA base 업그레이드\n",
    "        self.base_model_configs = [\n",
    "            {\n",
    "                'name': 'electra_small_listwise',   # 🚀 가벼운 ELECTRA Small\n",
    "                'model_name': 'monologg/koelectra-small-v3-discriminator',\n",
    "                'learning_rate': 3e-5,        # small 모델은 높은 LR\n",
    "                'epochs': 45,                 # 🔥 충분한 학습 (20→45로 대폭 증가!)\n",
    "                'batch_size': 64,             # small이므로 배치 증가 가능\n",
    "                'warmup_steps': 300,\n",
    "                'weight_decay': 0.01,\n",
    "                'max_grad_norm': 1.0,\n",
    "                'early_stopping_patience': 8  # 에포크가 많아졌으니 patience도 증가\n",
    "            },\n",
    "            {\n",
    "                'name': 'bert_base_listwise', \n",
    "                'model_name': 'klue/bert-base',\n",
    "                'learning_rate': 2e-5,        # 안정적\n",
    "                'epochs': 40,                 # 🔥 충분한 학습\n",
    "                'batch_size': 32,             # FP16 제거로 배치 사이즈 조정\n",
    "                'warmup_steps': 400,\n",
    "                'weight_decay': 0.01,\n",
    "                'max_grad_norm': 1.0,\n",
    "                'early_stopping_patience': 8   # 충분히 기다림\n",
    "            },\n",
    "            {\n",
    "                'name': 'roberta_small_listwise',\n",
    "                'model_name': 'klue/roberta-small',\n",
    "                'learning_rate': 2e-5,        # 안정화\n",
    "                'epochs': 35,                 # 🔥 충분한 학습\n",
    "                'batch_size': 48,             # FP16 제거로 조정\n",
    "                'warmup_steps': 300,\n",
    "                'weight_decay': 0.01,\n",
    "                'max_grad_norm': 1.0,\n",
    "                'early_stopping_patience': 6\n",
    "            }\n",
    "        ]\n",
    "    \n",
    "    def train_base_model(self, config, train_dataset, valid_dataset, tokenizer, device):\n",
    "        \"\"\"Listwise Loss가 적용된 베이스 모델 학습\"\"\"\n",
    "        print(f\"\\n🔥 {config['name']} 모델 학습 시작 (Listwise Loss 적용)...\")\n",
    "        \n",
    "        # 모델 생성 (FP16 제거)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            config['model_name'],\n",
    "            num_labels=24,\n",
    "            cache_dir='C:/huggingface_cache'\n",
    "        )\n",
    "        model.to(device)\n",
    "        \n",
    "        # 🎯 최적화된 학습 설정\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=f\"./results_{config['name']}_listwise\",\n",
    "            \n",
    "            # 핵심 하이퍼파라미터\n",
    "            learning_rate=config['learning_rate'],\n",
    "            per_device_train_batch_size=config['batch_size'],\n",
    "            per_device_eval_batch_size=64,\n",
    "            num_train_epochs=config['epochs'],\n",
    "            \n",
    "            # 최적화 설정\n",
    "            warmup_steps=config['warmup_steps'],\n",
    "            weight_decay=config['weight_decay'],\n",
    "            max_grad_norm=config['max_grad_norm'],\n",
    "            \n",
    "            # 성능 향상 설정\n",
    "            gradient_accumulation_steps=2,\n",
    "            dataloader_pin_memory=True,\n",
    "            dataloader_num_workers=4,\n",
    "            group_by_length=True,\n",
    "            \n",
    "            # 평가 및 저장 (더 자주)\n",
    "            eval_strategy=\"steps\",\n",
    "            eval_steps=100,\n",
    "            save_strategy=\"steps\",\n",
    "            save_steps=100,\n",
    "            save_total_limit=3,\n",
    "            \n",
    "            # 모델 선택\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"accuracy\",\n",
    "            greater_is_better=True,\n",
    "            \n",
    "            # 시스템 최적화 (FP16 제거)\n",
    "            dataloader_drop_last=True,\n",
    "            remove_unused_columns=False,\n",
    "            \n",
    "            # 로깅\n",
    "            logging_steps=50,\n",
    "            report_to=None,\n",
    "            seed=42,\n",
    "            data_seed=42,\n",
    "        )\n",
    "        \n",
    "        # 🚀 조기 종료 설정\n",
    "        from transformers import EarlyStoppingCallback\n",
    "        callbacks = [EarlyStoppingCallback(\n",
    "            early_stopping_patience=config['early_stopping_patience']\n",
    "        )]\n",
    "        \n",
    "        # 🎯 Listwise Loss를 사용하는 커스텀 트레이너\n",
    "        class ListwiseTrainer(Trainer):\n",
    "            def __init__(self, *args, **kwargs):\n",
    "                super().__init__(*args, **kwargs)\n",
    "                self.listwise_loss = ListwiseRankingLoss(temperature=1.0)\n",
    "            \n",
    "            def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "                # 모든 추가 키워드 인자들을 받도록 **kwargs 추가\n",
    "                labels = inputs.get(\"labels\")\n",
    "                outputs = model(**inputs)\n",
    "                logits = outputs.get('logits')\n",
    "                \n",
    "                # Listwise Ranking Loss 적용\n",
    "                loss = self.listwise_loss(logits, labels)\n",
    "                \n",
    "                return (loss, outputs) if return_outputs else loss\n",
    "        \n",
    "        # 트레이너 생성 (Listwise Loss 적용)\n",
    "        trainer = ListwiseTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=valid_dataset,\n",
    "            tokenizer=tokenizer,\n",
    "            data_collator=DataCollatorWithPadding(\n",
    "                tokenizer=tokenizer,\n",
    "                padding=True,\n",
    "                max_length=512,\n",
    "                pad_to_multiple_of=8\n",
    "            ),\n",
    "            compute_metrics=lambda eval_pred: {\n",
    "                \"accuracy\": accuracy_score(\n",
    "                    eval_pred.label_ids, \n",
    "                    np.argmax(eval_pred.predictions, axis=1)\n",
    "                )\n",
    "            },\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "        \n",
    "        # 📊 학습 파라미터 출력\n",
    "        print(f\"🎓 {config['name']} Listwise 설정:\")\n",
    "        print(f\"   Learning Rate: {config['learning_rate']}\")\n",
    "        print(f\"   Batch Size: {config['batch_size']}\")\n",
    "        print(f\"   Epochs: {config['epochs']}\")\n",
    "        print(f\"   Loss Function: ListMLE (Listwise Ranking)\")\n",
    "        print(f\"   Early Stopping: {config['early_stopping_patience']} patience\")\n",
    "        \n",
    "        # 학습 실행\n",
    "        trainer.train()\n",
    "        \n",
    "        # 📈 최종 평가\n",
    "        eval_results = trainer.evaluate()\n",
    "        print(f\"✅ {config['name']} 최종 성능 (Listwise):\")\n",
    "        print(f\"   Accuracy: {eval_results['eval_accuracy']:.4f}\")\n",
    "        \n",
    "        # 모델 저장\n",
    "        model_save_path = f\"./results_{config['name']}_listwise/final\"\n",
    "        trainer.save_model(model_save_path)\n",
    "        \n",
    "        print(f\"💾 {config['name']} 모델 저장 완료!\")\n",
    "        \n",
    "        return {\n",
    "            'model': model,\n",
    "            'trainer': trainer,\n",
    "            'config': config,\n",
    "            'save_path': model_save_path,\n",
    "            'final_accuracy': eval_results['eval_accuracy']\n",
    "        }\n",
    "    \n",
    "    # 나머지 메서드들은 기존과 동일\n",
    "    def generate_meta_features(self, models, data, device):\n",
    "        \"\"\"메타 특성 생성 (K-Fold 교차 검증)\"\"\"\n",
    "        print(\"\\n🧠 메타 특성 생성 중...\")\n",
    "        \n",
    "        # 데이터를 DataFrame으로 변환\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # K-Fold 설정\n",
    "        kf = KFold(n_splits=self.n_folds, shuffle=True, random_state=self.random_state)\n",
    "        \n",
    "        # 메타 특성 저장할 배열\n",
    "        meta_features = np.zeros((len(data), len(models) * 24))\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(df)):\n",
    "            print(f\"  Fold {fold + 1}/{self.n_folds} 처리 중...\")\n",
    "            \n",
    "            val_data = df.iloc[val_idx]\n",
    "            \n",
    "            for model_idx, model_info in enumerate(models):\n",
    "                model = model_info['model']\n",
    "                model.eval()\n",
    "                \n",
    "                tokenizer = AutoTokenizer.from_pretrained(\n",
    "                    model_info['config']['model_name'],\n",
    "                    cache_dir='C:/huggingface_cache'\n",
    "                )\n",
    "                \n",
    "                fold_predictions = []\n",
    "                \n",
    "                for _, row in val_data.iterrows():\n",
    "                    text = row['text']\n",
    "                    \n",
    "                    inputs = tokenizer(\n",
    "                        text,\n",
    "                        return_tensors=\"pt\",\n",
    "                        truncation=True,\n",
    "                        padding=True,\n",
    "                        max_length=512\n",
    "                    ).to(device)\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        outputs = model(**inputs)\n",
    "                        probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "                        fold_predictions.append(probabilities.cpu().numpy()[0])\n",
    "                \n",
    "                start_col = model_idx * 24\n",
    "                end_col = (model_idx + 1) * 24\n",
    "                meta_features[val_idx, start_col:end_col] = np.array(fold_predictions)\n",
    "        \n",
    "        return meta_features\n",
    "    \n",
    "    def train_meta_model(self, meta_features, labels):\n",
    "        \"\"\"메타 모델 학습\"\"\"\n",
    "        print(\"\\n🎯 메타 모델 학습 중...\")\n",
    "        \n",
    "        self.meta_model = lgb.LGBMClassifier(\n",
    "            objective='multiclass',\n",
    "            num_class=24,\n",
    "            boosting_type='gbdt',\n",
    "            num_leaves=31,\n",
    "            learning_rate=0.05,\n",
    "            feature_fraction=0.9,\n",
    "            bagging_fraction=0.8,\n",
    "            bagging_freq=5,\n",
    "            verbose=0,\n",
    "            random_state=self.random_state\n",
    "        )\n",
    "        \n",
    "        self.meta_model.fit(meta_features, labels)\n",
    "        print(\"✅ 메타 모델 학습 완료!\")\n",
    "        \n",
    "        return self.meta_model\n",
    "    \n",
    "    def fit(self, train_data, valid_data, device):\n",
    "        \"\"\"전체 스택킹 앙상블 학습\"\"\"\n",
    "        print(\"🚀 Listwise Loss 기반 Stacking 앙상블 학습 시작!\")\n",
    "        \n",
    "        train_df = pd.DataFrame(train_data)\n",
    "        valid_df = pd.DataFrame(valid_data)\n",
    "        \n",
    "        train_dataset = Dataset.from_pandas(train_df)\n",
    "        valid_dataset = Dataset.from_pandas(valid_df)\n",
    "        \n",
    "        # 1단계: Listwise Loss 베이스 모델들 학습\n",
    "        print(\"\\n📚 1단계: Listwise Loss 베이스 모델들 학습\")\n",
    "        for config in self.base_model_configs:\n",
    "            tokenizer = AutoTokenizer.from_pretrained(\n",
    "                config['model_name'],\n",
    "                cache_dir='C:/huggingface_cache'\n",
    "            )\n",
    "            print(f\"✅ {config['name']} 토크나이저 로드 완료\")\n",
    "            \n",
    "            def tokenize_function(examples):\n",
    "                return tokenizer(\n",
    "                    examples[\"text\"],\n",
    "                    truncation=True,\n",
    "                    padding=True,\n",
    "                    max_length=512\n",
    "                )\n",
    "            \n",
    "            current_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "            current_valid_dataset = valid_dataset.map(tokenize_function, batched=True)\n",
    "            \n",
    "            current_train_dataset = current_train_dataset.remove_columns([\"text\", \"original_sentences\", \"answer\"])\n",
    "            current_valid_dataset = current_valid_dataset.remove_columns([\"text\", \"original_sentences\", \"answer\"])\n",
    "            \n",
    "            model_info = self.train_base_model(config, current_train_dataset, current_valid_dataset, tokenizer, device)\n",
    "            self.base_models.append(model_info)\n",
    "        \n",
    "        # 📊 베이스 모델 성능 요약\n",
    "        print(\"\\n📈 Listwise Loss 베이스 모델 성능 요약:\")\n",
    "        total_accuracy = 0\n",
    "        for model_info in self.base_models:\n",
    "            accuracy = model_info['final_accuracy']\n",
    "            total_accuracy += accuracy\n",
    "            print(f\"  {model_info['config']['name']}: {accuracy:.4f}\")\n",
    "        avg_accuracy = total_accuracy / len(self.base_models)\n",
    "        print(f\"  평균 정확도: {avg_accuracy:.4f}\")\n",
    "        \n",
    "        # 2단계: 메타 특성 생성\n",
    "        print(\"\\n🔧 2단계: 메타 특성 생성\")\n",
    "        meta_features = self.generate_meta_features(self.base_models, train_data, device)\n",
    "        labels = [item['label'] for item in train_data]\n",
    "        \n",
    "        # 3단계: 메타 모델 학습\n",
    "        print(\"\\n🎓 3단계: 메타 모델 학습\")\n",
    "        self.train_meta_model(meta_features, labels)\n",
    "        \n",
    "        print(\"\\n🎉 Listwise Loss 기반 Stacking 앙상블 학습 완료!\")\n",
    "        print(f\"🏆 예상 앙상블 성능: {avg_accuracy + 0.08:.4f} (Listwise 효과 + 메타 모델)\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, test_data, device):\n",
    "        \"\"\"스택킹 앙상블 예측\"\"\"\n",
    "        print(\"\\n🔮 Listwise Loss 기반 앙상블 예측 중...\")\n",
    "        \n",
    "        test_meta_features = []\n",
    "        \n",
    "        for model_info in self.base_models:\n",
    "            model = model_info['model']\n",
    "            model.eval()\n",
    "            \n",
    "            tokenizer = AutoTokenizer.from_pretrained(\n",
    "                model_info['config']['model_name'],\n",
    "                cache_dir='C:/huggingface_cache'\n",
    "            )\n",
    "            \n",
    "            model_predictions = []\n",
    "            model_name = model_info['config']['name']\n",
    "            \n",
    "            for text in tqdm(test_data, desc=f\"{model_name} 예측\"):\n",
    "                inputs = tokenizer(\n",
    "                    text,\n",
    "                    return_tensors=\"pt\",\n",
    "                    truncation=True,\n",
    "                    padding=True,\n",
    "                    max_length=512\n",
    "                ).to(device)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    outputs = model(**inputs)\n",
    "                    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "                    model_predictions.append(probabilities.cpu().numpy()[0])\n",
    "            \n",
    "            test_meta_features.append(np.array(model_predictions))\n",
    "        \n",
    "        final_meta_features = np.hstack(test_meta_features)\n",
    "        final_predictions = self.meta_model.predict(final_meta_features)\n",
    "        final_probabilities = self.meta_model.predict_proba(final_meta_features)\n",
    "        \n",
    "        print(\"✅ Listwise Loss 기반 예측 완료!\")\n",
    "        \n",
    "        return final_predictions, final_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce16b92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "디바이스 설정 중...\n",
      "디바이스: cuda\n",
      "GPU 메모리: 0.00GB 사용 / 8.00GB 전체 (0.0% 사용)\n"
     ]
    }
   ],
   "source": [
    "print(\"디바이스 설정 중...\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"디바이스: {device}\")\n",
    "\n",
    "# GPU 메모리 사용량 체크 함수\n",
    "def print_gpu_utilization():\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "        total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "        usage_percent = (allocated / total) * 100\n",
    "        print(f\"GPU 메모리: {allocated:.2f}GB 사용 / {total:.2f}GB 전체 ({usage_percent:.1f}% 사용)\")\n",
    "    else:\n",
    "        print(\"CUDA 사용 불가\")\n",
    "\n",
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efbbef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Listwise Loss 기반 Stacking 앙상블 학습 시작!\n",
      "\n",
      "📚 1단계: Listwise Loss 베이스 모델들 학습\n",
      "✅ electra_small_listwise 토크나이저 로드 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 23523/23523 [00:03<00:00, 7776.82 examples/s]\n",
      "Map: 100%|██████████| 5881/5881 [00:00<00:00, 6614.16 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔥 electra_small_listwise 모델 학습 시작 (Listwise Loss 적용)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-small-v3-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎓 electra_small_listwise Listwise 설정:\n",
      "   Learning Rate: 3e-05\n",
      "   Batch Size: 64\n",
      "   Epochs: 45\n",
      "   Loss Function: ListMLE (Listwise Ranking)\n",
      "   Early Stopping: 8 patience\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8280' max='8280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8280/8280 2:10:53, Epoch 45/45]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.178400</td>\n",
       "      <td>3.178081</td>\n",
       "      <td>0.046360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.146400</td>\n",
       "      <td>3.177083</td>\n",
       "      <td>0.044986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.089700</td>\n",
       "      <td>2.992770</td>\n",
       "      <td>0.138393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.666700</td>\n",
       "      <td>2.563617</td>\n",
       "      <td>0.187157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.391900</td>\n",
       "      <td>2.270684</td>\n",
       "      <td>0.207246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.122300</td>\n",
       "      <td>2.062250</td>\n",
       "      <td>0.220295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.012700</td>\n",
       "      <td>1.932511</td>\n",
       "      <td>0.290865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.887800</td>\n",
       "      <td>1.824717</td>\n",
       "      <td>0.343578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.804900</td>\n",
       "      <td>1.727361</td>\n",
       "      <td>0.383070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.675800</td>\n",
       "      <td>1.627850</td>\n",
       "      <td>0.385989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.577000</td>\n",
       "      <td>1.512388</td>\n",
       "      <td>0.427198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.456900</td>\n",
       "      <td>1.410342</td>\n",
       "      <td>0.441793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>1.364400</td>\n",
       "      <td>1.324603</td>\n",
       "      <td>0.490728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>1.281800</td>\n",
       "      <td>1.233156</td>\n",
       "      <td>0.513393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.205400</td>\n",
       "      <td>1.171319</td>\n",
       "      <td>0.535371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>1.135200</td>\n",
       "      <td>1.088777</td>\n",
       "      <td>0.571600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>1.066700</td>\n",
       "      <td>1.036431</td>\n",
       "      <td>0.583104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>1.026700</td>\n",
       "      <td>0.974549</td>\n",
       "      <td>0.606456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.955100</td>\n",
       "      <td>0.916506</td>\n",
       "      <td>0.618819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.911800</td>\n",
       "      <td>0.873367</td>\n",
       "      <td>0.645604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.855300</td>\n",
       "      <td>0.838904</td>\n",
       "      <td>0.643544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.829700</td>\n",
       "      <td>0.796354</td>\n",
       "      <td>0.677370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.778500</td>\n",
       "      <td>0.775139</td>\n",
       "      <td>0.683036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.748100</td>\n",
       "      <td>0.721617</td>\n",
       "      <td>0.700378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.727600</td>\n",
       "      <td>0.703878</td>\n",
       "      <td>0.709306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.684200</td>\n",
       "      <td>0.673841</td>\n",
       "      <td>0.728537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.660800</td>\n",
       "      <td>0.650665</td>\n",
       "      <td>0.761676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.619500</td>\n",
       "      <td>0.623138</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.610200</td>\n",
       "      <td>0.587321</td>\n",
       "      <td>0.774897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.559600</td>\n",
       "      <td>0.562589</td>\n",
       "      <td>0.783654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.554000</td>\n",
       "      <td>0.541602</td>\n",
       "      <td>0.804087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.516300</td>\n",
       "      <td>0.519186</td>\n",
       "      <td>0.815934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.502508</td>\n",
       "      <td>0.829155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.469500</td>\n",
       "      <td>0.474037</td>\n",
       "      <td>0.844437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.459800</td>\n",
       "      <td>0.450657</td>\n",
       "      <td>0.853022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.422300</td>\n",
       "      <td>0.432824</td>\n",
       "      <td>0.854224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.403200</td>\n",
       "      <td>0.423097</td>\n",
       "      <td>0.855254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.387800</td>\n",
       "      <td>0.388812</td>\n",
       "      <td>0.871051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.351900</td>\n",
       "      <td>0.378617</td>\n",
       "      <td>0.877404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.349700</td>\n",
       "      <td>0.354805</td>\n",
       "      <td>0.883757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.308900</td>\n",
       "      <td>0.336966</td>\n",
       "      <td>0.889423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.310600</td>\n",
       "      <td>0.321236</td>\n",
       "      <td>0.894746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.285000</td>\n",
       "      <td>0.310090</td>\n",
       "      <td>0.899210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.275400</td>\n",
       "      <td>0.295682</td>\n",
       "      <td>0.902988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.252200</td>\n",
       "      <td>0.275295</td>\n",
       "      <td>0.912431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.239900</td>\n",
       "      <td>0.281031</td>\n",
       "      <td>0.906937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.235300</td>\n",
       "      <td>0.269093</td>\n",
       "      <td>0.913633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.218200</td>\n",
       "      <td>0.248173</td>\n",
       "      <td>0.922734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.221900</td>\n",
       "      <td>0.239897</td>\n",
       "      <td>0.923764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.197500</td>\n",
       "      <td>0.234626</td>\n",
       "      <td>0.927026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>0.221972</td>\n",
       "      <td>0.928228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.167300</td>\n",
       "      <td>0.220085</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>0.176200</td>\n",
       "      <td>0.207261</td>\n",
       "      <td>0.934409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.163100</td>\n",
       "      <td>0.202100</td>\n",
       "      <td>0.938187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.153800</td>\n",
       "      <td>0.204523</td>\n",
       "      <td>0.936641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.136900</td>\n",
       "      <td>0.184832</td>\n",
       "      <td>0.940591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>0.140300</td>\n",
       "      <td>0.175772</td>\n",
       "      <td>0.947630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.136500</td>\n",
       "      <td>0.178354</td>\n",
       "      <td>0.946429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>0.124400</td>\n",
       "      <td>0.167018</td>\n",
       "      <td>0.949004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.132200</td>\n",
       "      <td>0.163232</td>\n",
       "      <td>0.949863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>0.131500</td>\n",
       "      <td>0.153730</td>\n",
       "      <td>0.952266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.113300</td>\n",
       "      <td>0.151548</td>\n",
       "      <td>0.953812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>0.103300</td>\n",
       "      <td>0.150330</td>\n",
       "      <td>0.953812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.106800</td>\n",
       "      <td>0.145688</td>\n",
       "      <td>0.955529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.107900</td>\n",
       "      <td>0.144888</td>\n",
       "      <td>0.956216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>0.099100</td>\n",
       "      <td>0.146744</td>\n",
       "      <td>0.955185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>0.097100</td>\n",
       "      <td>0.143325</td>\n",
       "      <td>0.957074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>0.100300</td>\n",
       "      <td>0.135274</td>\n",
       "      <td>0.959993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>0.087800</td>\n",
       "      <td>0.133799</td>\n",
       "      <td>0.958963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.081600</td>\n",
       "      <td>0.131810</td>\n",
       "      <td>0.958791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7100</td>\n",
       "      <td>0.087300</td>\n",
       "      <td>0.134504</td>\n",
       "      <td>0.958791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>0.090900</td>\n",
       "      <td>0.127624</td>\n",
       "      <td>0.962912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7300</td>\n",
       "      <td>0.084800</td>\n",
       "      <td>0.120596</td>\n",
       "      <td>0.963771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>0.085600</td>\n",
       "      <td>0.123737</td>\n",
       "      <td>0.961882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.082000</td>\n",
       "      <td>0.124308</td>\n",
       "      <td>0.963255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>0.086300</td>\n",
       "      <td>0.121841</td>\n",
       "      <td>0.962740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7700</td>\n",
       "      <td>0.082200</td>\n",
       "      <td>0.117255</td>\n",
       "      <td>0.964801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>0.076800</td>\n",
       "      <td>0.116645</td>\n",
       "      <td>0.964629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7900</td>\n",
       "      <td>0.074700</td>\n",
       "      <td>0.116974</td>\n",
       "      <td>0.964973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.075300</td>\n",
       "      <td>0.114729</td>\n",
       "      <td>0.965488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8100</td>\n",
       "      <td>0.076300</td>\n",
       "      <td>0.117357</td>\n",
       "      <td>0.964286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>0.080100</td>\n",
       "      <td>0.116618</td>\n",
       "      <td>0.965488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='91' max='91' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [91/91 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ electra_small_listwise 최종 성능 (Listwise):\n",
      "   Accuracy: 0.9651\n",
      "💾 electra_small_listwise 모델 저장 완료!\n",
      "✅ bert_base_listwise 토크나이저 로드 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 23523/23523 [00:03<00:00, 6952.68 examples/s]\n",
      "Map: 100%|██████████| 5881/5881 [00:00<00:00, 8712.27 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔥 bert_base_listwise 모델 학습 시작 (Listwise Loss 적용)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎓 bert_base_listwise Listwise 설정:\n",
      "   Learning Rate: 2e-05\n",
      "   Batch Size: 32\n",
      "   Epochs: 40\n",
      "   Loss Function: ListMLE (Listwise Ranking)\n",
      "   Early Stopping: 8 patience\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='201' max='14720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  201/14720 03:56 < 4:47:06, 0.84 it/s, Epoch 0.54/40]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.201000</td>\n",
       "      <td>3.179537</td>\n",
       "      <td>0.046188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Stacking 앙상블 생성 및 학습\n",
    "stacking_ensemble = AdvancedStackingEnsemble(n_folds=5, random_state=42)\n",
    "\n",
    "# 학습 실행 (tokenizer 파라미터 제거)\n",
    "stacking_ensemble.fit(train_data, valid_data, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bba2465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 구조 인식 투표 예측기 클래스 (기존 코드에 추가)\n",
    "# =============================================================================\n",
    "\n",
    "class StructureAwareVotingPredictor:\n",
    "    \"\"\"문장 순서 배열을 위한 구조 인식 투표 예측기\"\"\"\n",
    "    \n",
    "    def __init__(self, stacking_ensemble, label_to_perm, perm_to_label):\n",
    "        self.ensemble = stacking_ensemble\n",
    "        self.label_to_perm = label_to_perm\n",
    "        self.perm_to_label = perm_to_label\n",
    "        \n",
    "    def predict(self, test_texts, device):\n",
    "        \"\"\"구조 인식 투표 예측 실행\"\"\"\n",
    "        print(\"🎯 구조 인식 투표 예측 시작...\")\n",
    "        \n",
    "        # 각 베이스 모델별 예측 수집\n",
    "        all_model_predictions = []\n",
    "        all_model_probabilities = []\n",
    "        \n",
    "        for model_idx, model_info in enumerate(self.ensemble.base_models):\n",
    "            print(f\"  모델 {model_idx + 1}/{len(self.ensemble.base_models)} 예측 중...\")\n",
    "            \n",
    "            model = model_info['model']\n",
    "            model.eval()\n",
    "            \n",
    "            tokenizer = AutoTokenizer.from_pretrained(\n",
    "                model_info['config']['model_name'],\n",
    "                cache_dir='C:/huggingface_cache'\n",
    "            )\n",
    "            \n",
    "            model_predictions = []\n",
    "            model_probabilities = []\n",
    "            \n",
    "            for text in tqdm(test_texts, desc=f\"모델 {model_idx + 1}\"):\n",
    "                inputs = tokenizer(\n",
    "                    text,\n",
    "                    return_tensors=\"pt\",\n",
    "                    truncation=True,\n",
    "                    padding=True,\n",
    "                    max_length=512\n",
    "                ).to(device)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    outputs = model(**inputs)\n",
    "                    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "                    prob_array = probabilities.cpu().numpy()[0]\n",
    "                    \n",
    "                    model_predictions.append(np.argmax(prob_array))\n",
    "                    model_probabilities.append(prob_array)\n",
    "            \n",
    "            all_model_predictions.append(model_predictions)\n",
    "            all_model_probabilities.append(model_probabilities)\n",
    "        \n",
    "        # 구조 인식 투표 실행\n",
    "        print(\"  🧠 문장 쌍별 관계 분석 및 최적 순열 구성 중...\")\n",
    "        final_predictions = []\n",
    "        final_probabilities = []\n",
    "        \n",
    "        for i in tqdm(range(len(test_texts)), desc=\"구조 분석\"):\n",
    "            # 각 모델의 예측을 순열로 변환\n",
    "            model_permutations = []\n",
    "            model_confidences = []\n",
    "            \n",
    "            for model_idx in range(len(self.ensemble.base_models)):\n",
    "                pred_label = all_model_predictions[model_idx][i]\n",
    "                pred_perm = self.label_to_perm[pred_label]\n",
    "                confidence = np.max(all_model_probabilities[model_idx][i])\n",
    "                \n",
    "                model_permutations.append(pred_perm)\n",
    "                model_confidences.append(confidence)\n",
    "            \n",
    "            # 문장 쌍별 순서 관계 분석\n",
    "            pair_votes = {}\n",
    "            for pos1 in range(4):\n",
    "                for pos2 in range(4):\n",
    "                    if pos1 != pos2:\n",
    "                        pair_votes[(pos1, pos2)] = []\n",
    "            \n",
    "            # 각 모델의 순열에서 쌍별 관계 추출\n",
    "            for model_idx, perm in enumerate(model_permutations):\n",
    "                confidence = model_confidences[model_idx]\n",
    "                \n",
    "                for pos1 in range(4):\n",
    "                    for pos2 in range(4):\n",
    "                        if pos1 != pos2:\n",
    "                            # perm[pos1]이 perm[pos2]보다 먼저 나와야 하는지 확인\n",
    "                            sent1_order = perm[pos1]\n",
    "                            sent2_order = perm[pos2]\n",
    "                            \n",
    "                            if sent1_order < sent2_order:\n",
    "                                # 문장 pos1이 문장 pos2보다 먼저\n",
    "                                pair_votes[(pos1, pos2)].append(confidence)\n",
    "                            else:\n",
    "                                # 문장 pos2가 문장 pos1보다 먼저\n",
    "                                pair_votes[(pos2, pos1)].append(confidence)\n",
    "            \n",
    "            # 쌍별 투표 결과로 최적 순열 구성\n",
    "            best_permutation = self._construct_optimal_permutation(pair_votes)\n",
    "            \n",
    "            # 최적 순열을 라벨로 변환\n",
    "            if best_permutation in self.perm_to_label:\n",
    "                final_label = self.perm_to_label[best_permutation]\n",
    "            else:\n",
    "                # 백업: 가장 높은 신뢰도의 모델 선택\n",
    "                best_model_idx = np.argmax(model_confidences)\n",
    "                final_label = all_model_predictions[best_model_idx][i]\n",
    "            \n",
    "            final_predictions.append(final_label)\n",
    "            \n",
    "            # 확률은 해당 순열에 대한 모든 모델의 평균 확률\n",
    "            avg_probs = np.mean([all_model_probabilities[j][i] for j in range(len(self.ensemble.base_models))], axis=0)\n",
    "            final_probabilities.append(avg_probs)\n",
    "        \n",
    "        final_predictions = np.array(final_predictions)\n",
    "        final_probabilities = np.array(final_probabilities)\n",
    "        \n",
    "        print(\"✅ 구조 인식 투표 예측 완료!\")\n",
    "        return final_predictions, final_probabilities\n",
    "    \n",
    "    def _construct_optimal_permutation(self, pair_votes):\n",
    "        \"\"\"쌍별 투표 결과로부터 최적 순열 구성\"\"\"\n",
    "        # 각 쌍에 대한 투표 강도 계산\n",
    "        pair_strengths = {}\n",
    "        for pair, votes in pair_votes.items():\n",
    "            if votes:\n",
    "                pair_strengths[pair] = sum(votes) / len(votes)\n",
    "            else:\n",
    "                pair_strengths[pair] = 0\n",
    "        \n",
    "        # 토너먼트 방식으로 순서 결정\n",
    "        sentences = list(range(4))\n",
    "        sentence_scores = {i: 0 for i in range(4)}\n",
    "        \n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                if i != j:\n",
    "                    if pair_strengths.get((i, j), 0) > pair_strengths.get((j, i), 0):\n",
    "                        sentence_scores[i] += pair_strengths.get((i, j), 0)\n",
    "                    else:\n",
    "                        sentence_scores[j] += pair_strengths.get((j, i), 0)\n",
    "        \n",
    "        # 점수 순으로 정렬하여 순열 생성\n",
    "        sorted_sentences = sorted(sentences, key=lambda x: sentence_scores[x], reverse=True)\n",
    "        \n",
    "        # 순열을 올바른 형태로 변환 (어떤 문장이 몇 번째 위치에 있는지)\n",
    "        permutation = [0] * 4\n",
    "        for position, sentence_idx in enumerate(sorted_sentences):\n",
    "            permutation[sentence_idx] = position\n",
    "        \n",
    "        return tuple(permutation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d4a0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터 예측 중...\n",
      "테스트 데이터: 1780개\n",
      "🎯 구조 인식 투표 예측 시작...\n",
      "  모델 1/3 예측 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "모델 1: 100%|██████████| 1780/1780 [00:22<00:00, 79.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  모델 2/3 예측 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "모델 2: 100%|██████████| 1780/1780 [00:12<00:00, 144.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  모델 3/3 예측 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "모델 3: 100%|██████████| 1780/1780 [00:23<00:00, 74.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  🧠 문장 쌍별 관계 분석 및 최적 순열 구성 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "구조 분석: 100%|██████████| 1780/1780 [00:00<00:00, 12999.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 구조 인식 투표 예측 완료!\n",
      "\n",
      "평균 예측 신뢰도: 0.6991\n",
      "\n",
      "🎯 구조 인식 투표 분석:\n",
      "   - 문장 쌍별 관계 기반 예측\n",
      "   - 베이스 모델 수: 3개\n",
      "   - 신뢰도 가중 투표 적용\n",
      "   - 순열 일관성 검증 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 수정된 예측 셀 코드 (기존 셀 8번 대체)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"테스트 데이터 예측 중...\")\n",
    "\n",
    "# 테스트 데이터 로드\n",
    "test_df = pd.read_csv(\"./test.csv\")\n",
    "print(f\"테스트 데이터: {len(test_df)}개\")\n",
    "\n",
    "# 테스트 데이터 전처리\n",
    "test_texts = []\n",
    "for _, row in test_df.iterrows():\n",
    "    sentences = [row[f\"sentence_{i}\"] for i in range(4)]\n",
    "    text = \" [SEP] \".join(sentences)\n",
    "    test_texts.append(text)\n",
    "\n",
    "# 구조 인식 투표 예측기 생성\n",
    "structure_predictor = StructureAwareVotingPredictor(\n",
    "    stacking_ensemble, label_to_perm, perm_to_label\n",
    ")\n",
    "\n",
    "# 구조 인식 투표로 예측 실행\n",
    "final_predictions, final_probabilities = structure_predictor.predict(test_texts, device)\n",
    "\n",
    "# 예측 결과를 순열로 변환\n",
    "predicted_orders = []\n",
    "confidences = []\n",
    "\n",
    "for i, pred_label in enumerate(final_predictions):\n",
    "    predicted_order = list(label_to_perm[pred_label])\n",
    "    confidence = np.max(final_probabilities[i])\n",
    "    \n",
    "    predicted_orders.append(predicted_order)\n",
    "    confidences.append(confidence)\n",
    "\n",
    "# 평균 신뢰도 출력\n",
    "avg_confidence = np.mean(confidences)\n",
    "print(f\"\\n평균 예측 신뢰도: {avg_confidence:.4f}\")\n",
    "\n",
    "# 구조 인식 투표의 효과 분석\n",
    "print(f\"\\n🎯 구조 인식 투표 분석:\")\n",
    "print(f\"   - 문장 쌍별 관계 기반 예측\")\n",
    "print(f\"   - 베이스 모델 수: {len(stacking_ensemble.base_models)}개\")\n",
    "print(f\"   - 신뢰도 가중 투표 적용\")\n",
    "print(f\"   - 순열 일관성 검증 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e891b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission 파일 생성 중...\n",
      "제출 파일 저장 완료: stacking_ensemble_submission.csv\n",
      "\n",
      "============================================================\n",
      "🏆 고급 Stacking 앙상블 완료!\n",
      "📊 베이스 모델 수: 3개\n",
      "🎯 메타 모델: LightGBM\n",
      "🔮 평균 예측 신뢰도: 69.91%\n",
      "📁 제출 파일: stacking_ensemble_submission.csv\n",
      "============================================================\n",
      "\n",
      "개별 베이스 모델 정보:\n",
      "  모델 1: bert_small (LR: 1.5e-05, Epochs: 25)\n",
      "  모델 2: roberta_small (LR: 2e-05, Epochs: 20)\n",
      "  모델 3: electra_small (LR: 3e-05, Epochs: 15)\n"
     ]
    }
   ],
   "source": [
    "print(\"Submission 파일 생성 중...\")\n",
    "\n",
    "# 샘플 제출 파일 로드\n",
    "sample_submission = pd.read_csv(\"./sample_submission.csv\")\n",
    "\n",
    "# 예측 결과를 제출 형식으로 변환\n",
    "for i in range(4):\n",
    "    sample_submission[f\"answer_{i}\"] = [pred[i] for pred in predicted_orders]\n",
    "\n",
    "# 파일 저장\n",
    "submission_filename = \"stacking_ensemble_submission.csv\"\n",
    "sample_submission.to_csv(submission_filename, index=False)\n",
    "\n",
    "print(f\"제출 파일 저장 완료: {submission_filename}\")\n",
    "\n",
    "# 최종 결과 요약\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(f\"🏆 고급 Stacking 앙상블 완료!\")\n",
    "print(f\"📊 베이스 모델 수: {len(stacking_ensemble.base_models)}개\")\n",
    "print(f\"🎯 메타 모델: LightGBM\")\n",
    "print(f\"🔮 평균 예측 신뢰도: {avg_confidence*100:.2f}%\")\n",
    "print(f\"📁 제출 파일: {submission_filename}\")\n",
    "print(f\"=\"*60)\n",
    "\n",
    "# 개별 모델 성능도 확인해보기\n",
    "print(f\"\\n개별 베이스 모델 정보:\")\n",
    "for i, model_info in enumerate(stacking_ensemble.base_models):\n",
    "    config = model_info['config']\n",
    "    print(f\"  모델 {i+1}: {config['name']} (LR: {config['learning_rate']}, Epochs: {config['epochs']})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daycon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
