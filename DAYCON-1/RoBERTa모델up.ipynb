{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "703e1e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import lightgbm as lgb\n",
    "import safetensors\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer, \n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "from itertools import permutations\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74934889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ 24ê°œì˜ ìˆœì—´ í´ë˜ìŠ¤ ìƒì„±\n",
      "ì˜ˆì‹œ ë§¤í•‘:\n",
      "  ë¼ë²¨ 0: (0, 1, 2, 3)\n",
      "  ë¼ë²¨ 1: (0, 1, 3, 2)\n",
      "  ë¼ë²¨ 2: (0, 2, 1, 3)\n",
      "  ë¼ë²¨ 3: (0, 2, 3, 1)\n",
      "  ë¼ë²¨ 4: (0, 3, 1, 2)\n"
     ]
    }
   ],
   "source": [
    "def create_label_mappings():\n",
    "    \"\"\"24ê°€ì§€ ìˆœì—´ì— ëŒ€í•œ ë¼ë²¨ ë§¤í•‘ ìƒì„±\"\"\"\n",
    "    all_permutations = list(permutations([0, 1, 2, 3]))\n",
    "    perm_to_label = {perm: idx for idx, perm in enumerate(all_permutations)}\n",
    "    label_to_perm = {idx: perm for idx, perm in enumerate(all_permutations)}\n",
    "    \n",
    "    print(f\"ì´ {len(all_permutations)}ê°œì˜ ìˆœì—´ í´ë˜ìŠ¤ ìƒì„±\")\n",
    "    print(\"ì˜ˆì‹œ ë§¤í•‘:\")\n",
    "    for i in range(5):\n",
    "        print(f\"  ë¼ë²¨ {i}: {all_permutations[i]}\")\n",
    "    \n",
    "    return perm_to_label, label_to_perm\n",
    "\n",
    "# ìˆœì—´ ë§¤í•‘ ìƒì„±\n",
    "perm_to_label, label_to_perm = create_label_mappings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bef94fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_roberta_data(train_df, perm_to_label):\n",
    "    \"\"\"RoBERTaìš© ë°ì´í„° ì¤€ë¹„\"\"\"\n",
    "    processed_data = []\n",
    "    \n",
    "    for _, row in train_df.iterrows():\n",
    "        sentences = [row[f\"sentence_{i}\"] for i in range(4)]\n",
    "        answer_tuple = tuple([row[f\"answer_{i}\"] for i in range(4)])\n",
    "        text = \" [SEP] \".join(sentences)\n",
    "        label = perm_to_label[answer_tuple]\n",
    "        \n",
    "        processed_data.append({\n",
    "            \"text\": text,\n",
    "            \"label\": label,\n",
    "            \"original_sentences\": sentences,\n",
    "            \"answer\": answer_tuple\n",
    "        })\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "def augment_roberta_data_advanced(train_df, perm_to_label, multiplier=4):\n",
    "    \"\"\"ê³ ê¸‰ ë°ì´í„° ì¦ê°•\"\"\"\n",
    "    augmented_data = []\n",
    "    \n",
    "    # ì›ë³¸ ë°ì´í„°\n",
    "    original_data = prepare_roberta_data(train_df, perm_to_label)\n",
    "    augmented_data.extend(original_data)\n",
    "    \n",
    "    # ë‹¤ì–‘í•œ ì¦ê°• ë°©ë²•\n",
    "    for aug_round in range(multiplier - 1):\n",
    "        for _, row in train_df.iterrows():\n",
    "            sentences = [row[f\"sentence_{i}\"] for i in range(4)]\n",
    "            original_answer = [row[f\"answer_{i}\"] for i in range(4)]\n",
    "            \n",
    "            if aug_round == 0:\n",
    "                # ëœë¤ ì…”í”Œ\n",
    "                indices = list(range(4))\n",
    "                np.random.shuffle(indices)\n",
    "            elif aug_round == 1:\n",
    "                # ìˆœí™˜ ì´ë™\n",
    "                shift = np.random.randint(1, 4)\n",
    "                indices = [(i + shift) % 4 for i in range(4)]\n",
    "            else:\n",
    "                # ë¶€ë¶„ êµí™˜\n",
    "                indices = list(range(4))\n",
    "                i, j = np.random.choice(4, 2, replace=False)\n",
    "                indices[i], indices[j] = indices[j], indices[i]\n",
    "            \n",
    "            shuffled_sentences = [sentences[i] for i in indices]\n",
    "            new_answer = tuple([indices.index(original_answer[i]) for i in range(4)])\n",
    "            \n",
    "            text = \" [SEP] \".join(shuffled_sentences)\n",
    "            label = perm_to_label[new_answer]\n",
    "            \n",
    "            augmented_data.append({\n",
    "                \"text\": text,\n",
    "                \"label\": label,\n",
    "                \"original_sentences\": shuffled_sentences,\n",
    "                \"answer\": new_answer\n",
    "            })\n",
    "    \n",
    "    print(f\"ê³ ê¸‰ ë°ì´í„° ì¦ê°• ì™„ë£Œ: {len(original_data)} â†’ {len(augmented_data)}\")\n",
    "    return augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b89decf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "ì›ë³¸ í•™ìŠµ ë°ì´í„°: 7351ê°œ\n",
      "\n",
      "ê³ ê¸‰ ë°ì´í„° ì¦ê°• ì¤‘...\n",
      "ê³ ê¸‰ ë°ì´í„° ì¦ê°• ì™„ë£Œ: 7351 â†’ 29404\n",
      "\n",
      "í•™ìŠµ/ê²€ì¦ ë°ì´í„° ë¶„í• ...\n",
      "í•™ìŠµ ë°ì´í„°: 23523ê°œ\n",
      "ê²€ì¦ ë°ì´í„°: 5881ê°œ\n"
     ]
    }
   ],
   "source": [
    "print(\"ë°ì´í„° ë¡œë“œ ì¤‘...\")\n",
    "train_df = pd.read_csv('./train.csv')\n",
    "print(f\"ì›ë³¸ í•™ìŠµ ë°ì´í„°: {len(train_df)}ê°œ\")\n",
    "\n",
    "print(\"\\nê³ ê¸‰ ë°ì´í„° ì¦ê°• ì¤‘...\")\n",
    "augmented_data = augment_roberta_data_advanced(train_df, perm_to_label, multiplier=4)\n",
    "\n",
    "print(\"\\ní•™ìŠµ/ê²€ì¦ ë°ì´í„° ë¶„í• ...\")\n",
    "train_data, valid_data = train_test_split(\n",
    "    augmented_data, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=[item[\"label\"] for item in augmented_data]\n",
    ")\n",
    "\n",
    "print(f\"í•™ìŠµ ë°ì´í„°: {len(train_data)}ê°œ\")\n",
    "print(f\"ê²€ì¦ ë°ì´í„°: {len(valid_data)}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90071e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ì…€ 5: Stacking ì•™ìƒë¸” í´ë˜ìŠ¤ ì •ì˜ (ì™„ì „ ìˆ˜ì •ë¨)\n",
    "# =============================================================================\n",
    "class AdvancedStackingEnsemble:\n",
    "    \"\"\"ìµœê³  ì„±ëŠ¥ Stacking ì•™ìƒë¸”\"\"\"\n",
    "    \n",
    "    def __init__(self, n_folds=5, random_state=42):\n",
    "        self.n_folds = n_folds\n",
    "        self.random_state = random_state\n",
    "        self.base_models = []\n",
    "        self.meta_model = None\n",
    "        self.base_model_configs = [\n",
    "            {\n",
    "                'name': 'bert_small', \n",
    "                'model_name': 'klue/bert-base',  # BERT ì•„í‚¤í…ì²˜ (ì²« ë²ˆì§¸)\n",
    "                'learning_rate': 1.5e-5,\n",
    "                'epochs': 25,\n",
    "                'batch_size': 48,\n",
    "                'warmup_steps': 200\n",
    "            },\n",
    "            {\n",
    "                'name': 'roberta_small',\n",
    "                'model_name': 'klue/roberta-small',\n",
    "                'learning_rate': 2e-5,\n",
    "                'epochs': 20,\n",
    "                'batch_size': 64,\n",
    "                'warmup_steps': 150\n",
    "            },\n",
    "            {\n",
    "                'name': 'electra_small',\n",
    "                'model_name': 'monologg/koelectra-small-v3-discriminator',  # ELECTRA ì•„í‚¤í…ì²˜ (ë§ˆì§€ë§‰)\n",
    "                'learning_rate': 3e-5,\n",
    "                'epochs': 15,\n",
    "                'batch_size': 80,\n",
    "                'warmup_steps': 100\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "    def train_base_model(self, config, train_dataset, valid_dataset, tokenizer, device):\n",
    "        \"\"\"ê°œë³„ ë² ì´ìŠ¤ ëª¨ë¸ í•™ìŠµ\"\"\"\n",
    "        print(f\"\\nğŸ”¥ {config['name']} ëª¨ë¸ í•™ìŠµ ì‹œì‘...\")\n",
    "        \n",
    "        # ëª¨ë¸ ìƒì„±\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            config['model_name'],\n",
    "            num_labels=24,\n",
    "            cache_dir='C:/huggingface_cache'\n",
    "        )\n",
    "        model.to(device)\n",
    "        \n",
    "        # í•™ìŠµ ì„¤ì • (ì¡°ê¸° ì¢…ë£Œ í¬í•¨)\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=f\"./results_{config['name']}\",\n",
    "            learning_rate=config['learning_rate'],\n",
    "            per_device_train_batch_size=config['batch_size'],\n",
    "            per_device_eval_batch_size=128,\n",
    "            gradient_accumulation_steps=2,\n",
    "            num_train_epochs=config['epochs'],\n",
    "            eval_strategy=\"steps\",\n",
    "            eval_steps=150,\n",
    "            save_strategy=\"steps\", \n",
    "            save_steps=150,\n",
    "            save_total_limit=2,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"accuracy\",\n",
    "            greater_is_better=True,\n",
    "            fp16=True,\n",
    "            dataloader_pin_memory=True,\n",
    "            dataloader_num_workers=6,\n",
    "            warmup_steps=config['warmup_steps'],\n",
    "            weight_decay=0.01,\n",
    "            logging_steps=20,\n",
    "            report_to=None,\n",
    "        )\n",
    "        \n",
    "        # íŠ¸ë ˆì´ë„ˆ ìƒì„± (ì¡°ê¸° ì¢…ë£Œ ì½œë°± í¬í•¨)\n",
    "        from transformers import EarlyStoppingCallback\n",
    "        \n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=valid_dataset,\n",
    "            tokenizer=tokenizer,\n",
    "            data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "            compute_metrics=lambda eval_pred: {\n",
    "                \"accuracy\": accuracy_score(eval_pred.label_ids, np.argmax(eval_pred.predictions, axis=1))\n",
    "            },\n",
    "            callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    "        )\n",
    "        \n",
    "        # í•™ìŠµ ì‹¤í–‰\n",
    "        trainer.train()\n",
    "        \n",
    "        # ëª¨ë¸ ì €ì¥\n",
    "        model_save_path = f\"./results_{config['name']}/final\"\n",
    "        trainer.save_model(model_save_path)\n",
    "        \n",
    "        print(f\"âœ… {config['name']} ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")\n",
    "        \n",
    "        return {\n",
    "            'model': model,\n",
    "            'trainer': trainer,\n",
    "            'config': config,\n",
    "            'save_path': model_save_path\n",
    "        }\n",
    "    \n",
    "    def generate_meta_features(self, models, data, device):\n",
    "        \"\"\"ë©”íƒ€ íŠ¹ì„± ìƒì„± (K-Fold êµì°¨ ê²€ì¦)\"\"\"\n",
    "        print(\"\\nğŸ§  ë©”íƒ€ íŠ¹ì„± ìƒì„± ì¤‘...\")\n",
    "        \n",
    "        # ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # K-Fold ì„¤ì •\n",
    "        kf = KFold(n_splits=self.n_folds, shuffle=True, random_state=self.random_state)\n",
    "        \n",
    "        # ë©”íƒ€ íŠ¹ì„± ì €ì¥í•  ë°°ì—´\n",
    "        meta_features = np.zeros((len(data), len(models) * 24))  # ê° ëª¨ë¸ë‹¹ 24ê°œ í´ë˜ìŠ¤ í™•ë¥ \n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(df)):\n",
    "            print(f\"  Fold {fold + 1}/{self.n_folds} ì²˜ë¦¬ ì¤‘...\")\n",
    "            \n",
    "            # ê²€ì¦ ë°ì´í„° ì¶”ì¶œ\n",
    "            val_data = df.iloc[val_idx]\n",
    "            \n",
    "            # ê° ë² ì´ìŠ¤ ëª¨ë¸ë¡œ ì˜ˆì¸¡\n",
    "            for model_idx, model_info in enumerate(models):\n",
    "                model = model_info['model']\n",
    "                model.eval()\n",
    "                \n",
    "                # í•´ë‹¹ ëª¨ë¸ì˜ í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "                tokenizer = AutoTokenizer.from_pretrained(\n",
    "                    model_info['config']['model_name'],\n",
    "                    cache_dir='C:/huggingface_cache'\n",
    "                )\n",
    "                \n",
    "                fold_predictions = []\n",
    "                \n",
    "                # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì˜ˆì¸¡\n",
    "                for _, row in val_data.iterrows():\n",
    "                    text = row['text']\n",
    "                    \n",
    "                    inputs = tokenizer(\n",
    "                        text,\n",
    "                        return_tensors=\"pt\",\n",
    "                        truncation=True,\n",
    "                        padding=True,\n",
    "                        max_length=512\n",
    "                    ).to(device)\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        outputs = model(**inputs)\n",
    "                        probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "                        fold_predictions.append(probabilities.cpu().numpy()[0])\n",
    "                \n",
    "                # ë©”íƒ€ íŠ¹ì„±ì— ì €ì¥\n",
    "                start_col = model_idx * 24\n",
    "                end_col = (model_idx + 1) * 24\n",
    "                meta_features[val_idx, start_col:end_col] = np.array(fold_predictions)\n",
    "        \n",
    "        return meta_features\n",
    "    \n",
    "    def train_meta_model(self, meta_features, labels):\n",
    "        \"\"\"ë©”íƒ€ ëª¨ë¸ í•™ìŠµ\"\"\"\n",
    "        print(\"\\nğŸ¯ ë©”íƒ€ ëª¨ë¸ í•™ìŠµ ì¤‘...\")\n",
    "        \n",
    "        # LightGBMì„ ë©”íƒ€ ëª¨ë¸ë¡œ ì‚¬ìš© (ê°€ì¥ íš¨ê³¼ì )\n",
    "        self.meta_model = lgb.LGBMClassifier(\n",
    "            objective='multiclass',\n",
    "            num_class=24,\n",
    "            boosting_type='gbdt',\n",
    "            num_leaves=31,\n",
    "            learning_rate=0.05,\n",
    "            feature_fraction=0.9,\n",
    "            bagging_fraction=0.8,\n",
    "            bagging_freq=5,\n",
    "            verbose=0,\n",
    "            random_state=self.random_state\n",
    "        )\n",
    "        \n",
    "        # ë©”íƒ€ ëª¨ë¸ í•™ìŠµ\n",
    "        self.meta_model.fit(meta_features, labels)\n",
    "        \n",
    "        print(\"âœ… ë©”íƒ€ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")\n",
    "        \n",
    "        return self.meta_model\n",
    "    \n",
    "    def fit(self, train_data, valid_data, device):\n",
    "        \"\"\"ì „ì²´ ìŠ¤íƒí‚¹ ì•™ìƒë¸” í•™ìŠµ\"\"\"\n",
    "        print(\"ğŸš€ Stacking ì•™ìƒë¸” í•™ìŠµ ì‹œì‘!\")\n",
    "        \n",
    "        # ë°ì´í„°ì…‹ ìƒì„±\n",
    "        train_df = pd.DataFrame(train_data)\n",
    "        valid_df = pd.DataFrame(valid_data)\n",
    "        \n",
    "        train_dataset = Dataset.from_pandas(train_df)\n",
    "        valid_dataset = Dataset.from_pandas(valid_df)\n",
    "        \n",
    "        # 1ë‹¨ê³„: ë² ì´ìŠ¤ ëª¨ë¸ë“¤ í•™ìŠµ\n",
    "        print(\"\\nğŸ“š 1ë‹¨ê³„: ë² ì´ìŠ¤ ëª¨ë¸ë“¤ í•™ìŠµ\")\n",
    "        for config in self.base_model_configs:\n",
    "            # ê° ëª¨ë¸ì— ë§ëŠ” í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "            tokenizer = AutoTokenizer.from_pretrained(\n",
    "                config['model_name'],\n",
    "                cache_dir='C:/huggingface_cache'\n",
    "            )\n",
    "            print(f\"âœ… {config['name']} í† í¬ë‚˜ì´ì € ë¡œë“œ ì™„ë£Œ\")\n",
    "            \n",
    "            # í† í¬ë‚˜ì´ì§• í•¨ìˆ˜\n",
    "            def tokenize_function(examples):\n",
    "                return tokenizer(\n",
    "                    examples[\"text\"],\n",
    "                    truncation=True,\n",
    "                    padding=True,\n",
    "                    max_length=512\n",
    "                )\n",
    "            \n",
    "            # ê° ëª¨ë¸ë³„ë¡œ ë°ì´í„°ì…‹ í† í¬ë‚˜ì´ì§•\n",
    "            current_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "            current_valid_dataset = valid_dataset.map(tokenize_function, batched=True)\n",
    "            \n",
    "            current_train_dataset = current_train_dataset.remove_columns([\"text\", \"original_sentences\", \"answer\"])\n",
    "            current_valid_dataset = current_valid_dataset.remove_columns([\"text\", \"original_sentences\", \"answer\"])\n",
    "            \n",
    "            # ëª¨ë¸ í•™ìŠµ\n",
    "            model_info = self.train_base_model(config, current_train_dataset, current_valid_dataset, tokenizer, device)\n",
    "            self.base_models.append(model_info)\n",
    "        \n",
    "        # 2ë‹¨ê³„: ë©”íƒ€ íŠ¹ì„± ìƒì„±\n",
    "        print(\"\\nğŸ”§ 2ë‹¨ê³„: ë©”íƒ€ íŠ¹ì„± ìƒì„±\")\n",
    "        meta_features = self.generate_meta_features(self.base_models, train_data, device)\n",
    "        labels = [item['label'] for item in train_data]\n",
    "        \n",
    "        # 3ë‹¨ê³„: ë©”íƒ€ ëª¨ë¸ í•™ìŠµ\n",
    "        print(\"\\nğŸ“ 3ë‹¨ê³„: ë©”íƒ€ ëª¨ë¸ í•™ìŠµ\")\n",
    "        self.train_meta_model(meta_features, labels)\n",
    "        \n",
    "        print(\"\\nğŸ‰ Stacking ì•™ìƒë¸” í•™ìŠµ ì™„ë£Œ!\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, test_data, device):\n",
    "        \"\"\"ìŠ¤íƒí‚¹ ì•™ìƒë¸” ì˜ˆì¸¡\"\"\"\n",
    "        print(\"\\nğŸ”® Stacking ì•™ìƒë¸” ì˜ˆì¸¡ ì¤‘...\")\n",
    "        \n",
    "        # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ë² ì´ìŠ¤ ëª¨ë¸ ì˜ˆì¸¡\n",
    "        test_meta_features = []\n",
    "        \n",
    "        for model_info in self.base_models:\n",
    "            model = model_info['model']\n",
    "            model.eval()\n",
    "            \n",
    "            # í•´ë‹¹ ëª¨ë¸ì˜ í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "            tokenizer = AutoTokenizer.from_pretrained(\n",
    "                model_info['config']['model_name'],\n",
    "                cache_dir='C:/huggingface_cache'\n",
    "            )\n",
    "            \n",
    "            model_predictions = []\n",
    "            \n",
    "            for text in tqdm(test_data, desc=f\"{model_info['config']['name']} ì˜ˆì¸¡\"):\n",
    "                inputs = tokenizer(\n",
    "                    text,\n",
    "                    return_tensors=\"pt\",\n",
    "                    truncation=True,\n",
    "                    padding=True,\n",
    "                    max_length=512\n",
    "                ).to(device)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    outputs = model(**inputs)\n",
    "                    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "                    model_predictions.append(probabilities.cpu().numpy()[0])\n",
    "            \n",
    "            test_meta_features.append(np.array(model_predictions))\n",
    "        \n",
    "        # ë©”íƒ€ íŠ¹ì„± ê²°í•©\n",
    "        final_meta_features = np.hstack(test_meta_features)\n",
    "        \n",
    "        # ë©”íƒ€ ëª¨ë¸ë¡œ ìµœì¢… ì˜ˆì¸¡\n",
    "        final_predictions = self.meta_model.predict(final_meta_features)\n",
    "        final_probabilities = self.meta_model.predict_proba(final_meta_features)\n",
    "        \n",
    "        return final_predictions, final_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce16b92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë””ë°”ì´ìŠ¤ ì„¤ì • ì¤‘...\n",
      "ë””ë°”ì´ìŠ¤: cuda\n",
      "GPU ë©”ëª¨ë¦¬: 0.25GB ì‚¬ìš© / 8.00GB ì „ì²´ (3.2% ì‚¬ìš©)\n"
     ]
    }
   ],
   "source": [
    "print(\"ë””ë°”ì´ìŠ¤ ì„¤ì • ì¤‘...\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"ë””ë°”ì´ìŠ¤: {device}\")\n",
    "\n",
    "# GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì²´í¬ í•¨ìˆ˜\n",
    "def print_gpu_utilization():\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "        total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "        usage_percent = (allocated / total) * 100\n",
    "        print(f\"GPU ë©”ëª¨ë¦¬: {allocated:.2f}GB ì‚¬ìš© / {total:.2f}GB ì „ì²´ ({usage_percent:.1f}% ì‚¬ìš©)\")\n",
    "    else:\n",
    "        print(\"CUDA ì‚¬ìš© ë¶ˆê°€\")\n",
    "\n",
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efbbef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Stacking ì•™ìƒë¸” í•™ìŠµ ì‹œì‘!\n",
      "\n",
      "ğŸ“š 1ë‹¨ê³„: ë² ì´ìŠ¤ ëª¨ë¸ë“¤ í•™ìŠµ\n",
      "âœ… bert_small í† í¬ë‚˜ì´ì € ë¡œë“œ ì™„ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23523/23523 [00:02<00:00, 8470.98 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5881/5881 [00:00<00:00, 8625.73 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”¥ bert_small ëª¨ë¸ í•™ìŠµ ì‹œì‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2850' max='6150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2850/6150 51:47 < 1:00:00, 0.92 it/s, Epoch 11/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.109400</td>\n",
       "      <td>2.962562</td>\n",
       "      <td>0.151165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.493800</td>\n",
       "      <td>1.331347</td>\n",
       "      <td>0.469988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.032500</td>\n",
       "      <td>0.915630</td>\n",
       "      <td>0.584935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.741500</td>\n",
       "      <td>0.674062</td>\n",
       "      <td>0.741200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.548300</td>\n",
       "      <td>0.510139</td>\n",
       "      <td>0.805135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.413800</td>\n",
       "      <td>0.409693</td>\n",
       "      <td>0.848495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.261300</td>\n",
       "      <td>0.338250</td>\n",
       "      <td>0.883013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.216300</td>\n",
       "      <td>0.247987</td>\n",
       "      <td>0.920762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.134700</td>\n",
       "      <td>0.207902</td>\n",
       "      <td>0.937936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.084700</td>\n",
       "      <td>0.154539</td>\n",
       "      <td>0.952389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.082000</td>\n",
       "      <td>0.125329</td>\n",
       "      <td>0.964972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.059000</td>\n",
       "      <td>0.114839</td>\n",
       "      <td>0.967693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.050300</td>\n",
       "      <td>0.097749</td>\n",
       "      <td>0.970753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.041900</td>\n",
       "      <td>0.084994</td>\n",
       "      <td>0.976535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.023100</td>\n",
       "      <td>0.086451</td>\n",
       "      <td>0.976875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.025800</td>\n",
       "      <td>0.069478</td>\n",
       "      <td>0.982316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.071738</td>\n",
       "      <td>0.981126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.027300</td>\n",
       "      <td>0.071074</td>\n",
       "      <td>0.982146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>0.014200</td>\n",
       "      <td>0.071298</td>\n",
       "      <td>0.981806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… bert_small ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\n",
      "âœ… roberta_small í† í¬ë‚˜ì´ì € ë¡œë“œ ì™„ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23523/23523 [00:02<00:00, 8501.27 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5881/5881 [00:00<00:00, 6158.13 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”¥ roberta_small ëª¨ë¸ í•™ìŠµ ì‹œì‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-small and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2101' max='3680' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2101/3680 33:07 < 24:55, 1.06 it/s, Epoch 11.41/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.181600</td>\n",
       "      <td>3.087374</td>\n",
       "      <td>0.088420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.912500</td>\n",
       "      <td>1.761048</td>\n",
       "      <td>0.420507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.175300</td>\n",
       "      <td>1.050144</td>\n",
       "      <td>0.606359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.774600</td>\n",
       "      <td>0.742543</td>\n",
       "      <td>0.726747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.590900</td>\n",
       "      <td>0.548103</td>\n",
       "      <td>0.807006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.419000</td>\n",
       "      <td>0.423061</td>\n",
       "      <td>0.853256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.278900</td>\n",
       "      <td>0.319827</td>\n",
       "      <td>0.898487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.211600</td>\n",
       "      <td>0.243814</td>\n",
       "      <td>0.923482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.148700</td>\n",
       "      <td>0.206569</td>\n",
       "      <td>0.938106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.103000</td>\n",
       "      <td>0.164750</td>\n",
       "      <td>0.952049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.089400</td>\n",
       "      <td>0.135801</td>\n",
       "      <td>0.962251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.066900</td>\n",
       "      <td>0.118104</td>\n",
       "      <td>0.967352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.059400</td>\n",
       "      <td>0.101860</td>\n",
       "      <td>0.972794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Stacking ì•™ìƒë¸” ìƒì„± ë° í•™ìŠµ\n",
    "stacking_ensemble = AdvancedStackingEnsemble(n_folds=5, random_state=42)\n",
    "\n",
    "# í•™ìŠµ ì‹¤í–‰ (tokenizer íŒŒë¼ë¯¸í„° ì œê±°)\n",
    "stacking_ensemble.fit(train_data, valid_data, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46776aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ì¤‘...\n",
      "í…ŒìŠ¤íŠ¸ ë°ì´í„°: 1780ê°œ\n",
      "\n",
      "ğŸ”® Stacking ì•™ìƒë¸” ì˜ˆì¸¡ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "roberta_v1 ì˜ˆì¸¡: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1780/1780 [00:12<00:00, 143.99it/s]\n",
      "roberta_v2 ì˜ˆì¸¡: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1780/1780 [00:11<00:00, 149.93it/s]\n",
      "roberta_v3 ì˜ˆì¸¡: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1780/1780 [00:13<00:00, 133.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "\n",
      "í‰ê·  ì˜ˆì¸¡ ì‹ ë¢°ë„: 0.9554\n"
     ]
    }
   ],
   "source": [
    "print(\"í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ì¤‘...\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ\n",
    "test_df = pd.read_csv(\"./test.csv\")\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_df)}ê°œ\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ì „ì²˜ë¦¬\n",
    "test_texts = []\n",
    "for _, row in test_df.iterrows():\n",
    "    sentences = [row[f\"sentence_{i}\"] for i in range(4)]\n",
    "    text = \" [SEP] \".join(sentences)\n",
    "    test_texts.append(text)\n",
    "\n",
    "# Stacking ì•™ìƒë¸”ë¡œ ì˜ˆì¸¡ (tokenizer íŒŒë¼ë¯¸í„° ì œê±°)\n",
    "final_predictions, final_probabilities = stacking_ensemble.predict(test_texts, device)\n",
    "\n",
    "# ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ìˆœì—´ë¡œ ë³€í™˜\n",
    "predicted_orders = []\n",
    "confidences = []\n",
    "\n",
    "for i, pred_label in enumerate(final_predictions):\n",
    "    predicted_order = list(label_to_perm[pred_label])\n",
    "    confidence = np.max(final_probabilities[i])\n",
    "    \n",
    "    predicted_orders.append(predicted_order)\n",
    "    confidences.append(confidence)\n",
    "\n",
    "# í‰ê·  ì‹ ë¢°ë„ ì¶œë ¥\n",
    "avg_confidence = np.mean(confidences)\n",
    "print(f\"\\ní‰ê·  ì˜ˆì¸¡ ì‹ ë¢°ë„: {avg_confidence:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2beb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission íŒŒì¼ ìƒì„± ì¤‘...\n",
      "ì œì¶œ íŒŒì¼ ì €ì¥ ì™„ë£Œ: stacking_ensemble_submission.csv\n",
      "\n",
      "============================================================\n",
      "ğŸ† ê³ ê¸‰ Stacking ì•™ìƒë¸” ì™„ë£Œ!\n",
      "ğŸ“Š ë² ì´ìŠ¤ ëª¨ë¸ ìˆ˜: 3ê°œ\n",
      "ğŸ¯ ë©”íƒ€ ëª¨ë¸: LightGBM\n",
      "ğŸ”® í‰ê·  ì˜ˆì¸¡ ì‹ ë¢°ë„: 95.54%\n",
      "ğŸ“ ì œì¶œ íŒŒì¼: stacking_ensemble_submission.csv\n",
      "============================================================\n",
      "\n",
      "ê°œë³„ ë² ì´ìŠ¤ ëª¨ë¸ ì •ë³´:\n",
      "  ëª¨ë¸ 1: roberta_v1 (LR: 2e-05, Epochs: 20)\n",
      "  ëª¨ë¸ 2: roberta_v2 (LR: 1.5e-05, Epochs: 25)\n",
      "  ëª¨ë¸ 3: roberta_v3 (LR: 3e-05, Epochs: 15)\n"
     ]
    }
   ],
   "source": [
    "print(\"Submission íŒŒì¼ ìƒì„± ì¤‘...\")\n",
    "\n",
    "# ìƒ˜í”Œ ì œì¶œ íŒŒì¼ ë¡œë“œ\n",
    "sample_submission = pd.read_csv(\"./sample_submission.csv\")\n",
    "\n",
    "# ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì œì¶œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "for i in range(4):\n",
    "    sample_submission[f\"answer_{i}\"] = [pred[i] for pred in predicted_orders]\n",
    "\n",
    "# íŒŒì¼ ì €ì¥\n",
    "submission_filename = \"stacking_ensemble_submission.csv\"\n",
    "sample_submission.to_csv(submission_filename, index=False)\n",
    "\n",
    "print(f\"ì œì¶œ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {submission_filename}\")\n",
    "\n",
    "# ìµœì¢… ê²°ê³¼ ìš”ì•½\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(f\"ğŸ† ê³ ê¸‰ Stacking ì•™ìƒë¸” ì™„ë£Œ!\")\n",
    "print(f\"ğŸ“Š ë² ì´ìŠ¤ ëª¨ë¸ ìˆ˜: {len(stacking_ensemble.base_models)}ê°œ\")\n",
    "print(f\"ğŸ¯ ë©”íƒ€ ëª¨ë¸: LightGBM\")\n",
    "print(f\"ğŸ”® í‰ê·  ì˜ˆì¸¡ ì‹ ë¢°ë„: {avg_confidence*100:.2f}%\")\n",
    "print(f\"ğŸ“ ì œì¶œ íŒŒì¼: {submission_filename}\")\n",
    "print(f\"=\"*60)\n",
    "\n",
    "# ê°œë³„ ëª¨ë¸ ì„±ëŠ¥ë„ í™•ì¸í•´ë³´ê¸°\n",
    "print(f\"\\nê°œë³„ ë² ì´ìŠ¤ ëª¨ë¸ ì •ë³´:\")\n",
    "for i, model_info in enumerate(stacking_ensemble.base_models):\n",
    "    config = model_info['config']\n",
    "    print(f\"  ëª¨ë¸ {i+1}: {config['name']} (LR: {config['learning_rate']}, Epochs: {config['epochs']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e891b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daycon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
