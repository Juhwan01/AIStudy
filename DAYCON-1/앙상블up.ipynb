{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334da619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import lightgbm as lgb\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F  \n",
    "import safetensors\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer, \n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "from itertools import permutations\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Listwise Ranking Loss ì •ì˜\n",
    "class ListwiseRankingLoss(nn.Module):\n",
    "    def __init__(self, temperature=1.0):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        \n",
    "    def forward(self, logits, labels):\n",
    "        batch_size = logits.size(0)\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch_idx in range(batch_size):\n",
    "            batch_logits = logits[batch_idx] / self.temperature\n",
    "            target_label = labels[batch_idx].item()\n",
    "            target_permutation = self.label_to_permutation(target_label)\n",
    "            \n",
    "            remaining_positions = list(range(4))\n",
    "            listwise_loss = 0\n",
    "            \n",
    "            for pos in range(4):\n",
    "                correct_sentence = target_permutation[pos]\n",
    "                if correct_sentence in remaining_positions:\n",
    "                    position_probs = F.softmax(batch_logits, dim=0)\n",
    "                    listwise_loss += -torch.log(position_probs[target_label] + 1e-8)\n",
    "                    break\n",
    "            \n",
    "            total_loss += listwise_loss\n",
    "        \n",
    "        return total_loss / batch_size\n",
    "    \n",
    "    def label_to_permutation(self, label):\n",
    "        return label_to_perm[label]\n",
    "\n",
    "# ê³µí†µ ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜\n",
    "def train_single_model(config, train_dataset, valid_dataset, device, model_save_dir=\"./models\"):\n",
    "    \"\"\"ë‹¨ì¼ ëª¨ë¸ í•™ìŠµ ë° ì €ì¥\"\"\"\n",
    "    import os\n",
    "    os.makedirs(model_save_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"\\nğŸ”¥ {config['name']} ëª¨ë¸ í•™ìŠµ ì‹œì‘...\")\n",
    "    \n",
    "    # í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        config['model_name'],\n",
    "        cache_dir='C:/huggingface_cache'\n",
    "    )\n",
    "    \n",
    "    # ëª¨ë¸ ë¡œë“œ\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        config['model_name'],\n",
    "        num_labels=24,\n",
    "        cache_dir='C:/huggingface_cache'\n",
    "    )\n",
    "    model.to(device)\n",
    "    \n",
    "    # ë°ì´í„° í† í¬ë‚˜ì´ì§•\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(\n",
    "            examples[\"text\"],\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=512\n",
    "        )\n",
    "    \n",
    "    tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "    tokenized_valid = valid_dataset.map(tokenize_function, batched=True)\n",
    "    \n",
    "    tokenized_train = tokenized_train.remove_columns([\"text\", \"original_sentences\", \"answer\"])\n",
    "    tokenized_valid = tokenized_valid.remove_columns([\"text\", \"original_sentences\", \"answer\"])\n",
    "    \n",
    "    # í•™ìŠµ ì„¤ì •\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"{model_save_dir}/{config['name']}_results\",\n",
    "        learning_rate=config['learning_rate'],\n",
    "        per_device_train_batch_size=config['batch_size'],\n",
    "        per_device_eval_batch_size=64,\n",
    "        num_train_epochs=config['epochs'],\n",
    "        warmup_steps=config['warmup_steps'],\n",
    "        weight_decay=config['weight_decay'],\n",
    "        max_grad_norm=config['max_grad_norm'],\n",
    "        gradient_accumulation_steps=2,\n",
    "        dataloader_pin_memory=True,\n",
    "        dataloader_num_workers=4,\n",
    "        group_by_length=True,\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=100,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=100,\n",
    "        save_total_limit=3,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"accuracy\",\n",
    "        greater_is_better=True,\n",
    "        dataloader_drop_last=True,\n",
    "        remove_unused_columns=False,\n",
    "        logging_steps=50,\n",
    "        report_to=None,\n",
    "        seed=42,\n",
    "        data_seed=42,\n",
    "    )\n",
    "    \n",
    "    # Listwise Loss ì ìš© íŠ¸ë ˆì´ë„ˆ\n",
    "    class ListwiseTrainer(Trainer):\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            super().__init__(*args, **kwargs)\n",
    "            self.listwise_loss = ListwiseRankingLoss(temperature=1.0)\n",
    "        \n",
    "        def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "            labels = inputs.get(\"labels\")\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.get('logits')\n",
    "            loss = self.listwise_loss(logits, labels)\n",
    "            return (loss, outputs) if return_outputs else loss\n",
    "    \n",
    "    # íŠ¸ë ˆì´ë„ˆ ìƒì„±\n",
    "    trainer = ListwiseTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train,\n",
    "        eval_dataset=tokenized_valid,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=DataCollatorWithPadding(\n",
    "            tokenizer=tokenizer,\n",
    "            padding=True,\n",
    "            max_length=512,\n",
    "            pad_to_multiple_of=8\n",
    "        ),\n",
    "        compute_metrics=lambda eval_pred: {\n",
    "            \"accuracy\": accuracy_score(\n",
    "                eval_pred.label_ids, \n",
    "                np.argmax(eval_pred.predictions, axis=1)\n",
    "            )\n",
    "        },\n",
    "        callbacks=[EarlyStoppingCallback(\n",
    "            early_stopping_patience=config['early_stopping_patience']\n",
    "        )]\n",
    "    )\n",
    "    \n",
    "    print(f\"ğŸ“ {config['name']} ì„¤ì •:\")\n",
    "    print(f\"   Learning Rate: {config['learning_rate']}\")\n",
    "    print(f\"   Batch Size: {config['batch_size']}\")\n",
    "    print(f\"   Epochs: {config['epochs']}\")\n",
    "    print(f\"   Loss Function: ListMLE (Listwise Ranking)\")\n",
    "    \n",
    "    # í•™ìŠµ ì‹¤í–‰\n",
    "    trainer.train()\n",
    "    \n",
    "    # í‰ê°€\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(f\"âœ… {config['name']} ìµœì¢… ì„±ëŠ¥:\")\n",
    "    print(f\"   Accuracy: {eval_results['eval_accuracy']:.4f}\")\n",
    "    \n",
    "    # ëª¨ë¸ ì €ì¥\n",
    "    model_save_path = f\"{model_save_dir}/{config['name']}_final\"\n",
    "    trainer.save_model(model_save_path)\n",
    "    tokenizer.save_pretrained(model_save_path)\n",
    "    \n",
    "    # ì„¤ì •ë„ ì €ì¥\n",
    "    import pickle\n",
    "    config_save_path = f\"{model_save_path}/config.pkl\"\n",
    "    with open(config_save_path, 'wb') as f:\n",
    "        pickle.dump(config, f)\n",
    "    \n",
    "    print(f\"ğŸ’¾ {config['name']} ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_save_path}\")\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'trainer': trainer,\n",
    "        'config': config,\n",
    "        'save_path': model_save_path,\n",
    "        'final_accuracy': eval_results['eval_accuracy'],\n",
    "        'tokenizer': tokenizer\n",
    "    }\n",
    "\n",
    "# ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜\n",
    "def load_trained_model(model_path, device):\n",
    "    \"\"\"ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ\"\"\"\n",
    "    import pickle\n",
    "    \n",
    "    # ì„¤ì • ë¡œë“œ\n",
    "    config_path = f\"{model_path}/config.pkl\"\n",
    "    with open(config_path, 'rb') as f:\n",
    "        config = pickle.load(f)\n",
    "    \n",
    "    # í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    \n",
    "    # ëª¨ë¸ ë¡œë“œ\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'config': config,\n",
    "        'tokenizer': tokenizer,\n",
    "        'save_path': model_path\n",
    "    }\n",
    "\n",
    "print(\"âœ… ê³µí†µ í•¨ìˆ˜ ë° í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7113fbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ë°ì´í„° ì¤€ë¹„ ì¤‘...\")\n",
    "\n",
    "# ìˆœì—´ ë§¤í•‘ ìƒì„± (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)\n",
    "def create_label_mappings():\n",
    "    all_permutations = list(permutations([0, 1, 2, 3]))\n",
    "    perm_to_label = {perm: idx for idx, perm in enumerate(all_permutations)}\n",
    "    label_to_perm = {idx: perm for idx, perm in enumerate(all_permutations)}\n",
    "    return perm_to_label, label_to_perm\n",
    "\n",
    "perm_to_label, label_to_perm = create_label_mappings()\n",
    "\n",
    "# ë°ì´í„° ì¦ê°• í•¨ìˆ˜ (ê¸°ì¡´ê³¼ ë™ì¼)\n",
    "def augment_roberta_data_advanced(train_df, perm_to_label, multiplier=4):\n",
    "    def prepare_roberta_data(train_df, perm_to_label):\n",
    "        processed_data = []\n",
    "        for _, row in train_df.iterrows():\n",
    "            sentences = [row[f\"sentence_{i}\"] for i in range(4)]\n",
    "            answer_tuple = tuple([row[f\"answer_{i}\"] for i in range(4)])\n",
    "            text = \" [SEP] \".join(sentences)\n",
    "            label = perm_to_label[answer_tuple]\n",
    "            \n",
    "            processed_data.append({\n",
    "                \"text\": text,\n",
    "                \"label\": label,\n",
    "                \"original_sentences\": sentences,\n",
    "                \"answer\": answer_tuple\n",
    "            })\n",
    "        return processed_data\n",
    "    \n",
    "    augmented_data = []\n",
    "    original_data = prepare_roberta_data(train_df, perm_to_label)\n",
    "    augmented_data.extend(original_data)\n",
    "    \n",
    "    for aug_round in range(multiplier - 1):\n",
    "        for _, row in train_df.iterrows():\n",
    "            sentences = [row[f\"sentence_{i}\"] for i in range(4)]\n",
    "            original_answer = [row[f\"answer_{i}\"] for i in range(4)]\n",
    "            \n",
    "            if aug_round == 0:\n",
    "                indices = list(range(4))\n",
    "                np.random.shuffle(indices)\n",
    "            elif aug_round == 1:\n",
    "                shift = np.random.randint(1, 4)\n",
    "                indices = [(i + shift) % 4 for i in range(4)]\n",
    "            else:\n",
    "                indices = list(range(4))\n",
    "                i, j = np.random.choice(4, 2, replace=False)\n",
    "                indices[i], indices[j] = indices[j], indices[i]\n",
    "            \n",
    "            shuffled_sentences = [sentences[i] for i in indices]\n",
    "            new_answer = tuple([indices.index(original_answer[i]) for i in range(4)])\n",
    "            \n",
    "            text = \" [SEP] \".join(shuffled_sentences)\n",
    "            label = perm_to_label[new_answer]\n",
    "            \n",
    "            augmented_data.append({\n",
    "                \"text\": text,\n",
    "                \"label\": label,\n",
    "                \"original_sentences\": shuffled_sentences,\n",
    "                \"answer\": new_answer\n",
    "            })\n",
    "    \n",
    "    return augmented_data\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ ë° ì¦ê°•\n",
    "train_df = pd.read_csv('./train.csv')\n",
    "print(f\"ì›ë³¸ í•™ìŠµ ë°ì´í„°: {len(train_df)}ê°œ\")\n",
    "\n",
    "augmented_data = augment_roberta_data_advanced(train_df, perm_to_label, multiplier=4)\n",
    "print(f\"ì¦ê°• í›„ ë°ì´í„°: {len(augmented_data)}ê°œ\")\n",
    "\n",
    "# í•™ìŠµ/ê²€ì¦ ë°ì´í„° ë¶„í• \n",
    "train_data, valid_data = train_test_split(\n",
    "    augmented_data, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=[item[\"label\"] for item in augmented_data]\n",
    ")\n",
    "\n",
    "# ë°ì´í„°ì…‹ ìƒì„±\n",
    "train_dataset = Dataset.from_pandas(pd.DataFrame(train_data))\n",
    "valid_dataset = Dataset.from_pandas(pd.DataFrame(valid_data))\n",
    "\n",
    "print(f\"í•™ìŠµ ë°ì´í„°: {len(train_data)}ê°œ\")\n",
    "print(f\"ê²€ì¦ ë°ì´í„°: {len(valid_data)}ê°œ\")\n",
    "print(\"âœ… ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cdad2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU ì„¤ì •\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"ë””ë°”ì´ìŠ¤: {device}\")\n",
    "\n",
    "# ELECTRA Small ì„¤ì •\n",
    "electra_config = {\n",
    "    'name': 'electra_small_listwise',\n",
    "    'model_name': 'monologg/koelectra-small-v3-discriminator',\n",
    "    'learning_rate': 3e-5,\n",
    "    'epochs': 45,\n",
    "    'batch_size': 64,\n",
    "    'warmup_steps': 300,\n",
    "    'weight_decay': 0.01,\n",
    "    'max_grad_norm': 1.0,\n",
    "    'early_stopping_patience': 8\n",
    "}\n",
    "\n",
    "# ELECTRA ëª¨ë¸ í•™ìŠµ (ì´ ì…€ë§Œ ì‹¤í–‰í•´ì„œ ELECTRA ëª¨ë¸ë§Œ í•™ìŠµ ê°€ëŠ¥)\n",
    "try:\n",
    "    electra_model_info = train_single_model(\n",
    "        electra_config, \n",
    "        train_dataset, \n",
    "        valid_dataset, \n",
    "        device, \n",
    "        model_save_dir=\"./saved_models\"\n",
    "    )\n",
    "    print(\"ğŸ‰ ELECTRA ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ELECTRA ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {e}\")\n",
    "    electra_model_info = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d3f1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT Base ì„¤ì •\n",
    "bert_config = {\n",
    "    'name': 'bert_base_listwise',\n",
    "    'model_name': 'klue/bert-base',\n",
    "    'learning_rate': 2e-5,\n",
    "    'epochs': 40,\n",
    "    'batch_size': 32,\n",
    "    'warmup_steps': 400,\n",
    "    'weight_decay': 0.01,\n",
    "    'max_grad_norm': 1.0,\n",
    "    'early_stopping_patience': 8\n",
    "}\n",
    "\n",
    "# BERT ëª¨ë¸ í•™ìŠµ (ì´ ì…€ë§Œ ì‹¤í–‰í•´ì„œ BERT ëª¨ë¸ë§Œ í•™ìŠµ ê°€ëŠ¥)\n",
    "try:\n",
    "    bert_model_info = train_single_model(\n",
    "        bert_config, \n",
    "        train_dataset, \n",
    "        valid_dataset, \n",
    "        device, \n",
    "        model_save_dir=\"./saved_models\"\n",
    "    )\n",
    "    print(\"ğŸ‰ BERT ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ BERT ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {e}\")\n",
    "    bert_model_info = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fdab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RoBERTa Small ì„¤ì •\n",
    "roberta_config = {\n",
    "    'name': 'roberta_small_listwise',\n",
    "    'model_name': 'klue/roberta-small',\n",
    "    'learning_rate': 2e-5,\n",
    "    'epochs': 35,\n",
    "    'batch_size': 48,\n",
    "    'warmup_steps': 300,\n",
    "    'weight_decay': 0.01,\n",
    "    'max_grad_norm': 1.0,\n",
    "    'early_stopping_patience': 6\n",
    "}\n",
    "\n",
    "# RoBERTa ëª¨ë¸ í•™ìŠµ (ì´ ì…€ë§Œ ì‹¤í–‰í•´ì„œ RoBERTa ëª¨ë¸ë§Œ í•™ìŠµ ê°€ëŠ¥)\n",
    "try:\n",
    "    roberta_model_info = train_single_model(\n",
    "        roberta_config, \n",
    "        train_dataset, \n",
    "        valid_dataset, \n",
    "        device, \n",
    "        model_save_dir=\"./saved_models\"\n",
    "    )\n",
    "    print(\"ğŸ‰ RoBERTa ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ RoBERTa ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {e}\")\n",
    "    roberta_model_info = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7a8a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ì €ì¥ëœ ëª¨ë¸ë“¤ ë¡œë“œ ì¤‘...\")\n",
    "\n",
    "# ëª¨ë¸ ê²½ë¡œë“¤\n",
    "model_paths = [\n",
    "    \"./saved_models/electra_small_listwise_final\",\n",
    "    \"./saved_models/bert_base_listwise_final\", \n",
    "    \"./saved_models/roberta_small_listwise_final\"\n",
    "]\n",
    "\n",
    "# ëª¨ë¸ë“¤ ë¡œë“œ\n",
    "loaded_models = []\n",
    "for path in model_paths:\n",
    "    try:\n",
    "        model_info = load_trained_model(path, device)\n",
    "        loaded_models.append(model_info)\n",
    "        print(f\"âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {model_info['config']['name']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ({path}): {e}\")\n",
    "\n",
    "print(f\"ì´ {len(loaded_models)}ê°œ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9a29a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_meta_features(models, data, device, n_folds=5):\n",
    "    \"\"\"ë©”íƒ€ íŠ¹ì„± ìƒì„±\"\"\"\n",
    "    print(\"ğŸ§  ë©”íƒ€ íŠ¹ì„± ìƒì„± ì¤‘...\")\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    meta_features = np.zeros((len(data), len(models) * 24))\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(df)):\n",
    "        print(f\"  Fold {fold + 1}/{n_folds} ì²˜ë¦¬ ì¤‘...\")\n",
    "        \n",
    "        val_data = df.iloc[val_idx]\n",
    "        \n",
    "        for model_idx, model_info in enumerate(models):\n",
    "            model = model_info['model']\n",
    "            tokenizer = model_info['tokenizer']\n",
    "            model.eval()\n",
    "            \n",
    "            fold_predictions = []\n",
    "            \n",
    "            for _, row in val_data.iterrows():\n",
    "                text = row['text']\n",
    "                \n",
    "                inputs = tokenizer(\n",
    "                    text,\n",
    "                    return_tensors=\"pt\",\n",
    "                    truncation=True,\n",
    "                    padding=True,\n",
    "                    max_length=512\n",
    "                ).to(device)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    outputs = model(**inputs)\n",
    "                    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "                    fold_predictions.append(probabilities.cpu().numpy()[0])\n",
    "            \n",
    "            start_col = model_idx * 24\n",
    "            end_col = (model_idx + 1) * 24\n",
    "            meta_features[val_idx, start_col:end_col] = np.array(fold_predictions)\n",
    "    \n",
    "    print(\"âœ… ë©”íƒ€ íŠ¹ì„± ìƒì„± ì™„ë£Œ\")\n",
    "    return meta_features\n",
    "\n",
    "# ë©”íƒ€ íŠ¹ì„± ìƒì„± (ëª¨ë¸ë“¤ì´ ë¡œë“œëœ í›„ì—ë§Œ ì‹¤í–‰)\n",
    "if len(loaded_models) > 0:\n",
    "    meta_features = generate_meta_features(loaded_models, train_data, device)\n",
    "    meta_labels = [item['label'] for item in train_data]\n",
    "    print(f\"ë©”íƒ€ íŠ¹ì„± í˜•íƒœ: {meta_features.shape}\")\n",
    "else:\n",
    "    print(\"âŒ ë¡œë“œëœ ëª¨ë¸ì´ ì—†ì–´ ë©”íƒ€ íŠ¹ì„±ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58446ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_meta_model(meta_features, meta_labels):\n",
    "    \"\"\"ë©”íƒ€ ëª¨ë¸ í•™ìŠµ (ë§¤ë²ˆ ìƒˆë¡œ í•™ìŠµ)\"\"\"\n",
    "    print(\"ğŸ¯ ë©”íƒ€ ëª¨ë¸ í•™ìŠµ ì¤‘...\")\n",
    "    \n",
    "    meta_model = lgb.LGBMClassifier(\n",
    "        objective='multiclass',\n",
    "        num_class=24,\n",
    "        boosting_type='gbdt',\n",
    "        num_leaves=31,\n",
    "        learning_rate=0.05,\n",
    "        feature_fraction=0.9,\n",
    "        bagging_fraction=0.8,\n",
    "        bagging_freq=5,\n",
    "        verbose=0,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    meta_model.fit(meta_features, meta_labels)\n",
    "    print(\"âœ… ë©”íƒ€ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ\")\n",
    "    \n",
    "    return meta_model\n",
    "\n",
    "# ë©”íƒ€ ëª¨ë¸ í•™ìŠµ (í”¼í´ ì €ì¥ ì—†ì´)\n",
    "if len(loaded_models) > 0:\n",
    "    meta_model = train_meta_model(meta_features, meta_labels)\n",
    "    print(\"ğŸ’¡ ë©”íƒ€ ëª¨ë¸ì´ ë©”ëª¨ë¦¬ì— ì¤€ë¹„ë¨ (ì €ì¥ ì—†ìŒ)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76457490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_ensemble(models, meta_model, test_texts, device):\n",
    "    \"\"\"ì•™ìƒë¸” ì˜ˆì¸¡\"\"\"\n",
    "    print(\"ğŸ”® ì•™ìƒë¸” ì˜ˆì¸¡ ì¤‘...\")\n",
    "    \n",
    "    # ê° ëª¨ë¸ë³„ ì˜ˆì¸¡\n",
    "    test_meta_features = []\n",
    "    \n",
    "    for model_info in models:\n",
    "        model = model_info['model']\n",
    "        tokenizer = model_info['tokenizer']\n",
    "        model.eval()\n",
    "        \n",
    "        model_predictions = []\n",
    "        model_name = model_info['config']['name']\n",
    "        \n",
    "        for text in tqdm(test_texts, desc=f\"{model_name} ì˜ˆì¸¡\"):\n",
    "            inputs = tokenizer(\n",
    "                text,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                padding=True,\n",
    "                max_length=512\n",
    "            ).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs)\n",
    "                probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "                model_predictions.append(probabilities.cpu().numpy()[0])\n",
    "        \n",
    "        test_meta_features.append(np.array(model_predictions))\n",
    "    \n",
    "    # ë©”íƒ€ íŠ¹ì„± ê²°í•©\n",
    "    final_meta_features = np.hstack(test_meta_features)\n",
    "    \n",
    "    # ë©”íƒ€ ëª¨ë¸ë¡œ ìµœì¢… ì˜ˆì¸¡\n",
    "    final_predictions = meta_model.predict(final_meta_features)\n",
    "    final_probabilities = meta_model.predict_proba(final_meta_features)\n",
    "    \n",
    "    return final_predictions, final_probabilities\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ë° ì˜ˆì¸¡\n",
    "if len(loaded_models) > 0 and 'meta_model' in locals():\n",
    "    print(\"í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ì‹œì‘...\")\n",
    "    \n",
    "    test_df = pd.read_csv(\"./test.csv\")\n",
    "    print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_df)}ê°œ\")\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì „ì²˜ë¦¬\n",
    "    test_texts = []\n",
    "    for _, row in test_df.iterrows():\n",
    "        sentences = [row[f\"sentence_{i}\"] for i in range(4)]\n",
    "        text = \" [SEP] \".join(sentences)\n",
    "        test_texts.append(text)\n",
    "    \n",
    "    # ì˜ˆì¸¡ ì‹¤í–‰\n",
    "    final_predictions, final_probabilities = predict_with_ensemble(\n",
    "        loaded_models, meta_model, test_texts, device\n",
    "    )\n",
    "    \n",
    "    # ê²°ê³¼ë¥¼ ìˆœì—´ë¡œ ë³€í™˜\n",
    "    predicted_orders = []\n",
    "    confidences = []\n",
    "    \n",
    "    for i, pred_label in enumerate(final_predictions):\n",
    "        predicted_order = list(label_to_perm[pred_label])\n",
    "        confidence = np.max(final_probabilities[i])\n",
    "        \n",
    "        predicted_orders.append(predicted_order)\n",
    "        confidences.append(confidence)\n",
    "    \n",
    "    avg_confidence = np.mean(confidences)\n",
    "    print(f\"í‰ê·  ì˜ˆì¸¡ ì‹ ë¢°ë„: {avg_confidence:.4f}\")\n",
    "    \n",
    "    # ì œì¶œ íŒŒì¼ ìƒì„±\n",
    "    sample_submission = pd.read_csv(\"./sample_submission.csv\")\n",
    "    for i in range(4):\n",
    "        sample_submission[f\"answer_{i}\"] = [pred[i] for pred in predicted_orders]\n",
    "    \n",
    "    submission_filename = \"meta_ensemble_submission.csv\"\n",
    "    sample_submission.to_csv(submission_filename, index=False)\n",
    "    \n",
    "    print(f\"âœ… ì œì¶œ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {submission_filename}\")\n",
    "    print(f\"ğŸ† ë©”íƒ€ ëª¨ë¸ ì•™ìƒë¸” ì™„ë£Œ! (ëª¨ë¸ ìˆ˜: {len(loaded_models)}ê°œ)\")\n",
    "\n",
    "else:\n",
    "    if len(loaded_models) == 0:\n",
    "        print(\"âŒ ì˜ˆì¸¡í•  ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ëª¨ë¸ë“¤ì„ í•™ìŠµí•´ì£¼ì„¸ìš”.\")\n",
    "    else:\n",
    "        print(\"âŒ ë©”íƒ€ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë©”íƒ€ ëª¨ë¸ì„ í•™ìŠµí•´ì£¼ì„¸ìš”.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
